<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>TeXtidote analysis</title>
<style type="text/css">
body {
  font-family: sans-serif;
}
.highlight, .highlight-sh, .highlight-spelling {
  padding: 2pt;
  border-radius: 4pt;
  cursor: help;
  opacity: 0.7;
  border: dashed 1px;
}
.highlight {
  background-color: orange;
  color: black;
}
.highlight-sh {
  background-color: yellow;
  color: black;
}
.highlight-spelling {
  background-color: red;
  color: white;
}
div.original-file {
  font-family: monospace;
  font-size: 11pt;
  background-color: #f8f8ff;
  padding: 20pt;
  border-radius: 6pt;
}
.textidote {
  	background-image: url(data:image/svg+xml;base64,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);
}
h2.filename {
  font-family: monospace;
}
h1.textidote {
  width: 378px;
  height: 68px;
  display: block;
}
.keyword1 {
  font-weight: bold;
  color: green;
}
.keyword2 {
  font-weight: bold;
  color: darkblue;
}
.comment, .comment * {
  color: darkred;
  font-weight: normal;
}
.linenb {
  font-style: italic;
  color: lightgrey;
  width: 30pt;
  float: left;
  margin-top: 1pt;
  margin-bottom: 1pt;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.codeline {
  margin-left: -30pt;
  padding-left: 60pt;
  margin-top: 1pt;
  margin-bottom: 1pt;
}
.no-text {
  display: none;
}
.clear {
  clear: both;
}
</style>
</head>
<body>
<a href="https://sylvainhalle.github.io/textidote"><h1 class="textidote"><span class="no-text">Results of TeXtidote analysis</span></h1></a>
<p>Here is the result of analyzing your file(s) with TeXtidote. Hover the mouse over highlighted portions of the document to read a tooltip that gives you some writing advice.</p>
<h2 class="filename">./Chapters/Chapter4_proposed2.tex</h2>

<p>Found 8 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 111 words). You should consider merging it with another section or make it longer. [sh:seclen]">chapter</span>{Proposed Methodology II} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:proposed2} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use~\ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline">CNN, like many computer vision models, is a scale-variant~\cite{van2017learning} model such that it cannot recognize objects at various scales unless it explicitly trained to recognize such objects. Data augmentation can accomplish some degree of invariance as it allows the network to be trained with distorted samples, but it not the case for pneumonia scales. This chapter presents a CNN architecture that learns multiscale features using scale pyramid of the  CNN's internal feature maps. Scale pyramid is constructed using atrous convolution of various dilation rates. The correct scale from scale pyramid that allows minimization of the objective function loss is selected using the spatial attention mechanism. </div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline"><span class="keyword1">\section</span>{Methodology II} </div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">    <span class="keyword2">\begin{figure*}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline">    \centerline{<span class="keyword1">\includegraphics</span>[height=40mm,width=15cm]{Figures/ProposedPipe.png}}</div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline"><span class="highlight-sh" title="This figure is missing a label [sh:figref]"> </span>   <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Proposed method for COVID-19 classification from CXR images.}<span class="keyword1">\label</span>{ProposedPipe</span>}<span class="keyword2">\end{figure*}</span><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline">    </div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline">The proposed system presented in this chapter proposes a novel CNN micro-architecture model for learning scale-invariant features from row input CXR images and then classifies these features into normal or COVID-19 cases. Fig.~\ref{ProposedPipe} illustrates trainable end-to-end pipeline of the proposed system. The proposed system depends on a novel Spatially weighted Atrous Spatial Pyramid Pooling (SWASPP) to extract multi-scale features of input CXR images. A novel attention module is then used to fuse the extracted these multi-scale features and select relevant features' scale that the next layer should consider.</div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline"><span class="keyword1">\subsection</span>{Data augmentation}</div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline">    <span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline">    \centerline{<span class="keyword1">\includegraphics</span>[height=30mm,width=9cm]{Figures/TexAug.PNG}}</div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Texture Augmentation module</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline">    <span class="keyword1">\label</span>{texaug}</div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline">    <span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline">The first phase of the proposed CXR classification system is data augmentation phase. Data augmentation is used to reduce the overfitting by artificially enlarge the training dataset~\cite{krizhevsky2012imagenet} using label preserving transformation. Data augmentation phase introduces a degree invariance to a distortion transformation such as the flipping and rotation. The input CXR images are augmented using texture augmentation.  Texture augmentation is performed by introducing a multiplicative normally distributed noises to the frequency spectrum of the input image. CXR image is transformed to the frequency spectrum using the fourier transform.  Noise is modeled using $\mathcal{N}(\mu = 1,\,\sigma = 0.3)$. Fig.~\ref{texaug} illustrates texture augmentation process for frequency distortion of the CXR image. Fig.~\ref{resltaug} shows the original CXR image and the corresponding frequency distorted CXR image. A standard augmentation techniques such as random rotation, horizontal flipping, and vertical flipping are included in the augmentation process. </div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline">    <span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline">    \centerline{<span class="keyword1">\includegraphics</span>[height=40mm,width=9cm]{Figures/freqJitt.png}}</div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Texture Augmentation</span>}{The resulting CXR image from Texture augmentation <span class="keyword1">\textbf</span>{left}: is the original image. <span class="keyword1">\textbf</span>{Right} is the augmented  CXR Image}</div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline">    <span class="keyword1">\label</span>{resltaug}</div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline">    <span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline">    <span class="keyword2">\end{center}</span> </div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline">    </div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=50mm,width=9cm]{Figures/SWASPP.PNG}}</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline"><span class="keyword1">\caption</span>{Spatially weighted atrous spatial Pyramid Pooling (SWASPP) interal layers within dashed square are parameter shared.}</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline"><span class="keyword1">\label</span>{swaspp}</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline"><span class="keyword1">\subsection</span>{Spatially Weighted Atrous Spatial Pyramid Pooling}</div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline">Atrous convolution is a powerful technique for adjusting the resolution of convolutional kernels. This allows to effectively enlarge the field-of-view of the kernel without increasing neither the number of kernel parameters nor the computational complexity of the convolution operation. Atrous convolution is equivalent to performing downsampling and then performing convolution with original kernel without dilation. As a result different dilation rates of the kernel corresponding to different downsampling degrees. A novel spatially weighted atrous spatial pyramid pooling (SWASPP) micro-architecture is presented that exploit the scale space of the CNN's feature maps. Fig.~\ref{swaspp} shows the architecture of the SWASPP. In Fig.~\ref{swaspp}, internal pipelines, bounded by dashed-line square, are parameter-shared and each pipeline of these has a different dilation rates. These pipelines are responsible for extracting multi-scale, scale invariant, features. Sharing of the parameters enforce these pipelines to learn features that exists at multiple levels of scale-pyramid and hence scale-invariance. For a given input CXR image, three scales feature maps are produced.</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=60mm,width=3.5cm]{Figures/AttentionModUl.PNG}}</div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Attantion module structure used by SWASPP micro-architecture</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline"><span class="keyword1">\label</span>{attain}</div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline">To fuse these feature maps produced by different pipeline of the SWASPP from the input feature map, an attention module is emerged. Attention module can be thought as a pixel level classification of which scale does this pixel it belongs to. Fig.~\ref{attain} illustrates the proposed attention module structure. Proposed attention module generates four heatmaps. The first three heatmaps correspond to the three scale feature maps while the remaining heatmap corresponds to the input feature map itself. These heatmaps are summed  up to one (<span class="keyword1">\textit</span>{i.e.,} for a  spatial position </div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline">$(x, y)$, $\sum_{i =1}^{4} H(i,x,y) = 1$ where $H(i,x,y)$ is the $i$ heatmap produced by the attention module). To make sure this property holds, softmax function is used. </div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline">The proposed mirco-architecture uses a pixel level weights produced by corresponding attention module rather than a single weight value for each scale. A single input CXR image may have multiple COVID-19 pneumonia scales which effectively lead to simply averaging the scale space when using single weight for each scale on scale space. In SWASPP, every convolution operation is followed by a BN and leakyReLU~\cite{krizhevsky2012imagenet} non-linearity except the re-projection layers that used to project back to the input space is not followed by nonlinearity. </div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline">BN allows the use of larger learning rate~\cite{ioffe2015batch} and makes network stable during training~\cite{ioffe2015batch}. BN makes the loss landscape of the optimization problem significantly smoother~\cite{santurkar2018does}.</div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline">leakyReLU is used to reduce the vanishing gradient problem~\cite{krizhevsky2012imagenet}.</div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline">A bottleneck is introduced within both the attention module and multi-scale feature extractor pipeline. A bottleneck in SWASPP is used to project the input feature map of dimension $C_{in}\times H\times W$ to $32\times H\times W$ then re-project back to $C_{in}\times H\times W$. Multi-scale feature extraction is preformed on the projected dimension. Same logic is applied to the attention module where the input feature map is projected to a dimension of $16\times H\times W$.</div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline">This bottleneck allows the efficient use of model capacity and reduce the network computational complexity~\cite{huang2017densely}. It only allows the flow of important information and discarding irrelevant information. </div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline"><span class="keyword1">\subsection</span>{Proposed CNN Architecture}</div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">SWASPP is densely stacked~\cite{huang2017densely} together as Fig.~\ref{denseB} illustrates. This kind of connectivity allows implicit deep supervisions as each layer is effectively connected to the last layer using shorter path also facilitate feature reuse~\cite{huang2017densely} and gradient flow. Residual layers are easier to optimize if the required mapping is the identity mapping or simply near to it~\cite{he2016deep}. Densely stacked SWASPP is denoted by (DSWASPP). Convolutional part of proposed model consists of stacking six DSWASPP layers such that the first four layers are interconnected using maxpooling to reduce the spatial size and enlarge the Network receptive field. A single level Spatial Pyramid Pooling (SPP)~\cite{he2015spatial} is added after to produce a fixed size feature vector for a variable size input. SPP layer divides the input feature map into $10\times 10 = 100$ bins then performs a $max$ for each bin as an aggregation function. </div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=30mm,width=6cm]{Figures/DensResd.PNG}}</div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline"><span class="keyword1">\caption</span>{Densely connected SWASPP (DSWASPP): is a stack of densely connected SWASPP, such that the output of any SWASPP is Concatenated to the input of all next layers. All the three layers produce an output of dimension of $C_{in} \times H \times W$.}</div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline"><span class="keyword1">\label</span>{denseB}</div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline">The fixed length feature vector produced by SPP is used as an input to dropout~\cite{srivastava2014dropout} layer. Dropout layer randomly sets the activation of to $0$ with a probability of $0.5$. Dropout prevents the overfitting and reduce complex co-adaptation between the neurons allowing them to learn better representation~\cite{srivastava2014dropout}. It allow implicit ensempling of exponential number of sampled thin network from the original network which enhance the network performance~\cite{srivastava2014dropout}. The result of dropout layer is used as input to the classification network. Classification network consists of a fully connected layers with a $3$ Dense layers such that the output layer is 2-neuron for binary classification<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="keyword1">\textit</span>{i.e)}</span> COVID19 or not. Table~\ref{PCNN} shows the details of the proposed architecture.</div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline">\renewcommand{\arraystretch}{1.5}</div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Proposed CNN architecture of methodology II</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{|c|c|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline">    <span class="keyword1">\textbf</span>{Layer}&amp;\multicolumn{3}{|c|}{<span class="keyword1">\textbf</span>{Proposed CNN Architecture of Methodology II}} \\</div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline">    \cline{2-4} </div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline">    <span class="keyword1">\textbf</span>{Name} &amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Input Shape}}&amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Output Shape}}&amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Param. Count}} \\</div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">    Input layer &amp; - &amp; $1 \times 320 \times 320$ &amp; 0 \\</div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">    BatchNorm-1 &amp; $1 \times 320 \times 320$ &amp; $1 \times 320 \times 320$ &amp; 2 \\</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">    DSWASPP-1&amp; $1 \times 320 \times 320$ &amp; $32 \times 320 \times 320$ &amp; 121,035  \\</div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">    Maxpooling-1&amp; $32 \times 320 \times 320$ &amp;$32 \times 160 \times 160$ &amp; 0 \\</div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline">    DSWASPP-2&amp; $32 \times 160 \times 160$ &amp; $64 \times 160 \times 160$ &amp; 298,236  \\</div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline">    Maxpooling-2 &amp; $64 \times 160 \times 160$ &amp; $64 \times 80 \times 80$ &amp;0  \\</div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline">    DSWASPP-3  &amp; $64 \times 80 \times 80$ &amp; $128 \times 80 \times 80$ &amp; 604,956  \\</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline">    Maxpooling-3 &amp; $128 \times 80 \times 80$ &amp; $128 \times 40 \times 40$ &amp; 0  \\</div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline">    DSWASPP-4  &amp; $128 \times 80 \times 80$ &amp; $128 \times 80 \times 80$ &amp; 784,092 \\</div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline">    DSWASPP-5  &amp; $128 \times 80 \times 80$ &amp; $128 \times 80 \times 80$ &amp; 784,092 \\</div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline">    DSWASPP-6  &amp; $128 \times 80 \times 80$ &amp; $128 \times 80 \times 80$ &amp; 784,092 \\</div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">108</div><div class="codeline">    SPP-1 &amp; $128 \times 80 \times 80$ &amp; $12800$ &amp; 0 \\</div><div class="clear"></div>
<div class="linenb">109</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">110</div><div class="codeline">    Dropout-1 &amp; $12800$ &amp; $12800$ &amp; 0 \\</div><div class="clear"></div>
<div class="linenb">111</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">112</div><div class="codeline">    FC-1 &amp; $12800$ &amp; $128$ &amp; 1,638,528 \\</div><div class="clear"></div>
<div class="linenb">113</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">114</div><div class="codeline">    FC-2 &amp; $128$ &amp; $128$ &amp; 16,512 \\</div><div class="clear"></div>
<div class="linenb">115</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">116</div><div class="codeline">    FC-3 &amp; $128$ &amp; $64$ &amp; 8,256 \\</div><div class="clear"></div>
<div class="linenb">117</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">118</div><div class="codeline">    FC-4 &amp; $64$ &amp; $2$ &amp; 130 \\</div><div class="clear"></div>
<div class="linenb">119</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">120</div><div class="codeline">    Softmax &amp; $2$ &amp; $2$ &amp; 0 \\</div><div class="clear"></div>
<div class="linenb">121</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">122</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">123</div><div class="codeline">    \multicolumn{3}{|c|}{Total Number of Parameter}&amp;5,040,571\\</div><div class="clear"></div>
<div class="linenb">124</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">125</div><div class="codeline">    \multicolumn{4}{c}{Any linear combination is followed by BN and leakyReLU nonlinearity}\\</div><div class="clear"></div>
<div class="linenb">126</div><div class="codeline">    \multicolumn{4}{l}{excluding re-projection layer of the SWASPP modules}</div><div class="clear"></div>
<div class="linenb">127</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">128</div><div class="codeline">    <span class="keyword1">\label</span>{PCNN}</div><div class="clear"></div>
<div class="linenb">129</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">130</div><div class="codeline">    <span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">131</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">132</div><div class="codeline"><span class="keyword1">\section</span>{Summary}</div><div class="clear"></div>
<div class="linenb">133</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">134</div><div class="codeline"><span class="comment"><span class="comment">% CNN is a scale variant model. Many approaches were introduced to overcome this problem such as shared networks, feature pyramid network and atrous convolution. Atrous convolution increases the receptive field of the convolutional kernel without neither increasing the parameter number nor the computational complexity. Atrous convolution is used in the proposed work II to construct the scale space of the input feature. Attention mechanism is used to guide to process the most relevant part of the feature maps. To select the correct scale and fuse multiple scales of the input feature map a spatial attention module is used. A novel CNN architecture is proposed that internally produces multiscale feature maps which is further fused using attention based mechanism. Compact representation is learned via a bottleneck dimension which is introduced in both the multiscale feature extractor module and the attention module.</span></span></div><div class="clear"></div>
<div class="linenb">135</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">136</div><div class="codeline">Convolutional Neural Networks (CNNs) have been widely used in computer vision tasks, including image classification, object detection, and segmentation. However, CNNs are known to be scale variant models, meaning that they can miss important features at different scales. To overcome this issue, various approaches have been proposed, such as shared networks, feature pyramid networks, and atrous convolution.</div><div class="clear"></div>
<div class="linenb">137</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">138</div><div class="codeline">Atrous convolution, also known as dilated convolution, increases the receptive field of the convolutional kernel without increasing the number of parameters or computational complexity. In the proposed work II, atrous convolution is used to construct the scale space of the input feature, allowing the CNN to extract multiscale features.</div><div class="clear"></div>
<div class="linenb">139</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">140</div><div class="codeline">Moreover, to select the correct scale and fuse multiple scales of the input feature map, a spatial attention module is used in the proposed work II. This attention mechanism guides the network to focus on the most relevant parts of the feature maps, which helps to improve the accuracy of the network.</div><div class="clear"></div>
<div class="linenb">141</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">142</div><div class="codeline">To further enhance the performance of the network, a novel CNN architecture is proposed in which multiscale feature maps are internally produced and then fused using an attention-based mechanism. This approach leads to a compact representation of the input data via a bottleneck dimension introduced in both the multiscale feature extractor module and the attention module. Overall, these techniques and architectures help to improve the performance and accuracy of CNNs for computer vision tasks.</div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/Chapter6_Conc.tex</h2>

<p>Found 0 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;3</div><div class="codeline">\chapter{Conclusion And Future Work} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:concl} <span class="comment">% </span></div><div class="clear"></div>
<div class="linenb">&nbsp;6</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;7</div><div class="codeline"><span class="comment"><span class="comment">% COVID-19 is a severe respiratory tract infections. COVID-19 caused by SARS-CoV-2 can readily spread through a contact with an infected person. Monotonically increasing SARS-CoV-2 infections have not only wasted lives but also severely damaged the financial systems of both developing and developed countries. This high spread rate pressure on the health care systems which rise the need to fast methods for diagnosing this disease. Convolutional Neural Networks (CNN) show a great success for various computer vision tasks. However, CNN is a scale-variant model and computationally expensive. In this Thesis, a novel architectures are proposed for multiscale feature extraction and classification and lightweight architecture for COVID-19 diagnosing. The proposed I which is a lightweight CNN model exploits spatial kernel separability to reduce the number of the training parameters to a large extent and regularize the model to only learns linear kernel. Furthermore, This model uses residual connection and batch normalization extensively to maintain the network stability during the training process and provide the model with the regularization effect to reduce the overfitting. This lightweight architecture is trained using QaTa-Cov19 benchmark dataset achieving  100\% for accuracy, sensitivity, precision and F1-score with a very low parameter count (150K) compared with the other methods in the literature. As a future work attention and context attention can benefit the performance. Also evaluating atrous convolution can in the context of spatial separability can be beneficial. Proposed CNN II learns multiscale features using a pyramid of shared convolution kernels with different atrous rates. This scale invariant CNN uses attention based mechanism that is used to guide and select correct scale for each input. Proposed CNN II is an end-to-end trainable network and exploit a novel augmentation technique, Texture Augmentation, to reduce the overfitting. Proposed method II achieved a 0.9929 for $F1-score$ tested on QaTa-Cov19 benchmark dataset with a total of $5,040,571$ trainable parameters. SWASPP can be show a great performance for the segmentation specially atrous convolution originating at the segmentation literature, Also this work can be extended to classify a various pneumonia types.</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;8</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;9</div><div class="codeline">The COVID-19 pandemic has caused severe respiratory tract infections that have rapidly spread through contact with infected individuals, resulting in devastating loss of life and economic damage worldwide. The high rate of transmission has put tremendous pressure on healthcare systems to develop fast and accurate methods for diagnosing the disease. Convolutional Neural Networks (CNNs) have shown success in various computer vision tasks, but they are scale-variant and computationally expensive. In this thesis, we proposed novel architectures for multiscale feature extraction and classification, as well as a lightweight architecture for COVID-19 diagnosis.</div><div class="clear"></div>
<div class="linenb">10</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">11</div><div class="codeline">The proposed lightweight CNN model, referred to as CNN-I, exploits spatial kernel separability to significantly reduce the number of training parameters, and regularizes the model to only learn linear kernels. To maintain network stability and reduce overfitting, residual connections and batch normalization are extensively used. We trained this lightweight architecture on the QaTa-Cov19 benchmark dataset, achieving $100\%$ accuracy, sensitivity, precision, and F1-score with a parameter count of only 150K, which is significantly lower than other methods in the literature. As future work, attention and context attention can be explored to further enhance performance, and evaluating atrous convolution in the context of spatial separability may be beneficial.</div><div class="clear"></div>
<div class="linenb">12</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">13</div><div class="codeline">Our second proposed architecture, CNN-II, learns multiscale features using a pyramid of shared convolution kernels with different atrous rates, making it scale-invariant. An attention-based mechanism is used to guide and select the correct scale for each input. CNN-II is an end-to-end trainable network that exploits a novel augmentation technique, Texture Augmentation, to reduce overfitting. This architecture achieved an F1-score of 0.9929 when tested on the QaTa-Cov19 benchmark dataset, with a total of 5,040,571 trainable parameters. We suggest that the SWASPP (Spatial Pyramid Atrous Spatial Pyramid Pooling) can show great performance for segmentation, especially atrous convolution originating in the segmentation literature. Additionally, this work can be extended to classify various types of pneumonia.</div><div class="clear"></div>
<div class="linenb">14</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">15</div><div class="codeline">In conclusion, this thesis proposes novel architectures for COVID-19 diagnosis that address the limitations of traditional CNN models. These architectures achieved high accuracy while reducing computational cost and parameter count. Further research can explore attention mechanisms and evaluate the use of atrous convolution in the context of spatial separability to improve performance. This work has the potential to improve COVID-19 diagnosis and aid in the development of fast and effective methods to combat future pandemics.</div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/Chapter5_Experment.tex</h2>

<p>Found 22 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">\chapter{Experimental Results} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:results} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use~\ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">In this chapter proposed methodologies are evaluated and compared with the related work.</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline">All models are Trained using QaTa-Cov-19~\cite{ahishali2021advance} dataset using NVIDIA Tesla P-100 GPU and programmed using PyTorch.</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline"><span class="keyword1">\section</span>{QaTa-COV19 Dataset}</div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=60mm,width=9cm]{ScaleDist.png}}</div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Pneumonia Scales of QaTa-COV19-v1, Y-axis represents the frequency, number of occurrence, of a pneumonia with a particular area</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline"><span class="keyword1">\label</span>{pdist}</div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline">QaTa-COV19 is a benchmark dataset for COVID-19 detection and Segmentation form CXR images. All models that used for comparison are trained using QaTa-COV19-v1. Qata-COV19-v1 consists of 4603 COVID-19 CXR and $120,013$ control group CXRs. A balanced number of samples for the two classes is used, namely 4603 CXR image for each class to train the models. Pneumonia Scales of QaTa-COV19-v1 does not exhibit a uniform distribution. Scale of the Pneumonia can be defined as number, area, of 8-neighbor connected pixels labeled as COVID-19 pneumonia. QaTa-COV19-v1 provides a binary masks of 2951 COVID-19 CXR image which can be used for approximating the distribution of scales across the dataset. Fig.~\ref{pdist} illustrates the statistical distribution of QaTa-COV19 scales. The non-uniform distribution of the scales allows the CNN models to only recognize the small scales and not large scales.</div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline"><span class="keyword1">\section</span>{Evaluation of the Methodology I}</div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline">Experiments are conducted on a Lenovo Z50-70 with Intel CORE i7-4510U CPU 2.00 GHz, 8GB RAM, NVIDIA GeForce 840M GPU; and with python and PyTorch library.</div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline"><span class="keyword1">\subsection</span>{Details of the Proposed Architecture}</div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline">The Proposed architecture composed Convbase and Densebase. Convbase is composed of a $6$ feature extraction modules <span class="keyword1">\textit</span>{(FX)} preceded by batch normalization layer. Each FX module can be considered sub-sequential model consists of RSB layer followed by Batch Normalization, Max-pooling and LeakyReLU activation function. The Densebase is a two fully connected layers that classify the Convbase output.</div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline"><span class="keyword1">\subsection</span>{Hyperparameter Specification}</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline">All input chest X-Ray images are resized to be $200\times 200$ . After resizing the input images, these images are fed the Convbase model part which consists of 6 layers of residual separated block. Each residual separated block is followed with batch normalization and LeakyReLU~\cite{he2015delving} as activation function. The output depth of each residual separated block is 4$\times$16, 4$\times$32, 4$\times$64, 4$\times$64, 4$\times$64 and 4$\times$16, respectively. The output of Convbase model part is 1D feature vector of 576 length. Densebase model part consists of two hidden layers. Each layer has the  size of 64 and the output layer of size 2. Each layer of Densebase layers is fully connected to its previous layer. The activation function used in the densebase model part is LeakyReLU. Table~\ref{lyrSpec} summarizes the architecture hyperparameters.</div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{The proposed architecture hyperparameters</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|l|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline"><span class="keyword1">\textbf</span>{Layer Number} &amp; <span class="keyword1">\textbf</span>{Layer Size} &amp; <span class="keyword1">\textbf</span>{Activation Function} \\</div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">RSBLayer1 &amp; 4 $\times$ 16 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline">RSBLayer2 &amp; 4 $\times$ 23 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline">RSBLayer3 &amp; 4 $\times$ 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline">RSBLayer4 &amp; 4 $\times$ 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline">RSBLayer5 &amp; 4 $\times$ 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline">RSBLayer6 &amp; 4 $\times$ 16 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline">\multicolumn{3}{|c|}{<span class="keyword1">\textit</span>{Flatten The Feature maps to 1D 576 feature  vector}}\\</div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline">\cline{1-3}</div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline">LinearLayer1 &amp; 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline">LinearLayer2 &amp; 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">LinearLayer3 &amp; 2 &amp; Softmax\\</div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline"><span class="keyword1">\label</span>{lyrSpec}</div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline"><span class="keyword1">\subsection</span>{Network Training}</div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">The proposed CNN model  is trained for 22 epoch. Adaptive Moment Estimation (Adam) optimizer~\cite{kingma2014adam} is a popular optimization  technique for training deep networks. Adam optimizer is used  during the training  phase of the proposed CNN model. Both batch size and Adam optimizer learning rate is changed during the training phase if the training loss stopped decreasing. Table~\ref{tabTrparam} summarizes the parameters values used in the training phase of the proposed CNN model. Fig.~\ref{fig5}(a) show the progress for training and validation loss across each epoch. The difference between the training loss and validation loss through epochs show that our did not memorize the dataset.</div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{The change of batch size and learning rate through the Training process</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|l|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline"><span class="keyword1">\textbf</span>{Epoch Number} &amp; <span class="keyword1">\textbf</span>{Batch Size} &amp; <span class="keyword1">\textbf</span>{Learning Rate} \\</div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">From 0 to 6 &amp; 128 &amp; 1e-3\\</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline">From 7 to 12 &amp; 256 &amp; 1e-3\\</div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline">From 13 to 21 &amp; 256 &amp; 1e-4\\</div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline"> </div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline"><span class="keyword1">\label</span>{tabTrparam}</div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline"><span class="keyword1">\subsection</span>{Model Evaluation}</div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline">To assess the efficiency of the proposed method,  the proposed method is compared to recent state-of-the-art methods for detecting Covid-19 cases. Experiments are conducted with the same dataset and the corresponding hyperparameter of each work. All the methods depend on CNN. The comparison is performed using precision, sensitivity, F1-score, and accuracy~\cite{hossin2015review}. In addition, the number of the parameters used in the training phase is very important comparison factor. Table~\ref{modelperf} depicts the comparison between state-of-the-art methods and the proposed method. As shown in the comparison, the proposed method  outperforms other methods achieving the maximum accuracy and the lowest  parameter count. </div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline"><span class="keyword1">\caption</span>{ A performance comparison between the proposed method and state-of-the-art models.}</div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|l|c|c|c|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline"><span class="keyword1">\textbf</span>{Method} &amp; <span class="keyword1">\textbf</span>{PC} &amp; <span class="keyword1">\textbf</span>{P(\%)}&amp; <span class="keyword1">\textbf</span>{S(\%)}&amp; <span class="keyword1">\textbf</span>{F1(\%)}&amp; <span class="keyword1">\textbf</span>{A(\%)} \\</div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline">Proposed Method &amp; 0.15M &amp; 100.00 &amp; 100.00 &amp; 100.00 &amp;100.00\\</div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline">ResNet-34~\cite{nayak2021application} &amp; 21.8M &amp; 96.77&amp; 100.00 &amp; 98.36 &amp;98.33  \\</div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline">ACoS Phase I~\cite{chandra2021coronavirus}&amp; - &amp; 98.266 &amp; 96.512 &amp; 98.551 &amp; 98.062 \\</div><div class="clear"></div>
<div class="linenb">108</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">109</div><div class="codeline">ResNet-50~\cite{nayak2021application}&amp; 25.6M&amp; 95.24&amp; 100.00&amp; 97.56&amp; 97.50 \\</div><div class="clear"></div>
<div class="linenb">110</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">111</div><div class="codeline">GoogleNet~\cite{nayak2021application}&amp; 5M &amp;96.67&amp; 96.67&amp; 96.67&amp; 96.67 \\</div><div class="clear"></div>
<div class="linenb">112</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">113</div><div class="codeline">VGG-16~\cite{nayak2021application}&amp; 138M&amp; 95.08 &amp; 96.67 &amp; 95.87 &amp;95.83\\</div><div class="clear"></div>
<div class="linenb">114</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">115</div><div class="codeline">AlexNet~\cite{nayak2021application}&amp; 60M&amp; 96.72 &amp;98.33 &amp; 97.52&amp; 97.50 \\</div><div class="clear"></div>
<div class="linenb">116</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">117</div><div class="codeline">MobileNet-V2~\cite{nayak2021application} &amp; 3.4M &amp;98.24&amp; 93.33&amp; 95.73 &amp; 95.83 \\</div><div class="clear"></div>
<div class="linenb">118</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">119</div><div class="codeline">Inception-V3~\cite{nayak2021application}&amp; 24M &amp;96.36&amp; 88.33 &amp; 92.17&amp; 92.50\\</div><div class="clear"></div>
<div class="linenb">120</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">121</div><div class="codeline">SqueezeNet~\cite{nayak2021application}&amp; 1.25M &amp;98.27 &amp;95.00&amp; 96.61&amp; 96.67 \\</div><div class="clear"></div>
<div class="linenb">122</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">123</div><div class="codeline">\multicolumn{6}{l}{<span class="keyword1">\textit</span>{ PC is Parameter count, P is precision, S is sensitivity }}\\</div><div class="clear"></div>
<div class="linenb">124</div><div class="codeline">\multicolumn{6}{l}{<span class="keyword1">\textit</span>{  F1 is F1-score, and A is accuracy }}\\</div><div class="clear"></div>
<div class="linenb">125</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">126</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">127</div><div class="codeline"><span class="keyword1">\label</span>{modelperf}</div><div class="clear"></div>
<div class="linenb">128</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">129</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">130</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">131</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">132</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">133</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">134</div><div class="codeline"><span class="keyword1">\includegraphics</span>[height=90mm,width=8.0cm]{Figures/fig6.png}</div><div class="clear"></div>
<div class="linenb">135</div><div class="codeline"><span class="highlight-sh" title="This figure is missing a label [sh:figref]"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]">\</span>caption{(a) The training loss and the validation loss of each epoch and (b) The training accuracy and the validation accuracy of each epoch.}<span class="keyword1">\label</span>{fig5</span>}<span class="keyword2">\end{center}</span><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">136</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">137</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">138</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">139</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 15 words). You should consider merging it with another section or make it longer. [sh:seclen]"><span class="highlight-sh" title="This section is very short (about 16 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span></span>{Evaluation of the Methodology II}</div><div class="clear"></div>
<div class="linenb">140</div><div class="codeline">Methodology II is evaluated and compared against strong baselines and related works. </div><div class="clear"></div>
<div class="linenb">141</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">142</div><div class="codeline"><span class="keyword1">\subsection</span>{Baseline Networks}</div><div class="clear"></div>
<div class="linenb">143</div><div class="codeline">Different architectures are trained to validate the effectiveness of the proposed method. </div><div class="clear"></div>
<div class="linenb">144</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Spatial Pyramid Pooling (SPP-net) Based model}</div><div class="clear"></div>
<div class="linenb">145</div><div class="codeline">Four variants of SPP-ne<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">t\cite</span>{he2015spatial} is trained. All $4$ variants have the same architecture but different SPP-layer. These variants of SPP-layer are as follows:</div><div class="clear"></div>
<div class="linenb">146</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">147</div><div class="codeline">  <span class="keyword1">\item</span> full pyramid SPP of 8-levels using average-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">148</div><div class="codeline">  <span class="keyword1">\item</span> full SPP pyramid of 8-levels using max-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">149</div><div class="codeline">  <span class="keyword1">\item</span> single level SPP with 10-bins using average-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">150</div><div class="codeline">  <span class="keyword1">\item</span> single level SPP with 10-bins using max-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">151</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">152</div><div class="codeline">  A Fixed Architecture is used for all SPP variant models with the same design principles of the proposed architecture. These architectures are the same as the proposed architecture but DSWASPP is replaced by DC6 and SPP-1 layer is replaced with the corresponding SPP layer. DC6 is defined as six convolutional layers Densely connected together. For SPP-net variants training a multiscale augmentation is added to the proposed augmentation process. Multiscale augmentation is done by randomly sampling different $5$ scales typically $\{320, 320\pm25, 320\pm50 \}$.</div><div class="clear"></div>
<div class="linenb">153</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Switchable Atrous Spatial Pyramid Pooling (SASPP-net) Based models} </div><div class="clear"></div>
<div class="linenb">154</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">155</div><div class="codeline"><span class="keyword2">\begin{figure*}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">156</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=63mm,width=15cm]{SPP-netsTraining.PNG}}</div><div class="clear"></div>
<div class="linenb">157</div><div class="codeline"><span class="keyword1">\caption</span>{Training profiles of both SPP-net variants and the proposed network. For the same color solid line represents training statistics while dashed line represents the validation statistics for the corresponding model. <span class="keyword1">\textbf</span>{left:} is the training accuracy. <span class="keyword1">\textbf</span>{Right:} is the training loss.}</div><div class="clear"></div>
<div class="linenb">158</div><div class="codeline"><span class="keyword1">\label</span>{SPP-train}</div><div class="clear"></div>
<div class="linenb">159</div><div class="codeline"><span class="keyword2">\end{figure*}</span></div><div class="clear"></div>
<div class="linenb">160</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">161</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">162</div><div class="codeline">Another Base-line is introduced for comparison which is exactly as same as the proposed network but with different Attention module structure and does not include a bottleneck within ASPP. This architecture is referred Switchable Atrous Spatial Pyramid Pooling (SASPP-net). Attention module structure is $Softmax(FC(GAP(X)))$ where: <span class="keyword1">\textit</span>{$X$: is the input feature map}, <span class="keyword1">\textit</span>{$GAP$: is a global average pooling}, <span class="keyword1">\textit</span>{$FC$: is fully Connected layer performs a non-linear projection to ${\rm I\!R}^{4}$ a 4 values for the three scales and the input feature map}.<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">163</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">164</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">165</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Baselines and their total number of parameters</span>}</div><div class="clear"></div>
<div class="linenb">166</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">167</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|c|c|c|}</div><div class="clear"></div>
<div class="linenb">168</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">169</div><div class="codeline"><span class="keyword1">\textbf</span>{Model}&amp;\multicolumn{2}{|c|}{<span class="keyword1">\textbf</span>{Baseline CNN Architectures}} \\</div><div class="clear"></div>
<div class="linenb">170</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">171</div><div class="codeline"><span class="keyword1">\textbf</span>{Type} &amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Variant}}&amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Param. Count}} \\</div><div class="clear"></div>
<div class="linenb">172</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">173</div><div class="codeline">  &amp; ML Average pooling &amp; $14,916,420$   \\</div><div class="clear"></div>
<div class="linenb">174</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">175</div><div class="codeline">SPP &amp; ML max pooling &amp; $14,916,420$   \\</div><div class="clear"></div>
<div class="linenb">176</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">177</div><div class="codeline">  &amp; SL Average pooling &amp; $14,490,436$   \\</div><div class="clear"></div>
<div class="linenb">178</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">179</div><div class="codeline">  &amp; SL max pooling &amp; $14,490,436$ \\</div><div class="clear"></div>
<div class="linenb">180</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">181</div><div class="codeline">\multicolumn{2}{|c|}{SASPP} &amp; $13,031,841$\\</div><div class="clear"></div>
<div class="linenb">182</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">183</div><div class="codeline">\multicolumn{3}{l}{ <span class="keyword1">\textbf</span>{ML}: Multilevel, <span class="keyword1">\textbf</span>{SL}: Single level}</div><div class="clear"></div>
<div class="linenb">184</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">185</div><div class="codeline"><span class="keyword1">\label</span>{Basarch}</div><div class="clear"></div>
<div class="linenb">186</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">187</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">188</div><div class="codeline">Table~\ref{Basarch} summarizes the base-line models and the Corresponding parameter count.</div><div class="clear"></div>
<div class="linenb">189</div><div class="codeline"><span class="keyword1">\subsection</span>{Models Training}</div><div class="clear"></div>
<div class="linenb">190</div><div class="codeline">Proposed architecture and baseline architecture are trained with the same hyperparameters. Dataset is split to $0.6$, $0.2$ and $0.2$ for training, validation and testing, respectively. For training a Cross Entropy Loss is used. All models trained with ADAM~\cite{kingma2014adam} optimizer with learning rate start by $10^{-3}$ and reduced every time validation loss plateau by multiplying by $10^{-1}$. A Max Norm Constraint is used to clip the gradient value to norm of $1$~\cite{krizhevsky2012imagenet}. A batch size of $128$ is used to calculate the gradient.</div><div class="clear"></div>
<div class="linenb">191</div><div class="codeline"><span class="keyword1">\subsection</span>{Reducing the overfitting}</div><div class="clear"></div>
<div class="linenb">192</div><div class="codeline">Overfitting is a critical problem for training large networks~\cite{krizhevsky2012imagenet}. Proposed work has reduced the overfitting by using:</div><div class="clear"></div>
<div class="linenb">193</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">194</div><div class="codeline"><span class="keyword1">\item</span> Using Dropout with retrain probability of $0.5$~\cite{srivastava2014dropout}.</div><div class="clear"></div>
<div class="linenb">195</div><div class="codeline"><span class="keyword1">\item</span> Using BatchNorm adds noise due to randomization introduced when constructing the minibatch~\cite{ioffe2015batch}.</div><div class="clear"></div>
<div class="linenb">196</div><div class="codeline"><span class="keyword1">\item</span> Using max norm constraint~\cite{krizhevsky2012imagenet}.</div><div class="clear"></div>
<div class="linenb">197</div><div class="codeline"><span class="keyword1">\item</span> Deep and thin architectures by design has an implicit regularization effect~\cite{he2016deep}. </div><div class="clear"></div>
<div class="linenb">198</div><div class="codeline"><span class="keyword1">\item</span> Augmentation process <span class="highlight-sh" title="Use a backslash or comma after the second period; otherwise LaTeX will think it is a full stop ending a sentence. [sh:011]">i.e.)</span> Texture augmentation~\cite{krizhevsky2012imagenet}. </div><div class="clear"></div>
<div class="linenb">199</div><div class="codeline"><span class="keyword1">\item</span> The use of small kernel size~\cite{simonyan2014very}.</div><div class="clear"></div>
<div class="linenb">200</div><div class="codeline"><span class="keyword1">\item</span> Bottleneck in SWASPP module and the attention module.</div><div class="clear"></div>
<div class="linenb">201</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">202</div><div class="codeline">During training no overfitting effects is observed.</div><div class="clear"></div>
<div class="linenb">203</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 108 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span>{Comparison with baselines}</div><div class="clear"></div>
<div class="linenb">204</div><div class="codeline">Proposed network is compared with the vanilla SPP-based Architectures and ASPP architecture.</div><div class="clear"></div>
<div class="linenb">205</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Comparing with SPP-nets}</div><div class="clear"></div>
<div class="linenb">206</div><div class="codeline">Fig.~\ref{SPP-train} illustrates both training loss and training and validation accuracies and losses. Table~\ref{blaccom} illustrates the testing accuracy for comparison between the SPP-nets baseline and the proposed architecture.</div><div class="clear"></div>
<div class="linenb">207</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">208</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Comparison between Proposed network and baseline SPP architectures </span>}</div><div class="clear"></div>
<div class="linenb">209</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">210</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|c|c|}</div><div class="clear"></div>
<div class="linenb">211</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">212</div><div class="codeline"><span class="keyword1">\textbf</span>{Model Name}&amp; Accurracy \\</div><div class="clear"></div>
<div class="linenb">213</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">214</div><div class="codeline"> SPP ML Average pooling &amp; $0.958$   \\</div><div class="clear"></div>
<div class="linenb">215</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">216</div><div class="codeline">SPP ML max pooling &amp; $0.950$   \\</div><div class="clear"></div>
<div class="linenb">217</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">218</div><div class="codeline">  SPP SL Average pooling &amp; $0.927$   \\</div><div class="clear"></div>
<div class="linenb">219</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">220</div><div class="codeline">  SPP SL max pooling &amp; $0.957$ \\</div><div class="clear"></div>
<div class="linenb">221</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">222</div><div class="codeline">Proposed Network &amp; $0.987$\\</div><div class="clear"></div>
<div class="linenb">223</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">224</div><div class="codeline">\multicolumn{2}{l}{ <span class="keyword1">\textbf</span>{ML}: Multilevel, <span class="keyword1">\textbf</span>{SL}: Single level}</div><div class="clear"></div>
<div class="linenb">225</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">226</div><div class="codeline"><span class="keyword1">\label</span>{blaccom}</div><div class="clear"></div>
<div class="linenb">227</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">228</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">229</div><div class="codeline">\<span class="highlight-sh" title="This subsubsection is very short (about 71 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsubsection</span>{Comparing with SASPP}</div><div class="clear"></div>
<div class="linenb">230</div><div class="codeline">Fig.~\ref{saspp} illustrates the training and validation loss of training a SASPP baseline architecture. As shown in Fig.~\ref{saspp} SASPP unable to generalize and start overfitting the training set. This comparison empirically shows the importance of the bottleneck introduced in the proposed architecture.</div><div class="clear"></div>
<div class="linenb">231</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">232</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">233</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">234</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{saspp.PNG}}</div><div class="clear"></div>
<div class="linenb">235</div><div class="codeline"><span class="keyword1">\caption</span>{SASPP baseline architecture loss during both training, solid line, and validation, bashed line, compared with Proposed network and best performing SPP architecture.}</div><div class="clear"></div>
<div class="linenb">236</div><div class="codeline"><span class="keyword1">\label</span>{saspp}</div><div class="clear"></div>
<div class="linenb">237</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">238</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">239</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">240</div><div class="codeline"><span class="keyword1">\subsection</span>{Comparing with the related works}</div><div class="clear"></div>
<div class="linenb">241</div><div class="codeline">To fairly compare with the related works proposed work is further trained. Fig.~\ref{ploss} shows the training and validation loss of the proposed network. Fig.~\ref{pacc} shows the of the training and validation accuracy. </div><div class="clear"></div>
<div class="linenb">242</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">243</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">244</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{PLOSS.PNG}}</div><div class="clear"></div>
<div class="linenb">245</div><div class="codeline"><span class="keyword1">\caption</span>{Cross entropy loss of the proposed architecture.}</div><div class="clear"></div>
<div class="linenb">246</div><div class="codeline"><span class="keyword1">\label</span>{ploss}</div><div class="clear"></div>
<div class="linenb">247</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">248</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">249</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">250</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">251</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{PACC.PNG}}</div><div class="clear"></div>
<div class="linenb">252</div><div class="codeline"><span class="keyword1">\caption</span>{Training and validation accuracy of the proposed architecture.}</div><div class="clear"></div>
<div class="linenb">253</div><div class="codeline"><span class="keyword1">\label</span>{pacc}</div><div class="clear"></div>
<div class="linenb">254</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">255</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">256</div><div class="codeline">Proposed Network has a sensitivity, recall, and precision of $0.994$ and $0.991$ respectively on the validation set. Precision can be improved by investigating the precision-recall trade-off. Fig.~\ref{prt} shows the trade-off between precision and recall for different thresholds. A threshold of $0.618$ is used to improve the precision resulting in a sensitivity, recall, of $0.9903$ and precision of $0.9956$.</div><div class="clear"></div>
<div class="linenb">257</div><div class="codeline">Comparison metrics are defined as follows:</div><div class="clear"></div>
<div class="linenb">258</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">259</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Accuracy}: is ratio of correctly classified samples to the total number of samples</div><div class="clear"></div>
<div class="linenb">260</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Sensitivity}: is ratio of correctly classified Covid-19 samples to the total number of actual Covid-19 samples </div><div class="clear"></div>
<div class="linenb">261</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Precision}: is the ratio of correctly, according to the ground-truth labels, classified Covid-19 samples to the total number of samples classified as Covid-19.</div><div class="clear"></div>
<div class="linenb">262</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Specificity}: is the ratio of correctly, according to the ground-truth labels, classified non-COVID-19 to the total number of non-Covid-19.</div><div class="clear"></div>
<div class="linenb">263</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{F1-score}: is the harmonic mean of both Sensitivity and Precision.</div><div class="clear"></div>
<div class="linenb">264</div><div class="codeline"><span class="keyword2">\begin{center}</span>  </div><div class="clear"></div>
<div class="linenb">265</div><div class="codeline"> $F_{1}=\frac{2\times\text{Precision} \times \text{Sensitivity}}{\text{Precision} + \text{Sensitivity}}$</div><div class="clear"></div>
<div class="linenb">266</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">267</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Param. Count}: is the total number of the trainable parameters.</div><div class="clear"></div>
<div class="linenb">268</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">269</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">270</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">271</div><div class="codeline"><span class="keyword2">\begin{table*}</span>[!p!t]</div><div class="clear"></div>
<div class="linenb">272</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Comparison between Proposed network and Related works </span>}</div><div class="clear"></div>
<div class="linenb">273</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">274</div><div class="codeline">\resizebox{\textwidth}{!}{<span class="keyword2">\begin{tabular}</span>{|c|c|c|c|c|c|c|}</div><div class="clear"></div>
<div class="linenb">275</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">276</div><div class="codeline"><span class="keyword1">\textbf</span>{Model Name}&amp; <span class="keyword1">\textbf</span>{Accuracy} &amp; <span class="keyword1">\textbf</span>{Sensitivity} &amp;<span class="keyword1">\textbf</span>{ Precision} &amp; <span class="keyword1">\textbf</span>{Specificity} &amp; <span class="keyword1">\textbf</span>{F1-score} &amp; <span class="keyword1">\textbf</span>{Param. Count}\\</div><div class="clear"></div>
<div class="linenb">277</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">278</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">279</div><div class="codeline">Proposed &amp; 0.99294 &amp; <span class="keyword1">\textbf</span>{0.9903} &amp; <span class="keyword1">\textbf</span>{0.9956} &amp; 0.9956 &amp; <span class="keyword1">\textbf</span>{0.9929} &amp; <span class="keyword1">\textbf</span>{5,040,571}\\</div><div class="clear"></div>
<div class="linenb">280</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">281</div><div class="codeline">SRC-Dal<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">m\cite</span>{ar} &amp; 0.985 &amp; 0.886 &amp; - &amp; 0.993 &amp; - &amp; -\\</div><div class="clear"></div>
<div class="linenb">282</div><div class="codeline">\hline </div><div class="clear"></div>
<div class="linenb">283</div><div class="codeline">SRC-Ho<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">m\cite</span>{ar} &amp; 0.977 &amp; 0.921 &amp; - &amp; 0.982 &amp; - &amp; - \\</div><div class="clear"></div>
<div class="linenb">284</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">285</div><div class="codeline">CRC-ligh<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">t\cite</span>{ar} &amp; 0.973 &amp; 0.955 &amp; - &amp; 0.974 &amp; - &amp;- \\</div><div class="clear"></div>
<div class="linenb">286</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">287</div><div class="codeline">DenseNet121*\cite{ar} &amp; 0.992 &amp; 0.9714 &amp; - &amp; 0.9949 &amp; - &amp; 6,955,906  \\</div><div class="clear"></div>
<div class="linenb">288</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">289</div><div class="codeline">Inception-v<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">3\cite</span>{ar} &amp; 0.993 &amp; 0.954 &amp; - &amp; 0.998 &amp; - &amp; 21,772,450  \\</div><div class="clear"></div>
<div class="linenb">290</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">291</div><div class="codeline">Modified MobileNetV2~\cite{akt}  &amp; 0.98 &amp; 0.98 &amp; 0.97 &amp; - &amp; 0.97 &amp; -\\</div><div class="clear"></div>
<div class="linenb">292</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">293</div><div class="codeline">ReCovNet-v<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">2\cite</span>{dag} &amp; 0.99726 &amp; 0.98571 &amp; 0.94262 &amp; 0.9977 &amp; 0.96369 &amp;- \\</div><div class="clear"></div>
<div class="linenb">294</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">295</div><div class="codeline">ReCovNet-v<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">1\cite</span>{dag} &amp; 0.99824 &amp; 0.9781 &amp; 0.97438 &amp; 0.99901 &amp; 0.97624 &amp; -\\</div><div class="clear"></div>
<div class="linenb">296</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">297</div><div class="codeline">DenseNet-12<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">1\cite</span>{dag}  &amp; <span class="keyword1">\textbf</span>{0.9988} &amp; 0.97429 &amp; 0.9932 &amp; <span class="keyword1">\textbf</span>{0.99974} &amp; 0.98365 &amp; 6,955,906 \\</div><div class="clear"></div>
<div class="linenb">298</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">299</div><div class="codeline"><span class="keyword2">\end{tabular}</span>}</div><div class="clear"></div>
<div class="linenb">300</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">301</div><div class="codeline"><span class="keyword1">\label</span>{rwcom}</div><div class="clear"></div>
<div class="linenb">302</div><div class="codeline"><span class="keyword2">\end{table*}</span></div><div class="clear"></div>
<div class="linenb">303</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">304</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">305</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">306</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">307</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{PresRecuTradff.PNG}}</div><div class="clear"></div>
<div class="linenb">308</div><div class="codeline"><span class="keyword1">\caption</span>{precision-recall trade-off of the proposed network.}</div><div class="clear"></div>
<div class="linenb">309</div><div class="codeline"><span class="keyword1">\label</span>{prt}</div><div class="clear"></div>
<div class="linenb">310</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">311</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">312</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">313</div><div class="codeline">Table~\ref{rwcom} summarizes the comparison between the recent related works and the proposed architecture. Proposed architecture outperform these works in many metrics. As their training and testing does not depend on a balanced number of samples, accuracy and specificity are not good metrics for evaluation. </div><div class="clear"></div>
<div class="linenb">314</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">315</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">316</div><div class="codeline"><span class="keyword1">\section</span>{Summary}</div><div class="clear"></div>
<div class="linenb">317</div><div class="codeline"><span class="comment"><span class="comment">% This chapter illustrates the superior performance of the proposed work I and II. Experimental results of proposed work I show the effectiveness of spatial separable kernels and residual connection for detecting COVID-19. The proposed architecture I use batch normalization to maintain the network stability during the training process. During the training process, the hyperparameters (such as batch size and learning rate) are determined dynamically. Proposed architecture I outperformed previous works for binary classification of chest X-Ray images to normal or COVID-19 cases. The proposed architecture has a very low parameter count (150K trainable parameter) compared to previous work. The proposed  architecture I achieved a performance of 100\% for accuracy, sensitivity, precision and F1-score. Proposed work I does not take care of the fact that CNN is scale variant model while proposed work II does. Better quantitative results for CXR COVID-19 classification can be obtained with a multiscale training approaches. Proposed work II internally produces multiscale feature maps using Atrous Spatial pyramid pooling. These multiscales feature maps are fused using an attention module. To learn a compact representation a bottleneck dimension is introduced in both the multiscale feature extractor module and the attention module. Proposed work II outperformed current sate-of-the-art architecture with lower parameter number. Proposed method has recorded a $0.9929$ for $F1-score$.</span></span></div><div class="clear"></div>
<div class="linenb">318</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">319</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">320</div><div class="codeline">This chapter illustrates the superior performance of the proposed work I and II. In addition to the superior performance of the proposed works I and II, the chapter also provides a detailed analysis of the experimental results. The evaluation of proposed work I demonstrates that the use of spatial separable kernels and residual connection significantly improves the performance of the COVID-19 detection system. The batch normalization technique is found to be effective in maintaining the network stability during the training process. The dynamic selection of hyperparameters such as batch size and learning rate further improves the performance of the proposed architecture I.</div><div class="clear"></div>
<div class="linenb">321</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">322</div><div class="codeline">Furthermore, the proposed architecture I outperforms existing works for binary classification of chest X-Ray images for normal and COVID-19 cases. This is particularly noteworthy as the proposed architecture has a low parameter count of only 150K trainable parameters compared to previous works. The achievement of a performance of $100\%$ for accuracy, sensitivity, precision, and F1-score indicates the high accuracy and reliability of the proposed architecture.</div><div class="clear"></div>
<div class="linenb">323</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">324</div><div class="codeline">Although the proposed architecture I performs exceptionally well, it does not address the scale variant nature of the CNN model. This issue is addressed in the proposed work II, which incorporates multiscale training approaches to obtain better quantitative results for CXR COVID-19 classification. The use of Atrous Spatial pyramid pooling enables the internal production of multiscale feature maps, which are then fused using an attention module. To achieve a compact representation, a bottleneck dimension is introduced in both the multiscale feature extractor module and the attention module.</div><div class="clear"></div>
<div class="linenb">325</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">326</div><div class="codeline">The proposed work II outperforms the current state-of-the-art architecture with lower parameter numbers. The recorded $0.9929$ for F1-score indicates the high performance of the proposed architecture. The detailed analysis and experimental results presented in this chapter provide valuable insights into the effectiveness of the proposed architectures and their potential for improving the accuracy and reliability of COVID-19 detection systems.</div><div class="clear"></div>
</div>
<h2 class="filename">./mainForPlagrism.tex</h2>

<p>Found 0 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">%</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline"><span class="keyword1">\documentclass</span>[</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">12pt, <span class="comment">% The default document font size, options: 10pt, 11pt, 12pt</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline"><span class="comment"><span class="comment">%oneside, % Two side (alternating margins) for binding by default, uncomment to switch to one side</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline">english, <span class="comment">% ngerman for German</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">onehalfspacing, <span class="comment">% singlespacing Single line spacing, alternatives: onehalfspacing or doublespacing</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline"><span class="comment"><span class="comment">%draft, % Uncomment to enable draft mode (no pictures, no links, overfull hboxes indicated)</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline"><span class="comment"><span class="comment">%nolistspacing, % If the document is onehalfspacing or doublespacing, uncomment this to set spacing in lists to single</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline">liststotoc, <span class="comment">% Uncomment to add the list of figures/tables/etc to the table of contents</span></div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline">toctotoc, <span class="comment">% Uncomment to add the main table of contents to the table of contents</span></div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline"><span class="comment"><span class="comment">%parskip, % Uncomment to add space between paragraphs</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">nohyperref, <span class="comment">% Uncomment to not load the hyperref package</span></div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline">headsepline, <span class="comment">% Uncomment to get a line under the header</span></div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline"><span class="comment"><span class="comment">%chapterinoneline, % Uncomment to place the chapter title next to the number on one line</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline"><span class="comment"><span class="comment">%consistentlayout, % Uncomment to change the layout of the declaration, abstract and acknowledgements pages to match the default layout</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline">]{MastersDoctoralThesis} <span class="comment">% The class file specifying the document structure</span></div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline"><span class="keyword1">\usepackage</span>[utf8]{inputenc} <span class="comment">% Required for inputting international characters</span></div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline"><span class="keyword1">\usepackage</span>[T1]{fontenc} <span class="comment">% Output font encoding for international characters</span></div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline"><span class="keyword1">\usepackage</span>{mathpazo} <span class="comment">% Use the Palatino font by default</span></div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline"><span class="keyword1">\usepackage</span>[backend=bibtex,style=numeric,natbib=true, sorting=none]{biblatex} <span class="comment">% Use the bibtex backend with the authoryear citation style (which resembles APA)</span></div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline">\addbibresource[label=refs]{example.bib} <span class="comment">% The filename of the bibliography</span></div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline">\addbibresource[label=ownpubs]{ownpubs.bib} <span class="comment">% The filename of the bibliography</span></div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline"><span class="keyword1">\usepackage</span>[autostyle=true]{csquotes} <span class="comment">% Required to generate language-dependent quotes in the bibliography</span></div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline"><span class="keyword1">\usepackage</span>{arabxetex}</div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline"><span class="keyword1">\usepackage</span>[printonlyused,withpage]{acronym}</div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline"><span class="keyword1">\usepackage</span>{algorithmic}</div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline"><span class="keyword1">\usepackage</span>{adjustbox}</div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline"><span class="keyword1">\usepackage</span>{caption}</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline"><span class="keyword1">\usepackage</span>{subcaption}</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{subfig}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline"><span class="comment"><span class="comment">%	MARGIN SETTINGS</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline">\geometry{</div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline">	paper=a4paper, <span class="comment">% Change to letterpaper for US letter</span></div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">	inner=2.5cm, <span class="comment">% Inner margin</span></div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline">	outer=3.8cm, <span class="comment">% Outer margin</span></div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline">	bindingoffset=.5cm, <span class="comment">% Binding offset</span></div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline">	top=1.5cm, <span class="comment">% Top margin</span></div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline">	bottom=1.5cm, <span class="comment">% Bottom margin</span></div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline">	<span class="comment">%showframe, % Uncomment to show how the type block is set on the page</span></div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline">}</div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline"><span class="comment"><span class="comment">%	THESIS INFORMATION</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline">\thesistitle{Automated detection of COVID-19 cases in digital medical images using deep learning approaches} <span class="comment">% Your thesis title, this is used in the title and abstract, print it elsewhere with \ttitle</span></div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">\supervisor{} <span class="comment">% Your supervisor's name, this is used in the title page, print it elsewhere with \supname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline">\examiner{} <span class="comment">% Your examiner's name, this is not currently used anywhere in the template, print it elsewhere with \examname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">\degree{Master of Science} <span class="comment">% Your degree name, this is used in the title page and abstract, print it elsewhere with \degreename</span></div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline">\author{Mahmoud Z. Fetoh} <span class="comment">% Your name, this is used in the title page and abstract, print it elsewhere with \authorname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline">\addresses{} <span class="comment">% Your address, this is not currently used anywhere in the template, print it elsewhere with \addressname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline">\subject{Information Technology} <span class="comment">% Your subject area, this is not currently used anywhere in the template, print it elsewhere with \subjectname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline">\keywords{ } <span class="comment">% Keywords for your thesis, this is not currently used anywhere in the template, print it elsewhere with \keywordnames</span></div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline">\university{Menofia University} <span class="comment">% Your university's name and URL, this is used in the title page and abstract, print it elsewhere with \univname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline">\department{Information Technology} <span class="comment">% Your department's name and URL, this is used in the title page and abstract, print it elsewhere with \deptname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline">\group{  } <span class="comment">% Your research group's name and URL, this is used in the title page, print it elsewhere with \groupname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline">\faculty{Faculty of computers and information} <span class="comment">% Your faculty's name and URL, this is used in the title page and abstract, print it elsewhere with \facname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline"><span class="keyword2">\begin{document}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline">\frontmatter <span class="comment">% Use roman page numbering style (i, ii, iii, iv...) for the pre-content pages</span></div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline">\pagestyle{plain} <span class="comment">% Default to the plain heading style until the thesis style is called for the body content</span></div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline"><span class="keyword2">\begin{abstract}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline">\addchaptertocentry{\abstractname} <span class="comment">% Add the abstract to the table of contents</span></div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">COVID-19 is a severe respiratory tract infections. COVID-19 caused by SARS-CoV-2 can readily spread through a contact with an infected person. Monotonically increasing SARS-CoV-2 infections have not only wasted lives but also severely damaged the financial systems of both developing and developed countries. This high spread rate pressure on the health care systems which rise the need to fast methods for diagnosing this disease. Convolutional Neural Networks (CNN) show a great success for various computer vision tasks. However, CNN is a scale-variant model and computationally expensive. In this Thesis, a novel architectures are proposed for multiscale feature extraction and classification and lightweight architecture for COVID-19 diagnosing. The proposed I which is a lightweight CNN model exploits spatial kernel separability to reduce the number of the training parameters to a large extent and regularize the model to only learns linear kernel. Furthermore, This model uses residual connection and batch normalization extensively to maintain the network stability during the training process and provide the model with the regularization effect to reduce the overfitting. Proposed CNN II learns multiscale features using a pyramid of shared convolution kernels with different atrous rates. This scale invariant CNN uses attention based mechanism that is used to guide and select correct scale for each input. Proposed CNN II is an end-to-end trainable network and exploit a novel augmentation technique, Texture Augmentation, to reduce the overfitting. The lightweight architecture is trained using QaTa-Cov19 benchmark dataset achieving  100\% for accuracy, sensitivity, precision and F1-score with a very low parameter count (150K) compared with the other methods in the literature.  Proposed method II achieved a 0.9929 for $F1-score$ tested on QaTa-Cov19 benchmark dataset with a total of $5,040,571$ trainable parameters.</div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline"><span class="keyword2">\end{abstract}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline">\mainmatter <span class="comment">% Begin numeric (1,2,3...) page numbering</span></div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline">\pagestyle{thesis} <span class="comment">% Return the page headers back to the "thesis" style</span></div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline"><span class="comment"><span class="comment">% \include{Chapters/Chapter1_intro.tex}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline"><span class="comment"><span class="comment">% \include{Chapters/Chapter2_Backgr.tex} </span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline"><span class="comment"><span class="comment">% \include{Chapters/Chapter3_Related.tex}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline">\include{Chapters/Chapter4_proposed.tex} </div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline">\include{Chapters/Chapter4_proposed2.tex} </div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline">\include{Chapters/Chapter5_Experment.tex}</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline">\include{Chapters/Chapter6_Conc.tex}</div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline"><span class="comment"><span class="comment">% \nocite{zaki2021covid} </span></span></div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline"><span class="comment"><span class="comment">% \nocite{zaki2022covid} </span></span></div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline"><span class="comment"><span class="comment">% \printbibheading[heading=bibintoc]</span></span></div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline"><span class="comment"><span class="comment">% \printbibliography[keyword={publ}, heading=subbibliography, title={Publications}]</span></span></div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline"><span class="comment"><span class="comment">% \printbibliography[title={References}]</span></span></div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline"><span class="comment"><span class="comment">% \appendix % Cue to tell LaTeX that the following "chapters" are Appendices</span></span></div><div class="clear"></div>
<div class="linenb">108</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">109</div><div class="codeline"><span class="comment"><span class="comment">% \include{Chapters/ArabSummery.tex}</span></span></div><div class="clear"></div>
<div class="linenb">110</div><div class="codeline"><span class="comment"><span class="comment">% \include{Chapters/ArabAbst.tex}</span></span></div><div class="clear"></div>
<div class="linenb">111</div><div class="codeline"><span class="comment"><span class="comment">% \include{Chapters/ArabCV.tex}</span></span></div><div class="clear"></div>
<div class="linenb">112</div><div class="codeline"><span class="keyword2">\end{document}</span>  </div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/Chapter4_proposed.tex</h2>

<p>Found 4 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 148 words). You should consider merging it with another section or make it longer. [sh:seclen]">chapter</span>{Proposed Methodology I} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:proposed1} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use~\ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">In this chapter, a novel architecture is introduced for detecting COVID-19 that is designed to be lightweight. The architecture is based on two key components: spatial kernel separability and residual connection. By exploiting spatial kernel separability, the number of training parameters is significantly reduced, making the model more computationally efficient. Additionally, residual connections are used extensively to maintain network stability during the training process and to provide the model with regularization effects that reduce overfitting. This combination of spatial kernel separability and residual connections creates a lightweight architecture that is highly effective at detecting COVID-19. Overall, this chapter provides a valuable contribution to the field of COVID-19 detection by introducing a novel and efficient architecture that can help to identify the disease quickly and accurately. </div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[th]</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[height=40mm,width=8.0cm]{Figures/fig1.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline">    <span class="comment">% \decoRule</span></div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">    <span class="keyword1">\caption</span>{The phases of the proposed method I.}</div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline">    <span class="keyword1">\label</span>{fig1}</div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline">    <span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline"><span class="keyword1">\section</span>{Methodology I}</div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline">In this section, a  proposed  method I to detect COVID-19 disease from chest X-Ray images is presented. The proposed method exploits CNN model to classify the input chest X-Ray image to one of two categories; normal case or Covid-19 case. The proposed  method I consists of three phases: preprocessing, feature extraction, and classification. The proposed method phases are shown in Fig.~\ref{fig1}. </div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline"><span class="keyword1">\subsection</span>{Preprocessing Phase}</div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline">The preprocessing phase is responsible for resizing and normalizing the  input  chest X-Ray images. The pre-processing phase is employed to maintain the numerical stability of the model and reduce the co-variance shift~\cite{lecun1989handwritten}. In addition, this phase leads the learning model of CNN model to reduce  the required overhead to adapt to the different scales of different features of the input data. Reshaping size is determined empirically. The input chest X-Ray image is re-sized and then adapted and normalized to a normal distribution as follows:</div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline">Y := \frac{x_i - \mu_{\mathcal B}}{\sqrt{\sigma_{\mathcal B}^2 + \epsilon}}</div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline"><span class="keyword1">\label</span>{eq1}</div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline">where $\mu$ and $\sigma$ is the mean and standard deviation of chest X-Ray image (X), respectively.</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline">After re-sizing the input chest X-Ray image, the input image is normalized to have a zero mean and unit standard deviation. Then,  the image can be scaled and shifted with a normalization parameter which is determined and adapted by the training dataset during the training process according to the following equation: </div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline">Z := w_1 Y + w_2</div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline"><span class="keyword1">\label</span>{eq2}</div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline">where $w_1$ and $w_2$ are a trainable parameter.</div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline">Unlike the  normalization method presented in~\cite{ioffe2015batch}, the batch normalization process presented in this paper has $z$-score normalization parameter that is used in both training and validation phases.</div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline"><span class="keyword1">\subsection</span>{Feature Extraction and Classification}</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline">CNN models achieved an outstanding success in image recognition~\cite{lecun2015deep}. This phase  is responsible for extracting spatial features from the normalized chest X-Ray image using a tailored CNN model.  This phase is based on learning the CNN model by the input preprocessed chest X-Ray images. The design of the tailored CNN model is described as follows: </div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Separable CNN kernels}</div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline"><span class="keyword2">\begin{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline"><span class="keyword1">\includegraphics</span>[height=33mm,width=14.0cm]{Figures/fig2.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline"><span class="keyword1">\caption</span>{Separable convolution  $Gy$ and $Gx$ have kernel size of $M\times1$ and $1 \times M$. The combination of these kernels is approximately a $M\times M$ kernel  and depth wise convolution are applied by a $1\times1$ convolution. The output depth  is padded with zeros to have the same spatial size of  $Gy, Gx$. $Gy, Gx$ are performed channel wise. }</div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline"><span class="highlight-sh" title="This figure is missing a label [sh:figref]">\</span>label{fig2}<span class="keyword2">\end{center}</span><span class="keyword2">\end{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline">    </div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline">Kernel separability~\cite{rigamonti2013learning}~\cite{szegedy2017inception} is based on decomposing a 2D convolution kernel to linear combinations of two 1D vectors which leads to a large reduction in  the total number of resulting parameters. For example, a 2D kernel of size $9 \times 9$ has a total number of $9^2 = 81$  trained parameters. Whereas in the case of separating this 2D kernel to  linear combinations of two 1D vectors of sizes $9 \times 1$ and $1 \times 9$, this results in a total number of  $9 + 9 = 18$ trained parameters. As a consequence, kernel separability reduces the number of CNN model operations (such as the multiplication and the addition). A  2D kernel of $k \times k$ applied for 2D signal with spatial dimensions of $ M \times N$ has a total number of  $(N-4)(M-4)\times k^2$ operations but in case of  applying kernel separability  yields $2(N-4)(M-4)k$ operations. The flow of separated convolution operations are summarized in Fig.~\ref{fig2}. Fig.~\ref{fig3} represents the structure, denoted by Separated Convolutional Layer, used in the proposed method with kernel size of $(M\times N)$ and satisfying the convolutional kernel separability. Separated Convolutional Layer is composed of three consecutive layers. The first convolutional layer has a kernel size of $(M\times1)$ and the number of convolutional neuron and  filters are equal to the number of channels as the input feature map and the convolution operations are performed in a channel wise. The second layer  operates in the same way as the first layer but it has a kernel of size $(1\times M)$. The third layer is the convolutional layer with kernel of size $(1\times1)$ and number of convolutional neuron is $N$. The collaboration of the three layers are  connected to preform similarly to the convolutional layer with kernel size of $(M\times M)$ and number of neuron and filter are the same as $N$ but with large difference in the performance.</div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[height=34mm,width=7.0cm]{Figures/fig3.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Separated Convolutional Layer</span>}{ composed of three consecutive layers. The first Convolutional layer has a kernel size of $(M\times1)$ and $D$  convolutional neuron. The second layer  operates in the same way as the first layer but it has a kernel of size $(1\times M)$ and $D$ convolutional neuron. The third layer is the convolutional layer with kernel of size $(1\times1)$ and number of convolutional neuron is $N$.}</div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline">    <span class="keyword1">\label</span>{fig3}</div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline">    <span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline"><span class="keyword1">\subsubsection</span>{ Batch Normalization and  Activation function}</div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline">In the proposed method linear separable convolutional kernels are followed by a batch normalization and an activation function. Rectified Linear Unit (ReLU)~\cite{he2015delving} is a nonlinear activation that allows the network to fit and approximate highly non-linear datasets distribution. The proposed method employs the batch normalization which is described in~\cite{ioffe2015batch}. </div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline">Batch Normalization~\cite{ioffe2015batch} reduces internal covariate shift produced as a result of  moving between layers during the feedforward procedure~\cite{ioffe2015batch}. Batch Normalization makes the loss landscape smoother and reduces the number of saddle points~\cite{santurkar2018does} which allows to use higher learning rates. Using a higher learning rate makes the network training  faster~\cite{ioffe2015batch}. Batch normalization reduces the vanishing gradient problem and exploding gradient problem as it makes the resulted activation scale independent from the trainable parameter scale~\cite{ioffe2015batch}. Batch normalization has the effect of regularization because of the inherited randomness when selecting the batch sample~\cite{ioffe2015batch} which help the generalization to unseen chest X-Ray image.</div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline"><span class="keyword1">\subsubsection</span>{ Deep and larger receptive field Network design}</div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline">Deeper convolutional neural network design is a very important task for any image recognition task~\cite{he2016deep}. Training a deeper network is very expensive and has many challenges such as vanishing gradient problem, exploding gradient problem, and degradation problem~\cite{he2016deep}. Exploding gradient problem occurs  when the  gradient update becomes very large (approaching infinity) resulting in the network diversion. Vanishing gradient problem occurs when the  gradient update becomes very small (approaching zero) resulting in preventing the parameter update for early layers~\cite{ioffe2015batch} and preventing the network to learn new patterns. Batch normalization~\cite{ioffe2015batch} and the use of ReLU activation function~\cite{krizhevsky2012imagenet} alleviate these two problems.</div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline">The deep layers of CNN networks sometimes need to  approximate the identity function which is not a simple task especially  with the existence of a non-linear functions. Residual connection~\cite{he2016deep} overcomes this problem by using skip connection as shown in Fig.~\ref{fig4}.</div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">Fig.~\ref{fig4} represents the building block layer of the feature extraction phase, denoted by stack of Residual Separated Block  (RSB). RSB consists of four layers of separated convolutional layers, each layer is followed by a batch normalization and an activation function. It has an output of depth $N$ where each sublayer produces an output of depth $N/4$ which is concatenated at the end of the layer to produce a depth  $N$. RSB produces a feature map that includes both low level features and high level features.</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline"><span class="keyword2">\begin{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline"><span class="keyword1">\includegraphics</span>[height=38mm,width=14.0cm]{Figures/fig4.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline"><span class="keyword1">\caption</span>{The stack of residual separated block  (RSB) consists of four layer of separated convolutional layer each of which is followed by batch normalization and activation function.}</div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline"><span class="keyword1">\label</span>{fig4}</div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline"><span class="keyword2">\end{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline"><span class="keyword2">\begin{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[height=37mm,width=14.0cm]{Figures/fig5.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">    <span class="keyword1">\caption</span>{The complete proposed tailored CNN architecture.}</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline">    <span class="keyword1">\label</span>{fig5}</div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline">    <span class="keyword2">\end{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">    </div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline">Unlike the traditional neural network, which is fully connected to the previous layer, convolutional neural network is connected locally to a local region of the previous feature map. This introduces the concept of the network receptive field~\cite{luo2016understanding}. Receptive field should be large enough to capture large patterns in the input chest X-Ray image. Therefore, any consecutive convolutional layers in the proposed method without a pooling layer in between a larger kernel size is used in one of them. Residual Separated block, RSB, in Fig.~\ref{fig4} may have kernel sizes of 3, 5, 7, and 9, respectively.<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline">Fig.~\ref{fig5} Represent a complete CNN architecture.</div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline"><span class="keyword1">\section</span>{Summary}</div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline"><span class="comment"><span class="comment">% In this chapter a lightweight CNN architecture is proposed for COVID19 detection. Proposed architecture is based on spatial separability of the convolutional kernel to enforce the learning of linear kernels. The proposed architecture consists of separated kernels convolutional layers that is connected by a residual connection. The proposed architecture uses batch normalization to maintain the network stability during the training process.</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline"><span class="comment"><span class="comment">% In this chapter, a novel lightweight CNN architecture is proposed for COVID-19 detection that is based on the concept of spatial kernel separability. The proposed architecture is designed to reduce the number of training parameters and improve computational efficiency by exploiting the separability of convolutional kernels. By learning linear kernels, the model can perform faster and more accurately on the given dataset. The proposed architecture includes separated kernel convolutional layers that are connected by a residual connection, which helps maintain network stability during training. Additionally, the proposed architecture utilizes batch normalization, a technique that helps to standardize the inputs of each layer and improve the convergence rate of the model. By combining these techniques, the proposed architecture offers a lightweight, efficient, and accurate method for detecting COVID-19.</span></span></div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline">In this chapter, the proposed lightweight CNN architecture for COVID-19 detection is designed with the concept of spatial separability in mind. The spatial separability of the convolutional kernel is used to enforce the learning of linear kernels, which reduces the number of training parameters and improves computational efficiency. Essentially, the model is designed to recognize patterns in the data that are linearly separable, which enables the use of simpler and more efficient models.</div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline">The proposed architecture comprises of separated kernel convolutional layers that are connected by a residual connection. The use of separated kernel convolutional layers helps to reduce the number of training parameters, while the residual connection improves network stability during the training process. The residual connection enables the model to retain important features while also discarding unimportant ones, which helps prevent overfitting.</div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline">Batch normalization is used in the proposed architecture to maintain network stability during the training process. The technique standardizes the inputs of each layer, which improves the convergence rate of the model. This is done by normalizing the layer inputs to have zero mean and unit variance, which helps prevent internal covariate shift. Internal covariate shift refers to the change in the distribution of network activations that occurs during training, which can slow down the convergence rate.</div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline">In summary, the proposed lightweight CNN architecture for COVID-19 detection is based on the spatial separability of the convolutional kernel, with separated kernel convolutional layers connected by a residual connection. Batch normalization is used to maintain network stability during training, which improves the convergence rate of the model. By combining these techniques, the proposed architecture offers an efficient, accurate, and stable method for detecting COVID-19.</div><div class="clear"></div>
</div>
<hr/>
Output produced by TeXtidote v0.8.2, &copy; 2018-2020 Sylvain Hall&eacute; - All rights reserved.<br/>
See the <a href="https://sylvainhalle.github.io/textidote">TeXtidote website</a> for more information.
</body>
</html>
