<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>TeXtidote analysis</title>
<style type="text/css">
body {
  font-family: sans-serif;
}
.highlight, .highlight-sh, .highlight-spelling {
  padding: 2pt;
  border-radius: 4pt;
  cursor: help;
  opacity: 0.7;
  border: dashed 1px;
}
.highlight {
  background-color: orange;
  color: black;
}
.highlight-sh {
  background-color: yellow;
  color: black;
}
.highlight-spelling {
  background-color: red;
  color: white;
}
div.original-file {
  font-family: monospace;
  font-size: 11pt;
  background-color: #f8f8ff;
  padding: 20pt;
  border-radius: 6pt;
}
.textidote {
  	background-image: url(data:image/svg+xml;base64,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);
}
h2.filename {
  font-family: monospace;
}
h1.textidote {
  width: 378px;
  height: 68px;
  display: block;
}
.keyword1 {
  font-weight: bold;
  color: green;
}
.keyword2 {
  font-weight: bold;
  color: darkblue;
}
.comment, .comment * {
  color: darkred;
  font-weight: normal;
}
.linenb {
  font-style: italic;
  color: lightgrey;
  width: 30pt;
  float: left;
  margin-top: 1pt;
  margin-bottom: 1pt;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.codeline {
  margin-left: -30pt;
  padding-left: 60pt;
  margin-top: 1pt;
  margin-bottom: 1pt;
}
.no-text {
  display: none;
}
.clear {
  clear: both;
}
</style>
</head>
<body>
<a href="https://sylvainhalle.github.io/textidote"><h1 class="textidote"><span class="no-text">Results of TeXtidote analysis</span></h1></a>
<p>Here is the result of analyzing your file(s) with TeXtidote. Hover the mouse over highlighted portions of the document to read a tooltip that gives you some writing advice.</p>
<h2 class="filename">./Chapters/Chapter3_Related.tex</h2>

<p>Found 16 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 89 words). You should consider merging it with another section or make it longer. [sh:seclen]">chapter</span>{Literature Review} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:related} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline">CNN outperformed traditional computer vision approaches for medical image classification due to its current advances on architecture design. Typically, CNN architectures are composed of two parts~\cite{krizhevsky2012imagenet}. First part is called a convolutional part which further consists of  convolutional layers interconnected with some connection patterns that are responsible for feature extraction. Second part is the fully connected layers which consist of Dense layers that are responsible for classification. This section discusses previous CNN based CXR classification systems  reporting the modeling mechanisms and the reported results.</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline"><span class="keyword1">\section</span>{CNN Based Models}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline">In this section CNN base models for covid detection is reviewed.</div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline"><span class="keyword1">\subsection</span>{Reliable COVID-19 Detection Using Chest X-ray Images}</div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/RltDag.png}</div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline">        <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{rlt:dag} ReCovNet model proposed by~\cite{dag}. It uses pretrained encoder for classification of COVID-19 CXR image</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline"><span class="highlight-sh" title="Do not use 'In [X]': the syntax of a sentence should not be changed by the removal of a citation. [sh:c:noin]">In \cite{</span>dag}, authors have adapted transfer learning techniques to train CNN models. Training is performed through two phases. Fig.~\ref{rlt:dag} represent proposed system <span class="highlight-sh" title="Do not use 'by [X]': the syntax of a sentence should not be changed by the removal of a citation. [sh:c:noin]">by \cite{</span>dag}. In phase I, u-shaped architecture is excluded by removing the skip connections, which performs the concatenation operation. The reason for constructing an encoder-decoder network without skip connections is that the contributions from the initial layers are avoided; therefore, the network can make decisions from the high level features that are closer to segmentation mapping of the input image.  In phase II, Decoder network is discarded, and the encoder network is fine-tuned for the binary classification task. Adam optimizer is used to train their network. Model is trained with QaTa-COV19 dataset. The method achieved a performance of 98.57\% for sensitivity and 99.77\%  for specificity.</div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 81 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span>{Advance Warning Methodologies for</div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline">COVID-19 Using Chest X-Ray Images}</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline"><span class="comment"><span class="comment">% In \cite{ar}, authors have proposed Convolutional Support Estimator Networks (CSENs) classifier. CSEN is used to classify features extracted by DenseNet-121. DenseNet-121 is pre-trained using ImageNet Dataset then fine-tuned using QaTa-Cov19. CSEN achieved 97\% of sensitivity and over 95.5\% of specificity. Authors also evaluated DenseNet-121 achieving 95\% of  sensitivity and 99.74\% of specificity.</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline"><span class="highlight-sh" title="Do not use 'In [X]': the syntax of a sentence should not be changed by the removal of a citation. [sh:c:noin]">In \cite{</span>ar}, authors evaluated the performance of different classifier for classifying the feature produced by DenseNet121. Their methedology is as follows:</div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Feature Extraction using DensNet121}</div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline">They pretrained two DenseNet121~\cite{huang2017densely} models on Early-QaTa-COV19 and ChestX-ray14 datasets are used to extract 1024-D feature vectors by taking the output after global pooling just before the classification layer. Then, a dimensionality reduction is applied over the calculated features with principal component analysis (PCA) by choosing the first $512$ principal components.</div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Representation-based classification}</div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline"> Representation-based classification (RC) techniques are used in many different classification tasks such as face recognition in~\cite{wright2010sparse}, hyperspectral image classification~\cite{li2016survey}, and human action recognition~\cite{guha2011learning}. Authors classified the feature vector produced by DenseNet121 using either Sparse RC or Collaborative RC. It is performed as follows:</div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline"> <span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline">    <span class="keyword2">\begin{split}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline">        \hat{x} = \arg \min_{x}(\lambda \vert \vert x \vert\vert_{1} + \vert\vert y - Dx \vert\vert_{2})</div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline">    <span class="keyword2">\end{split}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline">where $D$ is the dictionary of feature produced by DenseNet121 and projected using PCA. Sparse RC minimizes $\ell^{1}$ of $\hat{x}$. While Collaborative RC minimizes $\ell^{2}$ of $\hat{x}$ as follows:</div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline">    <span class="keyword2">\begin{split}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline">        \hat{x} = \arg \min_{x}(\lambda \vert \vert x \vert\vert_{2} + \vert\vert y - Dx \vert\vert_{2})</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">    <span class="keyword2">\end{split}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline">For both types of representations $\hat{x}$ reconstruction error is calculated as follows:</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline">    <span class="keyword2">\begin{split}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline">        e_i = \vert\vert y - D\hat{x} \vert\vert_2</div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline">    <span class="keyword2">\end{split}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline">Then assign a class of the lower construction error as follows:</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline">    <span class="keyword2">\begin{split}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">        class(y) \arg \min(e_i)</div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline">    <span class="keyword2">\end{split}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline">Fig.~\ref{fig:RC} represent representation classification pipeline presented in~\cite{ar}. They achieved a $.98$ and $.97$ of accuracy for Sparse Representation-based classification and Collaborative Representation-based classification, respectively. </div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/RCpipline.png}</div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{fig:RC} sparse and Collaborative Representation learning pipeline of~\cite{ar}</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline">Authors of~\cite{ar} also evaluated SVM for classifying features produces by DenseNet121 and recorded $.98$ of accuarcy.</div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline"><span class="comment"><span class="comment">%  <span class="keyword2">\begin{algorithm}</span>[H]</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline"><span class="comment"><span class="comment">%     \DontPrintSemicolon</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline"><span class="comment"><span class="comment">%     <span class="keyword1">\caption</span>{Sparse Representation-based Classification (SRC)}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline"><span class="comment"><span class="comment">%     \KwIn{a matrix of training samples $A = [A_{1}, A_{2}, \dots ,A_{k}] \in \mathbb{R}^{m \times n}$ </span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline"><span class="comment"><span class="comment">%       for $k$ classes, a test sample $\mathbf{y} \in \mathbb{R}^{m}$, (and an optional error tolerance $\varepsilon &gt; 0$).}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline"><span class="comment"><span class="comment">%     Normalize the columns of $A$ to have unit $\ell^{2}$-norm.\;</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline"><span class="comment"><span class="comment">%     Solve the $\ell^{1}$-minimization problem:</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline"><span class="comment"><span class="comment">%     $\hat{\bm{x}}_{1} = \arg \min_{x}\norm{\bm{x}}_{1}\quad \text{subject to}\quad A\bm{x} = \bm{y}$ \;</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline"><span class="comment"><span class="comment">%     (Or alternatively, solve</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline"><span class="comment"><span class="comment">%     $\hat{\bm{x}}_{1} = \arg \min_{x}\norm{\bm{x}}_{1}\quad \text{subject to}\quad \norm{A\bm{x} = \bm{y}}_{2} \leqslant \varepsilon$).\;</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline"><span class="comment"><span class="comment">%     Compute the residuals $r_{i}(\bm{y}) = \norm{\bm{y} - A \delta_{i}(\hat{\bm{x}}_{1})}_{2}$\;</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline"><span class="comment"><span class="comment">%     \For{$i = 1,\dots,k$}{something}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline"><span class="comment"><span class="comment">%   <span class="keyword2">\end{algorithm}</span></span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">  </div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline"><span class="keyword1">\subsection</span>{COVID-19 Detection Using DL Algorithm on CXR Images}</div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline">In~\cite{akt}, authors proposed a modified MobileNetV2 CNN model where the stander convolution is replaced by a depth-wise convolution. Their model is trained with $3616$ COVID-19 CXR images and 10,192 normal CXR images. Dataset is initially preprocessed by reshaping input images to $299\times299$ and image enhancement technique is applied. The model achieved an accuracy of 98\% for binary classification task. Fig.~\ref{fig:akterPipeline} illustrates general pipeline proposed by~\cite{akt} which is detailed as follows:</div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/AkterPipeline.png}</div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline">        <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{fig:akterPipeline} Pipeline proposed in~\cite{akt} for COVID-19 classification</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline">Preprocessing phase of~\cite{akt} initially performs image augmentations which includes horizontal flip, rotation, width shift and height shift on all the extracted data from the original dataset. Also, image enhancement applied Histogram equalization, Spectrum, Grays and Cyan. The N-CLAHE algorithm was then used to normalize pictures and highlight smaller features for machine learning classifiers to notice. Thereafter, the images were resized to the classifier?s standard resolution. After resizing the picture, the machine learning classifier used the enhanced (52,000) images in a ratio of 80\% data for training, whereas 20\% was used for testing. They proposed modified MobileNetV2 network and achieved 98\% of accuracy</div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline"><span class="highlight-sh" title="Do not use 'In [X]': the syntax of a sentence should not be changed by the removal of a citation. [sh:c:noin]">In \cite{</span>hyp} authors have proposed a hybrid model for multilabel classification where VGG16 is used as a feature extractor. Their system is trained by a combined dataset of QaTaCov19 and Chest X-Ray achieving accuracy of $91.09$\%.</div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">\<span class="highlight-sh" title="If a section has sub-sections, it should have more than one such sub-section. [sh:nsubdiv]"><span class="highlight-sh" title="This section is very short (about 1 words). You should consider merging it with another section or make it longer. [sh:seclen]"><span class="highlight-sh" title="This section is very short (about 2 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span></span></span>{Traditional Computer Vision Models}</div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline">\<span class="highlight-sh" title="Avoid stacked headings, i.e. consecutive headings without text in between. [sh:stacked]">subsection</span>{ COVID-19 detection in CXR images using</div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">majority voting based classifier ensemble}</div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline">In~\cite{acos}, authors proposed a two phases COVID-19 multi-label classification system as illustrated in Fig.~\ref{fig:Acos}. The system phase I classifies the input CXR images as normal or COVID-19. In case the image  is classified as COVID-19, phase II further classifies this image as pneumonia or COVID-19. Phase I and Phase II have the same structure with a total of $8196$  local features are extracted then classified using ensemble module. Base classifier of the ensemble module consist of NB, ANN, DT and SVM. A majority voting is used to combine the predictions of these classifiers. Their system achieved accuracy of $98.062$\%  and $91.329$\% for Phase I and Phase II, respectively. Both Phases have same anatomy of preprocessing and feature Description.</div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/ACoS.png}</div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline">        <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{fig:Acos} Proposed machine learning pipeline of~\cite{acos}</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline">Feature extraction is performed by extracting a total of 8196 features as follows:</div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline">    <span class="keyword1">\item</span> 8 features using FOSF~\cite{srinivasan2008statistical}.</div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline">    <span class="keyword1">\item</span> 88 feature using GLCM~\cite{gomez2012analysis}.</div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline">    <span class="keyword1">\item</span> 8100 feature using HOG~\cite{dalal2005histograms}.</div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline">binary grey wolf optimization (BGWO)~\cite{mirjalili2014grey} is to select the most relavant features from the previously extacted features. The final prediction of the set is the majority vote of seven benchmark classifiers (ANN, KNN, NB, DT, SVM (linear kernel, radial basis function (RBF) kernel, and polynomial kernel).</div><div class="clear"></div>
<div class="linenb">108</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">109</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">110</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">111</div><div class="codeline">\input{Tables/relatedlatex.tex}</div><div class="clear"></div>
<div class="linenb">112</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">113</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 140 words). You should consider merging it with another section or make it longer. [sh:seclen]"><span class="highlight-sh" title="This section is very short (about 140 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span></span>{Summary}</div><div class="clear"></div>
<div class="linenb">114</div><div class="codeline">CNN is a powerful computer vision model. It used intensively for COVID-19 detection. Table~\ref{tbl:related} summarizes recent related work for COVID-19 detection. Despite the high accuracy of current CNN based CXR classification methods, but these methods don't address the problem that CNN is scale variant model. This problem hinders the recognition of large scale COVID-19 pneumonia. In this thesis, a novel scale-invariant CNN architecture is proposed for classification of COVID-19 pneumonia. The proposed architecture deploys Atrous convolution method for learning the scale-invariant features. Then, an attention model is utilized to automatically and internally select at which scale  CNN should consider and ignore other scales. The proposed architecture exploits texture augmentation to reduce the overfitting and artificially enlarge the training dataset. The experimental results show that proposed system outperforms  the previous  CNN based CXR classification methods  with lower trainable parameter number.</div><div class="clear"></div>
<div class="linenb">115</div><div class="codeline">&nbsp;</div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/ArabCV.tex</h2>

<p>Found 1 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;2</div><div class="codeline"><span class="keyword2">\begin{arab}</span>[utf]</div><div class="clear"></div>
<div class="linenb">&nbsp;3</div><div class="codeline">\chapter*{\textarab[utf]{?????? ??????? ????? ???????}} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;4</div><div class="codeline">\addchaptertocentry{\textarab[utf]{?????? ??????? ????? ???????}}</div><div class="clear"></div>
<div class="linenb">&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{aracv} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;6</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;7</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;8</div><div class="codeline"><span class="comment"><span class="comment">% \textarab[utf]{ ??????? }</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;9</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">10</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">11</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{???????}}: \textarab[utf]{ ???? ???? ????????? ????????? }</div><div class="clear"></div>
<div class="linenb">12</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{??? ?????}}: \textarab[utf]{ ???? ???????? ?????????? ? ????? ???????? }</div><div class="clear"></div>
<div class="linenb">13</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ???????}}: \textarab[utf]{2 / ?????? / 1997}</div><div class="clear"></div>
<div class="linenb">14</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{ ???????<span class="highlight-sh" title="There should not be a space before a punctuation mark. If in your language, typographic rules require a space here, LaTeX takes care of inserting it without your intervention. [sh:d:005]"> }}:</span> \textarab[utf]{???? - ???? ???? - ?????? ???????}</div><div class="clear"></div>
<div class="linenb">15</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{?????? ???????}}: \textarab[utf]{????????? ???????? ?????????? ???? ????????? ?????????}</div><div class="clear"></div>
<div class="linenb">16</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{???????}}: \textarab[utf]{?????? ?? ????? ?????}</div><div class="clear"></div>
<div class="linenb">17</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{??? ??? ?????? ???????}}: \textarab[utf]{???? ???????? ?????????? ? ????? ????????}</div><div class="clear"></div>
<div class="linenb">18</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ??????}}: \textarab[utf]{???? 2019}</div><div class="clear"></div>
<div class="linenb">19</div><div class="codeline">    <span class="comment">% <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ??????? ????? ?????????}}: \textarab[utf]{2021/ ????? /25}%????/?/??</span></div><div class="clear"></div>
<div class="linenb">20</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ??????? ????? ?????????}}: \textarab[utf]{25 / ?????? / 2021}<span class="comment">%????/?/??</span></div><div class="clear"></div>
<div class="linenb">21</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">22</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">23</div><div class="codeline"><span class="keyword2">\end{arab}</span></div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/Chapter2_Backgr.tex</h2>

<p>Found 26 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 21 words). You should consider merging it with another section or make it longer. [sh:seclen]">chapter</span>{Background} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:background} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use~\ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline">This chapter includes required background to understand the thesis proposal presented in the following chapters.</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline">\<span class="highlight-sh" title="If a section has sub-sections, it should have more than one such sub-section. [sh:nsubdiv]"><span class="highlight-sh" title="This section is very short (about 145 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span></span>{Convolutional Neural Networks (CNN)}</div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline">CNN is initially introduced by LeCun \cite{lecun1989handwritten} which is based on learning adaptive convolutional kernels. CNN consist of two parts convbase and densebase parts. For the Convbase instead of connecting all of the units in a layer to all the units in a preceding layer, convolutional networks organize each layer into feature maps \cite{lecun1989handwritten}, which</div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">can be though of as parallel planes or channels. In a convolutional layer, the weighted sums are only performed within a small local window<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="keyword1">\textit</span>{i.e)}</span> receptive field, and weights are identical for all pixels, just as in regular shift-invariant image convolution and correlation. This parameter sharing reduce the required total number of parameter and allows learning shift invariant convolutional kernels. These convolutional kernels produce equivariant features maps. Fig.~\ref{lenet} represents typical CNN architecture of LeNet.</div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/LeNetCNN.jpeg}</div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline">        <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Typical CNN architecture</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline">        <span class="keyword1">\label</span>{lenet}</div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline"><span class="keyword1">\subsection</span>{Convolutional Layer}</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline">The building block of the convolutional layer is the 2D convolutional kernel. Fig.~\ref{conv2Dlayer} illustrates the 2D convolutional layer. Each 2D convolution kernel takes as input all of the $C_{i-1}$ channels in the preceding layer, windowed to a small area, and produces the values in one of the $C_{i}$ channels in the next layer. For each of the output channels, we have $K^2\times C_{i-1}$ kernel weights, so the total number of learnable parameters in each convolutional layer is $K^2\times C_{i-1} \times C_{i}$. In Fig.~\ref{conv2Dlayer}, we have $C_{i-1} = 6$ input channels and $C_{i} = 4$ output channels, with an $K = 3$ convolution window, for a total of $9 \times 6 \times 4$ learnable weights, shown in the middle column of the figure. Since the convolution is applied at each of the $W \times H$ pixels in a given layer, the amount of computation (multiply-adds) in each forward and backward pass</div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline">over one sample in a given layer is $W\times H \times K^{2} \times C_{i-1} \times C_{i}$.</div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline">To fully determine the behavior of a convolutional layer, we still need to specify the following hyperparameter:</div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Padding.} Padding is used to preserve the spatial dimension of the input feature map after the convolution operation is performed. Typically, it is performed by inserting $\lfloor K/2 \rfloor$ columns for both sides and $\lfloor K/2 \rfloor$ rows to the top and bottom.</div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Stride.} Stride is the step taken between two centers when performing the convolution operation. Typically, Stride is equal to $1$. Stride can act as down sampling operation that can be performed instead of the pooling operation.</div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Dilation.} Dilation is a technique that enlarge the kernel by inserting zeros between its consecutive elements. As a result it covers a larger area of the input without increasing the total number of parameters. Which can be discribed as \[y[i]=\sum_{k}^{K} x[i+r\times k] w[k]\] where $x$ is the input signal, $w$ is the convolutional filter with size of $K$, $y$ is the resultant signal, and $r$ is the dilation rate.</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/2DConvKernels.png}</div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline">        <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Convolutional layer with single input feature map and four convolutional kernels</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline">        <span class="keyword1">\label</span>{conv2Dlayer}</div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">Generally, each convolutional layer computes some activation based on its input and a nonlinear function. Activation function used in each layer have a great effect on the modeling of the problem and also the semantic assigned to the output of some units is affected by this choice. The most important activation functions will be introduced in the following section.</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline"><span class="keyword1">\section</span>{Activation functions}<span class="keyword1">\label</span>{sec:activations}</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline">\centering</div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline"><span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/Actfuncs.png}</div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline"><span class="keyword1">\caption</span>{Some of the most common activation functions: sigmoid, tanh, ReLU and Leaky ReLU. ReLU and Leaky ReLU are overlapping for $z \geq 0$.}</div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline"><span class="keyword1">\label</span>{fig:activations}</div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline">The activation function is one of the most important component of an CNN. To tackle non-linearly separable problems it is imperative to map the input into a space that is linearly separable. The activation function does this by performing an <span class="keyword1">\emph</span>{element-wise nonlinear transformation} of the pre-activation that comes from the linear combination of the convolutional layer.</div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline">The linear combination of the convolutional layer and the nonlinearity work together closely: the latter is usually fixed and does not evolve during training, but maps its input to a highly non-linear space; the former, is determined by the learned weights which is learned during the training process and uses the activation function to map the calculated activation into a new space where they are simpler and easier to separate. It is interesting to point out that $N$ consecutive linear combination is a single linear combination. Activation function breaks this property and low introducing deeper networks.</div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline">In the following subsection common activation function is presented.</div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline"><span class="keyword1">\subsection</span>{Sigmoid}<span class="keyword1">\label</span>{sec:logistic}</div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline">The sigmoid, often called <span class="keyword1">\emph</span>{logistic}, is a differentiable monotonically</div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">increasing function that takes any real-valued number and maps it to $[0, 1]$.</div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline">As illustrates in its representation in Fig.~\ref{fig:activations}, for large</div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline">negative numbers it approaches $0$. However, for large positive numbers it</div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline">approaches to $1$. It is defined as</div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline"><span class="keyword2">\begin{equation}</span><span class="keyword1">\label</span>{eq:logistic}</div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">    logistic(\mathbf{z}) = \frac{1}{1+\exp(-\mathbf{z})}.</div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline">\noindent The logistic function is the most used nonlinearity historically due to its possible interpretation as the firing probability of a neuron given its activation: when the activation is low the neuron fires less often whereas when the activation is high the frequency of the spikes increases.</div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline">Another very important property of the logistic function is that it is a very</div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline">simple and fast derivative computation such as follows:</div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline"><span class="keyword2">\begin{align}</span><span class="keyword1">\label</span>{eq:logistic_derivative}</div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline"><span class="keyword2">\begin{split}</span><span class="comment">% to show one label only</span></div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline">    \frac{\partial}{\partial \mathbf{z}}logistic(\mathbf{z}) &amp;=</div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline">        \frac{\exp(\mathbf{-z})}{\left(1+\exp(-\mathbf{z})\right)^2} ,\\</div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">    &amp;= \frac{1}{1+\exp(-\mathbf{z})} \cdot</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline">        \frac{\exp(-\mathbf{z})}{1+\exp(-\mathbf{z})} ,\\</div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline">    &amp;= logistic(\mathbf{z}) \cdot</div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline">        \frac{\exp(-\mathbf{z})}{1+\exp(-\mathbf{z})} ,\\</div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline">    &amp;= logistic(\mathbf{z}) \cdot</div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline">        \frac{1+\exp(-\mathbf{z})-1}{1+\exp(-\mathbf{z})} ,\\</div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline">    &amp;= logistic(\mathbf{z}) \cdot</div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline">        \left(1-\frac{1}{1+\exp(-\mathbf{z})}\right) ,\\</div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline">    &amp;= logistic(\mathbf{z}) \cdot (1-logistic(\mathbf{z})).</div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline"><span class="keyword2">\end{split}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline"><span class="keyword2">\end{align}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline">It becomes out of favor due to the following major drawbacks:</div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\emph</span>{Saturation region which weaken the gradient propagation:}</div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">        backpropagation algorithm exploits the gradient of the loss function to update the parameters of the network. </div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline">        However, sigmoid have a derivative of zero at both of ends which saturates the training. This problem -- often referred to as~<span class="keyword1">\emph</span>{vanishing gradient problem} -- makes training very slow or prevents it in some cases. As a result sigmoid requires a very careful initialization of the weights of the network.</div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\emph</span>{The output is not zero-centered:} </div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline">    according to \cite{ioffe2015batch} normalized activation (i.e., activation with zeros mean and unit variance) can accelerate the training. However, sigmoid always has non-negative activation as result non zero-center mean which slow down the training.</div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline"><span class="keyword1">\subsection</span>{Hyperbolic tangent (tanh)}<span class="keyword1">\label</span>{sec:tanh}</div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline">The hyperbolic tangent,~<span class="keyword1">\emph</span>{tanh}, is a differentiable monotonically increasing function that maps any real-valued number to $[-1, 1]$. This nonlinearity has the same problems as sigmoid except its activation is zeros-center.</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline"><span class="keyword2">\begin{equation}</span><span class="keyword1">\label</span>{eq:tanh}</div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline">    tanh(\mathbf{z}) = \frac{1-exp(-2\mathbf{z})}{1+exp(-2\mathbf{z})}.</div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline"><span class="keyword1">\subsection</span>{Rectified Linear Unit (ReLU)}<span class="keyword1">\label</span>{sec:relu}</div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline">Rectified Linear Unit (ReLU) is introduced in<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]">~<span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{krizhevsky2012imagenet}.It</span> has become the nonlinearity of choice in many applications~\cite{krizhevsky2012imagenet}\cite</span>{he2016deep}. It is defined as</div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">108</div><div class="codeline"><span class="keyword2">\begin{equation}</span><span class="keyword1">\label</span>{eq:relu}</div><div class="clear"></div>
<div class="linenb">109</div><div class="codeline">    relu(\mathbf{z}) = max(0, \mathbf{z}).</div><div class="clear"></div>
<div class="linenb">110</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">111</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">112</div><div class="codeline">Although very simple, it has some very interesting propertie<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">s\cite</span>{he2015delving} as follows:</div><div class="clear"></div>
<div class="linenb">113</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">114</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">115</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\emph</span>{No positive saturation:} the ReLU does not response, or saturate, for non-positive inputs, but does not otherwise. This ensures a flow of gradient, update signal, whenever the input is non-negative, that was found to significantly speed up the convergence of training.</div><div class="clear"></div>
<div class="linenb">116</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\emph</span>{Cheap to compute:} unlike many other activation functions which requires expensive computation, such as exponential function, ReLU's implementation simply a threshold at zero. Another important characteristic is that the gradient is trivial to compute:</div><div class="clear"></div>
<div class="linenb">117</div><div class="codeline">        <span class="keyword2">\begin{equation}</span><span class="keyword1">\label</span>{eq:relu_derivative}</div><div class="clear"></div>
<div class="linenb">118</div><div class="codeline">            \nabla (relu(\mathbf{z}^{(l)})) =</div><div class="clear"></div>
<div class="linenb">119</div><div class="codeline">                <span class="keyword2">\begin{cases}</span></div><div class="clear"></div>
<div class="linenb">120</div><div class="codeline">                    \mathbf{a}^{(l-1)},  &amp; \text{if } \mathbf{z}^{(l)} &gt; 0 ,\\</div><div class="clear"></div>
<div class="linenb">121</div><div class="codeline">                    0,          &amp; \text{if } \mathbf{z}^{(l)} &lt; 0 ,\\</div><div class="clear"></div>
<div class="linenb">122</div><div class="codeline">                    undefined,  &amp; \text{if } \mathbf{z}^{(l)} = 0.</div><div class="clear"></div>
<div class="linenb">123</div><div class="codeline">                <span class="keyword2">\end{cases}</span></div><div class="clear"></div>
<div class="linenb">124</div><div class="codeline">        <span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">125</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">126</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\emph</span>{Induce sparsity:} ReLU units induce sparsity, whenever the input is negative their activation is zero. Sparsity is a desired property: as opposed to dense encoding, sparsity will produce representations where only a few entries change upon small variations of the input, i.e., it will produce a representation that is more consistent and robust to perturbations. Furthermore, sparsity allows compact encoding, which is desirable in many contexts such as, e.g., data compression and efficient data transfer.  Finally, it is also usually easier to linearly separate sparse representations~\cite{GlorotDeep2011}.</div><div class="clear"></div>
<div class="linenb">127</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\emph</span>{ReLU units can die:} </div><div class="clear"></div>
<div class="linenb">128</div><div class="codeline">    ReLU does not restrict the gradient flow from the positive part. Large gradient can update the weight in a such way it can not activate again,<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> i.e,</span> it always produces a negative value. This problem can be partially solved with some ReLU variant such as leaky ReLU or a parametric ReLU.  </div><div class="clear"></div>
<div class="linenb">129</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">130</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">131</div><div class="codeline"><span class="keyword1">\subsection</span>{Leaky Rectified Linear Unit (Leaky ReLU)}<span class="keyword1">\label</span>{sec:lrelu}</div><div class="clear"></div>
<div class="linenb">132</div><div class="codeline">Leaky ReLUs have been proposed as a way to mitigate the saturated units of ReLUs caused by extreme update, by preventing the unit from have zero gradient thus allowing a  gradient to flow through the unit, potentially recovering extreme values of the weights. Leaky ReLUs are widely adapted and defined as follows:</div><div class="clear"></div>
<div class="linenb">133</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">134</div><div class="codeline"><span class="keyword2">\begin{equation}</span><span class="keyword1">\label</span>{eq:lrelu}</div><div class="clear"></div>
<div class="linenb">135</div><div class="codeline">    leaky\_relu(\mathbf{z}) = max(\beta*\mathbf{z}, \mathbf{z}),</div><div class="clear"></div>
<div class="linenb">136</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">137</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">138</div><div class="codeline">\noindent where $\beta$ is a small constant.</div><div class="clear"></div>
<div class="linenb">139</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">140</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 133 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span>{Softmax}<span class="keyword1">\label</span>{sec:softmax}</div><div class="clear"></div>
<div class="linenb">141</div><div class="codeline"> Unlike previously mentioned functions softmax differs in that it does depend in all the values of the  dimensions altogether to produce the categorical distribution of the over $N$ classes. It defined as follows:</div><div class="clear"></div>
<div class="linenb">142</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">143</div><div class="codeline"><span class="keyword2">\begin{equation}</span><span class="keyword1">\label</span>{eq:softmax}</div><div class="clear"></div>
<div class="linenb">144</div><div class="codeline">    softmax(z_i) = \frac{\exp(z_i)}{\sum_{k=0}^K{\exp(z_k)}},</div><div class="clear"></div>
<div class="linenb">145</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">146</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">147</div><div class="codeline">\noindent where $K$ is the number of classes, i.e., of dimensions (or neurons).</div><div class="clear"></div>
<div class="linenb">148</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">149</div><div class="codeline">Temperature parameter $T$ can be used with the softmax which controls its steepness (see Fig.~\ref{fig:softmax}), i.e., to manage the randomness of predictions. High temperature, case of $T = \inf$, produces a uniform categorical distribution. While small temperature produces peaked probability distribution for the larger value.</div><div class="clear"></div>
<div class="linenb">150</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">151</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">152</div><div class="codeline"><span class="keyword2">\begin{equation}</span><span class="keyword1">\label</span>{eq:softmax_tmp}</div><div class="clear"></div>
<div class="linenb">153</div><div class="codeline">    softmax(z_i) = \frac{\exp(z_i / T)}</div><div class="clear"></div>
<div class="linenb">154</div><div class="codeline">    {\sum_{k=0}^K{\exp(z_k / T)}}.</div><div class="clear"></div>
<div class="linenb">155</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">156</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">157</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[t]</div><div class="clear"></div>
<div class="linenb">158</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">159</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/Softmaxbehaviour.png}</div><div class="clear"></div>
<div class="linenb">160</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{The steepness of softmax function as temperature $T$ grows.}<span class="keyword1">\label</span>{fig:softmax</span>}</div><div class="clear"></div>
<div class="linenb">161</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">162</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">163</div><div class="codeline"><span class="keyword1">\section</span>{Pooling}<span class="keyword1">\label</span>{sec:pooling}</div><div class="clear"></div>
<div class="linenb">164</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">165</div><div class="codeline">In addition to convolutional , {\em pooling\/} operations</div><div class="clear"></div>
<div class="linenb">166</div><div class="codeline">is an important building block in CNNs. Pooling operations reduce the spatial size of feature maps by using some aggregation,<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> i.e)</span> max or average, function to summarize a particular region.</div><div class="clear"></div>
<div class="linenb">167</div><div class="codeline">The following properties affect the output size $o_j$ of a pooling layer</div><div class="clear"></div>
<div class="linenb">168</div><div class="codeline">along axis $j$:</div><div class="clear"></div>
<div class="linenb">169</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">170</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">171</div><div class="codeline">    <span class="keyword1">\item</span> $i_j$: input size along axis $j$,</div><div class="clear"></div>
<div class="linenb">172</div><div class="codeline">    <span class="keyword1">\item</span> $k_j$: pooling window size along axis $j$,</div><div class="clear"></div>
<div class="linenb">173</div><div class="codeline">    <span class="keyword1">\item</span> $s_j$: stride (distance between two consecutive positions of the</div><div class="clear"></div>
<div class="linenb">174</div><div class="codeline">        pooling window) along axis $j$.</div><div class="clear"></div>
<div class="linenb">175</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">176</div><div class="codeline"><span class="keyword1">\subsection</span>{Average Pooling}</div><div class="clear"></div>
<div class="linenb">177</div><div class="codeline">Average pooling is performed by sliding a window over the input feature map and performing and averaging the content of the window. Fig.~\ref{fig:numerical_average_pooling}</div><div class="clear"></div>
<div class="linenb">178</div><div class="codeline">provides an example for average pooling.</div><div class="clear"></div>
<div class="linenb">179</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">180</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">181</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_average_pooling_00.pdf}</div><div class="clear"></div>
<div class="linenb">182</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_average_pooling_01.pdf}</div><div class="clear"></div>
<div class="linenb">183</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_average_pooling_02.pdf}</div><div class="clear"></div>
<div class="linenb">184</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_average_pooling_03.pdf}</div><div class="clear"></div>
<div class="linenb">185</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_average_pooling_04.pdf}</div><div class="clear"></div>
<div class="linenb">186</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_average_pooling_05.pdf}</div><div class="clear"></div>
<div class="linenb">187</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_average_pooling_06.pdf}</div><div class="clear"></div>
<div class="linenb">188</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_average_pooling_07.pdf}</div><div class="clear"></div>
<div class="linenb">189</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_average_pooling_08.pdf}</div><div class="clear"></div>
<div class="linenb">190</div><div class="codeline">    <span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{fig:numerical_average_pooling} Computing the output values</div><div class="clear"></div>
<div class="linenb">191</div><div class="codeline">        of a $3 \times 3$ average pooling operation on a $5 \times 5$ input</div><div class="clear"></div>
<div class="linenb">192</div><div class="codeline">        using $1 \times 1$ strides.}</div><div class="clear"></div>
<div class="linenb">193</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">194</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">195</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">196</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">197</div><div class="codeline"><span class="keyword1">\subsection</span>{Max pooling}</div><div class="clear"></div>
<div class="linenb">198</div><div class="codeline">Max pooling is performed same way as the average pooling performed, but instead of performing the averaging as an aggregation function it performs max function. Fig.~\ref{fig:numerical_max_pooling} provides an example for average pooling.</div><div class="clear"></div>
<div class="linenb">199</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">200</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">201</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_max_pooling_00.pdf}</div><div class="clear"></div>
<div class="linenb">202</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_max_pooling_01.pdf}</div><div class="clear"></div>
<div class="linenb">203</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_max_pooling_02.pdf}</div><div class="clear"></div>
<div class="linenb">204</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_max_pooling_03.pdf}</div><div class="clear"></div>
<div class="linenb">205</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_max_pooling_04.pdf}</div><div class="clear"></div>
<div class="linenb">206</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_max_pooling_05.pdf}</div><div class="clear"></div>
<div class="linenb">207</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_max_pooling_06.pdf}</div><div class="clear"></div>
<div class="linenb">208</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_max_pooling_07.pdf}</div><div class="clear"></div>
<div class="linenb">209</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[width=0.32\textwidth]{pdf/numerical_max_pooling_08.pdf}</div><div class="clear"></div>
<div class="linenb">210</div><div class="codeline">    <span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{fig:numerical_max_pooling} Computing the output values of a</div><div class="clear"></div>
<div class="linenb">211</div><div class="codeline">        $3 \times 3$ max pooling operation on a $5 \times 5$ input using $1</div><div class="clear"></div>
<div class="linenb">212</div><div class="codeline">        \times 1$ strides.}</div><div class="clear"></div>
<div class="linenb">213</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">214</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">215</div><div class="codeline">CNN are used for feature extraction from images followed by fully connected layers for classification. As convolution operation is applied in a sliding window fashion it can accept input of varied size, resulting in a varied size output. As CNN is followed by fully connected layers which can accept input of fixed size. This makes CNN incapable of accepting varied size inputs. Thus images are first reshaped into some specific dimension before feeding into CNN. This creates another issue of image warping and reduced resolution. Spatial Pyramid pooling comes as a counter to this problem.</div><div class="clear"></div>
<div class="linenb">216</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">217</div><div class="codeline"><span class="keyword1">\section</span>{Spatial Pyramid Pooling}</div><div class="clear"></div>
<div class="linenb">218</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">219</div><div class="codeline">The convolutional layers process arbitrary variable length, and also they produce outputs of variable sizes. Classifiers like SVM, decision tree or fully-connected layers require fixed-length input feature vector. Such vectors can be generated by the Bag-of-Words (BoW) approach~\cite{sivic2003video} that pools the features together. Spatial pyramid pooling~\cite{grauman2005pyramid},~\cite{lazebnik2006beyond} improves BoW in where it can preserve the spatial information of the input by pooling local spatial bins. These spatial bins have sizes that are proportional to the input image, so the number of bins is fixed regardless of the input dimensions. While sliding window pooling of the previous deep networks~\cite{krizhevsky2012imagenet} the number of sliding windows depends on the input size. To adopt the deep network for images of arbitrary sizes, we replace the last pooling layer with a spatial pyramid pooling layer.</div><div class="clear"></div>
<div class="linenb">220</div><div class="codeline">Fig.~\ref{originalSpp} illustrates our method. In each spatial bin, we pool the responses of each filter. The outputs of the spatial pyramid pooling are $kM$-dimensional vectors with the number of bins denoted as M (k is the number of filters in the last convolutional layer). The fixed-dimensional vectors are the input to the fully-connected layer. With spatial pyramid pooling, the input image can be of any sizes.</div><div class="clear"></div>
<div class="linenb">221</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">222</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">223</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/SPP.png}</div><div class="clear"></div>
<div class="linenb">224</div><div class="codeline">        <span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{originalSpp} spatial pyramid</div><div class="clear"></div>
<div class="linenb">225</div><div class="codeline">        pooling layer. Input feature map is divided to pins for each pin an aggregation function is performed}</div><div class="clear"></div>
<div class="linenb">226</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">227</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">228</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">229</div><div class="codeline"><span class="keyword1">\section</span>{Neural Network Attention}</div><div class="clear"></div>
<div class="linenb">230</div><div class="codeline">In a vision system, an attention mechanism can be defined as a dynamic selection process that is realized by weighting features according to the importance of the input in an adaptive manner. Attention attempts to selectively concentrate on relevant information or features while ignoring other irrelevant ones.  Currently, attention based models have shown a great success in natural language processing \cite{vaswani2017attention} and computer vision tasks \cite{guo2022attention}. Attention modules guide the network to focus on the most relevant features only \cite{guo2022attention}. Attention has many categories such as channel attention and spatial attention. Stated as follows </div><div class="clear"></div>
<div class="linenb">231</div><div class="codeline"><span class="keyword1">\subsection</span>{Channel Attention}</div><div class="clear"></div>
<div class="linenb">232</div><div class="codeline">Internal CNN feature maps have different channels in different usually each channel represents different objects~\cite{chen2017sca}. Channel attention recalibrates the weight of each channel, and can be viewed as an object selection process, thus determining what to pay attention to.~\cite{hu2018squeeze} is a pioneering channel attention mechanism which is formulated as follows</div><div class="clear"></div>
<div class="linenb">233</div><div class="codeline"> <span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">234</div><div class="codeline">    <span class="keyword2">\begin{split}</span></div><div class="clear"></div>
<div class="linenb">235</div><div class="codeline">        &amp;Att(X) = \sigma(W_2ReLU(W_1GAP(X)))\\</div><div class="clear"></div>
<div class="linenb">236</div><div class="codeline">        &amp;Y = Att(X)X </div><div class="clear"></div>
<div class="linenb">237</div><div class="codeline">    <span class="keyword2">\end{split}</span></div><div class="clear"></div>
<div class="linenb">238</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">239</div><div class="codeline">\noindent where $\sigma$ is sigmoid activation function, $GAP$ is global average pooling.</div><div class="clear"></div>
<div class="linenb">240</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">241</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">242</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=.3\textwidth]{Figures/SE_attentBlock.png}</div><div class="clear"></div>
<div class="linenb">243</div><div class="codeline">        <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{fig:SE_block} Channel attention block of SE network</span>}</div><div class="clear"></div>
<div class="linenb">244</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">245</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">246</div><div class="codeline">Fig.~\ref{fig:SE_block} illustrates the channel attention mechanism of~\cite{hu2018squeeze}</div><div class="clear"></div>
<div class="linenb">247</div><div class="codeline"><span class="keyword1">\subsection</span>{Spatial Attention}</div><div class="clear"></div>
<div class="linenb">248</div><div class="codeline">Spatial attention can be considered as an adaptive spatial region selection mechanism: where to pay attention.</div><div class="clear"></div>
<div class="linenb">249</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">250</div><div class="codeline">In~\cite{woo2018cbam} generates a spatial attention map by utilizing the spatial relationship of features. Unlike channel attention, the spatial attention focuses on where is an informative part, which is complementary to the channel attention. They compute the spatial attention by first applying average-pooling and max-pooling operations over each channel and concatenate them to generate the  feature descriptor. After pooled-feature concatenation convolution layer is applied to generate a spatial attention map $<span class="keyword1">\textbf</span>{M}_{s}\left(F\right) \in \mathcal{R}^{H?W}$ which encodes the spatial importance.</div><div class="clear"></div>
<div class="linenb">251</div><div class="codeline">We aggregate channel information of a feature map by using two pooling operations, generating two 2D maps:</div><div class="clear"></div>
<div class="linenb">252</div><div class="codeline">$\mathbf{F}^{s}_{avg} \in \mathbb{R}^{1\times{H}\times{W}}$</div><div class="clear"></div>
<div class="linenb">253</div><div class="codeline">and $\mathbf{F}^{s}_{max} \in \mathbb{R}^{1\times{H}\times{W}}$. Each denotes average-pooled features and max-pooled features across the channel. Those are then concatenated and convolved by a standard convolution layer, producing the 2D spatial attention map. In short, the spatial attention is computed as:</div><div class="clear"></div>
<div class="linenb">254</div><div class="codeline"><span class="keyword2">\begin{equation}</span><span class="keyword2">\begin{split}</span></div><div class="clear"></div>
<div class="linenb">255</div><div class="codeline">    &amp;<span class="keyword1">\textbf</span>{M}_{s}\left(F\right) = \sigma\left(CONV_{7\times7}\left(\left[\text{AvgPool}\left(F\right);\text{MaxPool}\left(F\right)\right]\right)\right) \\</div><div class="clear"></div>
<div class="linenb">256</div><div class="codeline">    &amp;OR\\</div><div class="clear"></div>
<div class="linenb">257</div><div class="codeline">    &amp; <span class="keyword1">\textbf</span>{M}_{s}\left(F\right) = \sigma\left(CONV_{7\times7}\left(\left[\mathbf{F}^{s}_{avg};\mathbf{F}^{s}_{max} \right]\right)\right) </div><div class="clear"></div>
<div class="linenb">258</div><div class="codeline"><span class="keyword2">\end{split}</span><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">259</div><div class="codeline">where $\sigma$ denotes the sigmoid function,  $CONV_{7\times7}$ represents a convolution operation with the filter size of $7\times7$, and $[\cdot]$ is a concatenation operator.</div><div class="clear"></div>
<div class="linenb">260</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">261</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">262</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/SpatialAttentionExample.png}</div><div class="clear"></div>
<div class="linenb">263</div><div class="codeline">        <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{<span class="highlight-sh" title="Figure fig:spattex is never referenced in the text [sh:figref]">f</span>ig:spattex} Spatial attention mechanism </span>}</div><div class="clear"></div>
<div class="linenb">264</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">265</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">266</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">267</div><div class="codeline"><span class="keyword1">\section</span>{Normalization}</div><div class="clear"></div>
<div class="linenb">268</div><div class="codeline">Normalization is crucial for training a deep network. Normalization allows the use of larger learning rate and results in smoother loss landscape of the objective function. Different types are summarized as follows:</div><div class="clear"></div>
<div class="linenb">269</div><div class="codeline"><span class="keyword1">\subsection</span>{Batch Normalization}</div><div class="clear"></div>
<div class="linenb">270</div><div class="codeline">As proposed in~\cite{ioffe2015batch} batch normalization is reduces {\em  Internal Covariate Shift} (ICS). ICS is defined as the change in the distribution of network activations due to the change in network parameters during training. Batch Normalization (BN) mitigate the ICS by normalizing the internal feature maps, minibatch, to have zero mean and unit variance. BN also allows the CNN to undo the normalization by scaling and shifting the normalized features using $\gamma$, $\beta$. </div><div class="clear"></div>
<div class="linenb">271</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">272</div><div class="codeline">BN is applied to each layer for a minibatch $\mathcal{B}$ as follows:</div><div class="clear"></div>
<div class="linenb">273</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">274</div><div class="codeline"><span class="keyword2">\begin{split}</span></div><div class="clear"></div>
<div class="linenb">275</div><div class="codeline">    &amp; \mu_{\mathcal{B}} = \frac{1}{m}\sum^{m}_{i=1}x_{i}\\</div><div class="clear"></div>
<div class="linenb">276</div><div class="codeline">    &amp;  \sigma^{2}_{\mathcal{B}} = \frac{1}{m}\sum^{m}_{i=1}\left(x_{i}-\mu_{\mathcal{B}}\right)^{2}\\</div><div class="clear"></div>
<div class="linenb">277</div><div class="codeline">    &amp;  \hat{x}_{i} = \frac{x_{i} - \mu_{\mathcal{B}}}{\sqrt{\sigma^{2}_{\mathcal{B}}+\epsilon}} \\</div><div class="clear"></div>
<div class="linenb">278</div><div class="codeline">    &amp;  y_{i} = \gamma\hat{x}_{i} + \beta = \text{BN}_{\gamma, \beta}\left(x_{i}\right) \\</div><div class="clear"></div>
<div class="linenb">279</div><div class="codeline"><span class="keyword2">\end{split}</span></div><div class="clear"></div>
<div class="linenb">280</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">281</div><div class="codeline">BN has many benefits which is summarized as follows:</div><div class="clear"></div>
<div class="linenb">282</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">283</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Accelerate network training.} BN allows larger learning rate.</div><div class="clear"></div>
<div class="linenb">284</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Regularization effect.} BN has regularization effect due to batch construction is done stochastically.</div><div class="clear"></div>
<div class="linenb">285</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Mitigate the effect of saturating activation function.} Normalization performed by BN relocate the layer activation to linear regime of saturating activation function such as sigmoid.</div><div class="clear"></div>
<div class="linenb">286</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">287</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">288</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 138 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span>{Layer Normalization}</div><div class="clear"></div>
<div class="linenb">289</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">290</div><div class="codeline">Unlike batch normalization, Layer Normalization~\cite{ba2016layer} directly estimates the normalization statistics from the summed inputs to the neurons within a hidden layer so the normalization does not introduce any new dependencies between training samples.</div><div class="clear"></div>
<div class="linenb">291</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">292</div><div class="codeline">We compute the layer normalization statistics over all the hidden units in the same layer as follows:</div><div class="clear"></div>
<div class="linenb">293</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">294</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">295</div><div class="codeline"><span class="keyword2">\begin{split}</span></div><div class="clear"></div>
<div class="linenb">296</div><div class="codeline">    &amp; \mu^{l} = \frac{1}{H}\sum^{H}_{i=1}a_{i}^{l}\\</div><div class="clear"></div>
<div class="linenb">297</div><div class="codeline">    &amp;  \sigma^{l} = \sqrt{\frac{1}{H}\sum^{H}_{i=1}\left(a_{i}^{l}-\mu^{l}\right)^{2}} \\</div><div class="clear"></div>
<div class="linenb">298</div><div class="codeline"><span class="keyword2">\end{split}</span></div><div class="clear"></div>
<div class="linenb">299</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">300</div><div class="codeline">where $H$ denotes the number of hidden units in a layer. Under layer normalization, all the hidden units in a layer share the same normalization terms $\mu$ and $\sigma$, but different training samples have different normalization terms. Unlike batch normalization, layer normalization does not impose any constraint on the size of the mini-batch and it can be used in the pure online regime with batch size of 1 sample.</div><div class="clear"></div>
<div class="linenb">301</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">302</div><div class="codeline"><span class="keyword1">\section</span>{Augmentation}</div><div class="clear"></div>
<div class="linenb">303</div><div class="codeline">Data augmentation~\cite{balestriero2022effects} is a technique that is  used for enlarging the training set, based on different modifications, using label preserving transformation. Data augmentation not only helps to grow the dataset but it also increases the diversity of the dataset and introduce  robustness to these transformations. When training machine learning models, data augmentation acts as a regularizer and helps to avoid overfitting.</div><div class="clear"></div>
<div class="linenb">304</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">305</div><div class="codeline">Data augmentation techniques have been found useful in domains like NLP and computer vision. In computer vision, transformations like cropping, flipping, and rotation are used. Fig. \ref{fig:DADeg} represents pre-class performance to the degree of augmentation.</div><div class="clear"></div>
<div class="linenb">306</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">307</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">308</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/labelpreserveAug.png}</div><div class="clear"></div>
<div class="linenb">309</div><div class="codeline">        <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{fig:DADeg}Data augmentation using crop augmentation with different preserving degrees and the corresponding accuracy of recognizing certain classes using ResNet</span>}</div><div class="clear"></div>
<div class="linenb">310</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">311</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">312</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">313</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">314</div><div class="codeline"><span class="keyword1">\section</span>{Dropout}</div><div class="clear"></div>
<div class="linenb">315</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">316</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">317</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">318</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">319</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/oriDropout.png}</div><div class="clear"></div>
<div class="linenb">320</div><div class="codeline">        <span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{fig:Dropout} Dropout Neural network Model. <span class="keyword1">\textbf</span>{Left}: A standard network with two hidden layers. <span class="keyword1">\textbf</span>{Right}: An example of a thinned net produced by applying dropout to the network on the left. Crossed units have been dropped.}</div><div class="clear"></div>
<div class="linenb">321</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">322</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">323</div><div class="codeline">Dropout~\cite{srivastava2014dropout} is a regularization technique for neural networks that drops a unit (along with connections) at training time with a specified probability $p$ (a common value is $p=0.5$). At test time, all units are present, but with weights scaled by $p$ (<span class="highlight-sh" title="Use a backslash or comma after the second period; otherwise LaTeX will think it is a full stop ending a sentence. [sh:011]">i.e. </span>$w$ becomes $pw$).</div><div class="clear"></div>
<div class="linenb">324</div><div class="codeline">Dropout has the following benefits. </div><div class="clear"></div>
<div class="linenb">325</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">326</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Reduces co-adaptation between the neurons.} Complex co-adaptation between neuron occurs when the neurons of the one layer depend on the neurons on next layers to correct their errors. Dropout fixes this issue by making neuron existance stochastic.</div><div class="clear"></div>
<div class="linenb">327</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Implicit ensemble.} Dropout  approximately combining exponential number different thinned neural network architectures efficiently</div><div class="clear"></div>
<div class="linenb">328</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">329</div><div class="codeline">Fig.~\ref{fig:Dropout} illustrates the operation of the Dropout.</div><div class="clear"></div>
<div class="linenb">330</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">331</div><div class="codeline"><span class="keyword1">\section</span>{Multiscale Recognition}</div><div class="clear"></div>
<div class="linenb">332</div><div class="codeline">CNN,  like many computer vision models, is a scale-variant <span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{van2017learning} model such that it cannot recognize objects at various scales unless it explicitly trained to recognize such objects. Many approaches have been developed to overcome this problem. The first approach is referred to as <span class="keyword1">\textit</span>{shared-net}. Shared-net approach creates a scale-pyramid of the input image  to train a single shared network using  multiple scales. This shared network produces a feature vector for each scale which in turn is fused with an aggregation function to produce the final prediction \cite{farabet2012learning}\cite</span>{lin2016efficient}<span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{felzenszwalb2009object}\cite</span>{ciregan2012multi}. Shared-network needs to evaluate each scale independently which is a time-consuming.</div><div class="clear"></div>
<div class="linenb">333</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">334</div><div class="codeline">The second approach is to reuse low level features produced by the intermediate CNN layers using a skip connection <span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{chen2014semantic}\cite</span>{hariharan2015hypercolumns}. These features are considered multi-scale due to the different receptive field of the corresponding layers. The training of these networks is performed through two phases. Backbone network is trained in the first phase.  Then, it is fine-tuned during multi-scale feature extraction <span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{long2015fully}\cite</span>{lin2017feature}. The drawback of this approach is the separation between the classifier training and the feature extraction.<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">335</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">336</div><div class="codeline">    <span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">337</div><div class="codeline">    \centerline{<span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/AtrousConv.PNG}}</div><div class="clear"></div>
<div class="linenb">338</div><div class="codeline">    <span class="keyword1">\caption</span>{A grid represents a feature map and the circle inside the cell represents the corresponding value of $2\times 2$ convolutional kernel. <span class="keyword1">\textbf</span>{left}: A $2\times 2$ convolutional kernel with an atrous rate $r=1$. <span class="keyword1">\textbf</span>{middle}: A $2\times 2$ convolutional kernel with an atrous rate $r=2$. <span class="keyword1">\textbf</span>{right}: A $2\times 2$ convolutional kernel with an atrous rate $r=3$.}</div><div class="clear"></div>
<div class="linenb">339</div><div class="codeline">    <span class="keyword1">\label</span>{AtrousConv}</div><div class="clear"></div>
<div class="linenb">340</div><div class="codeline">    <span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">341</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">342</div><div class="codeline">The third and the  recent approach is to deploy atrous convolution <span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{holschneider1990real} in CNN context \cite{chen2017deeplab}\cite</span>{giusti2013fast}. Atrous convolution is defined as follows: \[y[i]=\sum_{k}^{K} x[i+r\times k] w[k]\] where $x$ is the input signal, $w$ is the convolutional filter with size of $K$, $y$ is the resultant signal, and $r$ is the atrous rate. Atrous convolution can be seen as a convolution  operation between the input signal and the upsampled version of the filter. This upsampling is performed by introducing $r-1$ zeros between the kernel values. Also, Atrous convolution can be seen as a  convolution between the downsampled version of the input signal and the kernel. Atrous convolution allows the change in the receptive field and controls the input signal resolution without increasing the parameter number \cite{chen2017rethinking}<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> (<span class="keyword1">\textit</span>{i.e,}</span> a $3\times 3$ convolutional kernel and a dilation rate of $r=2$ has the same receptive field of $5\times 5$ convolutional kernel and dilation rate of $r=1$). Atrous convolution can be used to build the resultant scale-space through  performing Atrous convolution with multiple Atrous rates, $r$, which is known as Atrous Spatial pyramid Pooling (ASPP) \cite{chen2017deeplab}. ASPP has a regularization effect as it ensures that the convolutional kernels will learn  useful features   across the scale space of the input. Fig. \ref{AtrousConv} shows an example of  Atrous convolution with different rates. </div><div class="clear"></div>
<div class="linenb">343</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">344</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">345</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\section</span>{Initialization}</span></span></div><div class="clear"></div>
<div class="linenb">346</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">347</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\section</span>{Optimization}</span></span></div><div class="clear"></div>
<div class="linenb">348</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">349</div><div class="codeline"><span class="keyword1">\section</span>{Summary}</div><div class="clear"></div>
<div class="linenb">350</div><div class="codeline">This chapter of provides an introduction to several key concepts and techniques in the field of deep learning, with a focus on convolutional neural networks (CNNs) and their applications in computer vision.</div><div class="clear"></div>
<div class="linenb">351</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">352</div><div class="codeline">The chapter begins by introducing the basic architecture of a CNN, including convolutional layers and pooling layers. It then discusses the role of activation functions in deep learning, such as sigmoid, tanh, and rectified linear unit (ReLU), and their impact on model performance.</div><div class="clear"></div>
<div class="linenb">353</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">354</div><div class="codeline">The chapter goes on to explore more advanced techniques in CNNs, including spatial pyramid pooling, which enables the network to learn features at multiple scales. It also covers channel attention and spatial attention mechanisms, which allow the network to selectively focus on certain features during training and inference.</div><div class="clear"></div>
<div class="linenb">355</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">356</div><div class="codeline">The chapter then discusses the importance of normalization techniques in deep learning, including batch normalization and layer normalization, which help to stabilize the network during training and improve its generalization performance.</div><div class="clear"></div>
<div class="linenb">357</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">358</div><div class="codeline">The chapter concludes with a discussion of various data augmentation techniques, such as image rotation and flipping, as well as dropout, which can help to prevent overfitting in the network. Finally, the chapter introduces the concept of multiscale recognition, which involves training the network to recognize objects at different scales, and its importance in achieving high accuracy in computer vision tasks.</div><div class="clear"></div>
<div class="linenb">359</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">360</div><div class="codeline">Overall, this chapter provides a comprehensive introduction to the key concepts and techniques in deep learning, with a focus on CNNs and their applications in computer vision to understand this thesis.</div><div class="clear"></div>
</div>
<h2 class="filename">./main.tex</h2>

<p>Found 34 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">%</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline"><span class="keyword1">\documentclass</span>[</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">12pt, <span class="comment">% The default document font size, options: 10pt, 11pt, 12pt</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline"><span class="comment"><span class="comment">%oneside, % Two side (alternating margins) for binding by default, uncomment to switch to one side</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline">english, <span class="comment">% ngerman for German</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">onehalfspacing, <span class="comment">% singlespacing Single line spacing, alternatives: onehalfspacing or doublespacing</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline"><span class="comment"><span class="comment">%draft, % Uncomment to enable draft mode (no pictures, no links, overfull hboxes indicated)</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline"><span class="comment"><span class="comment">%nolistspacing, % If the document is onehalfspacing or doublespacing, uncomment this to set spacing in lists to single</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline">liststotoc, <span class="comment">% Uncomment to add the list of figures/tables/etc to the table of contents</span></div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline">toctotoc, <span class="comment">% Uncomment to add the main table of contents to the table of contents</span></div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline"><span class="comment"><span class="comment">%parskip, % Uncomment to add space between paragraphs</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">nohyperref, <span class="comment">% Uncomment to not load the hyperref package</span></div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline">headsepline, <span class="comment">% Uncomment to get a line under the header</span></div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline"><span class="comment"><span class="comment">%chapterinoneline, % Uncomment to place the chapter title next to the number on one line</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline"><span class="comment"><span class="comment">%consistentlayout, % Uncomment to change the layout of the declaration, abstract and acknowledgements pages to match the default layout</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline">]{MastersDoctoralThesis} <span class="comment">% The class file specifying the document structure</span></div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline"><span class="keyword1">\usepackage</span>[utf8]{inputenc} <span class="comment">% Required for inputting international characters</span></div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline"><span class="keyword1">\usepackage</span>[T1]{fontenc} <span class="comment">% Output font encoding for international characters</span></div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline"><span class="keyword1">\usepackage</span>{mathpazo} <span class="comment">% Use the Palatino font by default</span></div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline"><span class="keyword1">\usepackage</span>[backend=bibtex,style=numeric,natbib=true, sorting=none]{biblatex} <span class="comment">% Use the bibtex backend with the authoryear citation style (which resembles APA)</span></div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline">\addbibresource[label=refs]{example.bib} <span class="comment">% The filename of the bibliography</span></div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline">\addbibresource[label=ownpubs]{ownpubs.bib} <span class="comment">% The filename of the bibliography</span></div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline"><span class="keyword1">\usepackage</span>[autostyle=true]{csquotes} <span class="comment">% Required to generate language-dependent quotes in the bibliography</span></div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline"><span class="keyword1">\usepackage</span>{arabxetex}</div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline"><span class="keyword1">\usepackage</span>[printonlyused,withpage]{acronym}</div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline"><span class="keyword1">\usepackage</span>{algorithmic}</div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline"><span class="keyword1">\usepackage</span>{adjustbox}</div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline"><span class="keyword1">\usepackage</span>{caption}</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline"><span class="keyword1">\usepackage</span>{subcaption}</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\usepackage</span>{subfig}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline"><span class="comment"><span class="comment">%	MARGIN SETTINGS</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline">\geometry{</div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline">	paper=a4paper, <span class="comment">% Change to letterpaper for US letter</span></div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">	inner=2.5cm, <span class="comment">% Inner margin</span></div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline">	outer=3.8cm, <span class="comment">% Outer margin</span></div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline">	bindingoffset=.5cm, <span class="comment">% Binding offset</span></div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline">	top=1.5cm, <span class="comment">% Top margin</span></div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline">	bottom=1.5cm, <span class="comment">% Bottom margin</span></div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline">	<span class="comment">%showframe, % Uncomment to show how the type block is set on the page</span></div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline">}</div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline"><span class="comment"><span class="comment">%	THESIS INFORMATION</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline">\thesistitle{Automated detection of COVID-19 cases in digital medical images using deep learning approaches} <span class="comment">% Your thesis title, this is used in the title and abstract, print it elsewhere with \ttitle</span></div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">\supervisor{} <span class="comment">% Your supervisor's name, this is used in the title page, print it elsewhere with \supname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline">\examiner{} <span class="comment">% Your examiner's name, this is not currently used anywhere in the template, print it elsewhere with \examname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">\degree{Master of Science} <span class="comment">% Your degree name, this is used in the title page and abstract, print it elsewhere with \degreename</span></div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline">\author{Mahmoud Z. Fetoh} <span class="comment">% Your name, this is used in the title page and abstract, print it elsewhere with \authorname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline">\addresses{} <span class="comment">% Your address, this is not currently used anywhere in the template, print it elsewhere with \addressname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline">\subject{Information Technology} <span class="comment">% Your subject area, this is not currently used anywhere in the template, print it elsewhere with \subjectname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline">\keywords{ } <span class="comment">% Keywords for your thesis, this is not currently used anywhere in the template, print it elsewhere with \keywordnames</span></div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline">\university{Menofia University} <span class="comment">% Your university's name and URL, this is used in the title page and abstract, print it elsewhere with \univname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline">\department{Information Technology} <span class="comment">% Your department's name and URL, this is used in the title page and abstract, print it elsewhere with \deptname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline">\group{  } <span class="comment">% Your research group's name and URL, this is used in the title page, print it elsewhere with \groupname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline">\faculty{Faculty of computers and information} <span class="comment">% Your faculty's name and URL, this is used in the title page and abstract, print it elsewhere with \facname</span></div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline"><span class="comment"><span class="comment">% \AtBeginDocument{</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline"><span class="comment"><span class="comment">% \hypersetup{pdftitle=\ttitle} % Set the PDF's title to your title</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline"><span class="comment"><span class="comment">% \hypersetup{pdfauthor=\authorname} % Set the PDF's author to your name</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline"><span class="comment"><span class="comment">% \hypersetup{pdfkeywords=\keywordnames} % Set the PDF's keywords to your keywords</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline"><span class="comment"><span class="comment">% }</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline"><span class="keyword2">\begin{document}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline">\frontmatter <span class="comment">% Use roman page numbering style (i, ii, iii, iv...) for the pre-content pages</span></div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline">\pagestyle{plain} <span class="comment">% Default to the plain heading style until the thesis style is called for the body content</span></div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline"><span class="comment"><span class="comment">%	TITLE PAGE</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{titlepage}</span></span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{center}</span></span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\includegraphics</span>[width=2cm,height=2cm]{Figures/Unilogo.png}\\ % University/department logo - uncomment to place it</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline"><span class="comment"><span class="comment">% \vspace*{.02\textheight}</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline"><span class="comment"><span class="comment">% {\scshape\LARGE \univname\par}\vspace{0.2cm} % University name</span></span></div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline"><span class="comment"><span class="comment">% \textsc{\Large Faculty of Computers and Information}\\[0.5cm] % Thesis type</span></span></div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline"><span class="comment"><span class="comment">% \HRule \\[0.4cm] % Horizontal line</span></span></div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline"><span class="comment"><span class="comment">% {\huge \bfseries \ttitle\par}\vspace{0.4cm} % Thesis title</span></span></div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline"><span class="comment"><span class="comment">% \HRule \\[1.5cm] % Horizontal line</span></span></div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline"> </div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{minipage}</span>[t]{0.4\textwidth}</span></span></div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{flushleft}</span> \large</span></span></div><div class="clear"></div>
<div class="linenb">108</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\emph</span>{Author:}\\</span></span></div><div class="clear"></div>
<div class="linenb">109</div><div class="codeline"><span class="comment"><span class="comment">% \authorname % Author name - remove the \href bracket to remove the link</span></span></div><div class="clear"></div>
<div class="linenb">110</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{flushleft}</span></span></span></div><div class="clear"></div>
<div class="linenb">111</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{minipage}</span></span></span></div><div class="clear"></div>
<div class="linenb">112</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{minipage}</span>[t]{0.4\textwidth}</span></span></div><div class="clear"></div>
<div class="linenb">113</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{flushright}</span> \large</span></span></div><div class="clear"></div>
<div class="linenb">114</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\emph</span>{Supervisors:} \\</span></span></div><div class="clear"></div>
<div class="linenb">115</div><div class="codeline"><span class="comment"><span class="comment">% Prof. Khalid M. Amin</span></span></div><div class="clear"></div>
<div class="linenb">116</div><div class="codeline"><span class="comment"><span class="comment">% Dr. Ahmed M. Hamad</span></span></div><div class="clear"></div>
<div class="linenb">117</div><div class="codeline"><span class="comment"><span class="comment">% % \supname % Supervisor name - remove the \href bracket to remove the link  </span></span></div><div class="clear"></div>
<div class="linenb">118</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{flushright}</span></span></span></div><div class="clear"></div>
<div class="linenb">119</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{minipage}</span>\\[2cm]</span></span></div><div class="clear"></div>
<div class="linenb">120</div><div class="codeline"> </div><div class="clear"></div>
<div class="linenb">121</div><div class="codeline"><span class="comment"><span class="comment">% % \vfill</span></span></div><div class="clear"></div>
<div class="linenb">122</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">123</div><div class="codeline"><span class="comment"><span class="comment">% \large <span class="keyword1">\textit</span>{A thesis submitted in fulfillment of the requirements\\ for the degree of \degreename}\\[0.3cm] % University requirement text</span></span></div><div class="clear"></div>
<div class="linenb">124</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\textit</span>{in the}\\[0.4cm]</span></span></div><div class="clear"></div>
<div class="linenb">125</div><div class="codeline"><span class="comment"><span class="comment">% % \groupname\\\deptname\\[2cm] % Research group name and department name</span></span></div><div class="clear"></div>
<div class="linenb">126</div><div class="codeline"><span class="comment"><span class="comment">% \deptname\\[2cm] %</span></span></div><div class="clear"></div>
<div class="linenb">127</div><div class="codeline"><span class="comment"><span class="comment">% % \vfill</span></span></div><div class="clear"></div>
<div class="linenb">128</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">129</div><div class="codeline"><span class="comment"><span class="comment">% {\large \today}\\[2cm] % Date</span></span></div><div class="clear"></div>
<div class="linenb">130</div><div class="codeline"> </div><div class="clear"></div>
<div class="linenb">131</div><div class="codeline"><span class="comment"><span class="comment">% \vfill</span></span></div><div class="clear"></div>
<div class="linenb">132</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{center}</span></span></span></div><div class="clear"></div>
<div class="linenb">133</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{titlepage}</span></span></span></div><div class="clear"></div>
<div class="linenb">134</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">135</div><div class="codeline"><span class="comment"><span class="comment">%------------------</span></span></div><div class="clear"></div>
<div class="linenb">136</div><div class="codeline"><span class="comment"><span class="comment">%	DECLARATION PAGE</span></span></div><div class="clear"></div>
<div class="linenb">137</div><div class="codeline"><span class="comment"><span class="comment">%--------------------</span></span></div><div class="clear"></div>
<div class="linenb">138</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">139</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{declaration}</span></span></span></div><div class="clear"></div>
<div class="linenb">140</div><div class="codeline"><span class="comment"><span class="comment">% \addchaptertocentry{\authorshipname} % Add the declaration to the table of contents</span></span></div><div class="clear"></div>
<div class="linenb">141</div><div class="codeline"><span class="comment"><span class="comment">% \noindent I, \authorname, declare that this thesis titled, \enquote{\ttitle} and the work presented in it are my own. I confirm that:</span></span></div><div class="clear"></div>
<div class="linenb">142</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">143</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{itemize}</span> </span></span></div><div class="clear"></div>
<div class="linenb">144</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\item</span> This work was done wholly or mainly while in candidature for a research degree at this University.</span></span></div><div class="clear"></div>
<div class="linenb">145</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\item</span> Where any part of this thesis has previously been submitted for a degree or any other qualification at this University or any other institution, this has been clearly stated.</span></span></div><div class="clear"></div>
<div class="linenb">146</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\item</span> Where I have consulted the published work of others, this is always clearly attributed.</span></span></div><div class="clear"></div>
<div class="linenb">147</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\item</span> Where I have quoted from the work of others, the source is always given. With the exception of such quotations, this thesis is entirely my own work.</span></span></div><div class="clear"></div>
<div class="linenb">148</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\item</span> I have acknowledged all main sources of help.</span></span></div><div class="clear"></div>
<div class="linenb">149</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\item</span> Where the thesis is based on work done by myself jointly with others, I have made clear exactly what was done by others and what I have contributed myself.\\</span></span></div><div class="clear"></div>
<div class="linenb">150</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{itemize}</span></span></span></div><div class="clear"></div>
<div class="linenb">151</div><div class="codeline"> </div><div class="clear"></div>
<div class="linenb">152</div><div class="codeline"><span class="comment"><span class="comment">% \noindent Signed:\\</span></span></div><div class="clear"></div>
<div class="linenb">153</div><div class="codeline"><span class="comment"><span class="comment">% \rule[0.5em]{25em}{0.5pt} % This prints a line for the signature</span></span></div><div class="clear"></div>
<div class="linenb">154</div><div class="codeline"> </div><div class="clear"></div>
<div class="linenb">155</div><div class="codeline"><span class="comment"><span class="comment">% \noindent Date:\\</span></span></div><div class="clear"></div>
<div class="linenb">156</div><div class="codeline"><span class="comment"><span class="comment">% \rule[0.5em]{25em}{0.5pt} % This prints a line to write the date</span></span></div><div class="clear"></div>
<div class="linenb">157</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{declaration}</span></span></span></div><div class="clear"></div>
<div class="linenb">158</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">159</div><div class="codeline"><span class="comment"><span class="comment">% \cleardoublepage</span></span></div><div class="clear"></div>
<div class="linenb">160</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">161</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">162</div><div class="codeline"><span class="comment"><span class="comment">%	QUOTATION PAGE</span></span></div><div class="clear"></div>
<div class="linenb">163</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">164</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">165</div><div class="codeline"><span class="comment"><span class="comment">% \vspace*{0.2\textheight}</span></span></div><div class="clear"></div>
<div class="linenb">166</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">167</div><div class="codeline"><span class="comment"><span class="comment">% \noindent\enquote{\itshape Thanks to my solid academic training, today I can write hundreds of words on virtually any topic without possessing a shred of information, which is how I got a good job in journalism.}\bigbreak</span></span></div><div class="clear"></div>
<div class="linenb">168</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">169</div><div class="codeline"><span class="comment"><span class="comment">% \hfill Dave Barry</span></span></div><div class="clear"></div>
<div class="linenb">170</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">171</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">172</div><div class="codeline"><span class="comment"><span class="comment">%	ABSTRACT PAGE</span></span></div><div class="clear"></div>
<div class="linenb">173</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">174</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">175</div><div class="codeline"><span class="keyword2">\begin{abstract}</span></div><div class="clear"></div>
<div class="linenb">176</div><div class="codeline">\addchaptertocentry{\abstractname} <span class="comment">% Add the abstract to the table of contents</span></div><div class="clear"></div>
<div class="linenb">177</div><div class="codeline">COVID-19 is a severe respiratory tract infections. COVID-19 caused by SARS-CoV-2 can readily spread through a contact with an infected person. Monotonically increasing SARS-CoV-2 infections have not only wasted lives but also severely damaged the financial systems of both developing and developed countries. This high spread rate pressure on the health care systems which rise the need to fast methods for diagnosing this disease. Convolutional Neural Networks (CNN) show a great success for various computer vision tasks. However, CNN is a scale-variant model and computationally expensive. In this Thesis, a novel architectures are proposed for multiscale feature extraction and classification and lightweight architecture for COVID-19 diagnosing. The proposed I which is a lightweight CNN model exploits spatial kernel separability to reduce the number of the training parameters to a large extent and regularize the model to only learns linear kernel. Furthermore, This model uses residual connection and batch normalization extensively to maintain the network stability during the training process and provide the model with the regularization effect to reduce the overfitting. Proposed CNN II learns multiscale features using a pyramid of shared convolution kernels with different atrous rates. This scale invariant CNN uses attention based mechanism that is used to guide and select correct scale for each input. Proposed CNN II is an end-to-end trainable network and exploit a novel augmentation technique, Texture Augmentation, to reduce the overfitting. The lightweight architecture is trained using QaTa-Cov19 benchmark dataset achieving  100\% for accuracy, sensitivity, precision and F1-score with a very low parameter count (150K) compared with the other methods in the literature.  Proposed method II achieved a 0.9929 for $F1-score$ tested on QaTa-Cov19 benchmark dataset with a total of $5,040,571$ trainable parameters.</div><div class="clear"></div>
<div class="linenb">178</div><div class="codeline"><span class="keyword2">\end{abstract}</span></div><div class="clear"></div>
<div class="linenb">179</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">180</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">181</div><div class="codeline"><span class="comment"><span class="comment">%	ACKNOWLEDGEMENTS</span></span></div><div class="clear"></div>
<div class="linenb">182</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">183</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">184</div><div class="codeline"><span class="keyword2">\begin{acknowledgements}</span></div><div class="clear"></div>
<div class="linenb">185</div><div class="codeline">\addchaptertocentry{\acknowledgementname} <span class="comment">% Add the acknowledgements to the table of contents</span></div><div class="clear"></div>
<div class="linenb">186</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">187</div><div class="codeline">\indent <span class="keyword1">\textbf</span>{Praise be to ALLAH first and last. Prayers and peace be upon MOHAMMED the Messenger of ALLAH}.<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">188</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">189</div><div class="codeline">I would like to thank my supervisors and my teachers <span class="keyword1">\textit</span>{Dr. Ahmed M. Hamad} and <span class="keyword1">\textit</span>{Prof. Khalid M. Amin} for their help and guide during my Study. They have been helpful with background information and have continually encouraged me and helped me with comments on my work. They always had time to discuss new ideas and give feedback on early ideas and research problems.</div><div class="clear"></div>
<div class="linenb">190</div><div class="codeline"><span class="keyword2">\end{acknowledgements}</span></div><div class="clear"></div>
<div class="linenb">191</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">192</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">193</div><div class="codeline"><span class="comment"><span class="comment">%	LIST OF CONTENTS/FIGURES/TABLES PAGES</span></span></div><div class="clear"></div>
<div class="linenb">194</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">195</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">196</div><div class="codeline">\tableofcontents <span class="comment">% Prints the main table of contents</span></div><div class="clear"></div>
<div class="linenb">197</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">198</div><div class="codeline">\listoffigures <span class="comment">% Prints the list of figures</span></div><div class="clear"></div>
<div class="linenb">199</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">200</div><div class="codeline">\listoftables <span class="comment">% Prints the list of tables</span></div><div class="clear"></div>
<div class="linenb">201</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">202</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">203</div><div class="codeline"><span class="comment"><span class="comment">%	ABBREVIATIONS</span></span></div><div class="clear"></div>
<div class="linenb">204</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">205</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">206</div><div class="codeline"><span class="keyword2">\begin{abbreviations}</span>{ll} <span class="comment">% Include a list of abbreviations (a table of two columns)</span></div><div class="clear"></div>
<div class="linenb">207</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">208</div><div class="codeline">COVID-19 &amp; COronaVIrus Disease 2019<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">209</div><div class="codeline">SARS-CoV-2 &amp; severe acute respiratory syndrome coronavirus 2<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">210</div><div class="codeline">WHO &amp;  World Health Organization<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">211</div><div class="codeline">rRT-PCR &amp; real-time reverse transcription polymerase chain reaction <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">212</div><div class="codeline">TMA &amp;  transcription-mediated amplification<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">213</div><div class="codeline">RT-LAMP &amp; reverse transcription loop-mediated isothermal amplification<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">214</div><div class="codeline">CXR  &amp; Chest X-rays <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">215</div><div class="codeline">CNN  &amp; convolutional Neural Network<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">216</div><div class="codeline">tanh &amp; Hyperbolic tangent <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">217</div><div class="codeline">ReLU &amp; Rectified Linear Unit <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">218</div><div class="codeline">BoW &amp; Bag-of-Words <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">219</div><div class="codeline">SVM  &amp; Support Vector Machine <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">220</div><div class="codeline">ICS &amp; Internal Covariate Shift<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">221</div><div class="codeline">BN &amp; Batch Normalization <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">222</div><div class="codeline">ASPP &amp; Atrous Spatial pyramid <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">223</div><div class="codeline">RC &amp;Representation-based classification <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">224</div><div class="codeline">BGWO  &amp; binary grey wolf optimization <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">225</div><div class="codeline">ANN  &amp; Artificial neural network <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">226</div><div class="codeline">PCA &amp; principal component analysis <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">227</div><div class="codeline">DT  &amp; Decision Tree <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">228</div><div class="codeline">NB  &amp;  Naive Bayes <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">229</div><div class="codeline">FOSF &amp;  first order statistical features  <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">230</div><div class="codeline">GLCM &amp; Gray Level Co-occurrence Matrix <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">231</div><div class="codeline">HOG &amp;  Histogram of Oriented Gradients<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">232</div><div class="codeline">KNN  &amp; k-nearest neighbors <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">233</div><div class="codeline">RBF  &amp; radial basis function <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">234</div><div class="codeline">RSB &amp; Residual Separated Block<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">235</div><div class="codeline">SWASPP &amp; Spatially weighted Atrous Spatial Pyramid<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">236</div><div class="codeline">DSWASPP &amp; Densely stacked SWASPP<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">237</div><div class="codeline">SPP &amp;  Spatial Pyramid Pooling<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">238</div><div class="codeline">SASPP-net &amp; Switchable Atrous Spatial Pyramid Pooling<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">239</div><div class="codeline">FX &amp; feature extraction modules<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">240</div><div class="codeline">Adam  &amp; Adaptive Moment Estimation <span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">241</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">242</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\textbf</span>{LAH} &amp; <span class="keyword1">\textbf</span>{L}ist <span class="keyword1">\textbf</span>{A}bbreviations <span class="keyword1">\textbf</span>{H}ere\\</span></span></div><div class="clear"></div>
<div class="linenb">243</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword1">\textbf</span>{WSF} &amp; <span class="keyword1">\textbf</span>{W}hat (it) <span class="keyword1">\textbf</span>{S}tands <span class="keyword1">\textbf</span>{F}or\\</span></span></div><div class="clear"></div>
<div class="linenb">244</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">245</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">246</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">247</div><div class="codeline"><span class="keyword2">\end{abbreviations}</span></div><div class="clear"></div>
<div class="linenb">248</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{acronym}</span></span></span></div><div class="clear"></div>
<div class="linenb">249</div><div class="codeline"><span class="comment"><span class="comment">% 	\acro{USA}{Uited States of America}</span></span></div><div class="clear"></div>
<div class="linenb">250</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{acronym}</span> </span></span></div><div class="clear"></div>
<div class="linenb">251</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">252</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">253</div><div class="codeline"><span class="comment"><span class="comment">%	PHYSICAL CONSTANTS/OTHER DEFINITIONS</span></span></div><div class="clear"></div>
<div class="linenb">254</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">255</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">256</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{constants}</span>{lr@{${}={}$}l} % The list of physical constants is a three column table</span></span></div><div class="clear"></div>
<div class="linenb">257</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">258</div><div class="codeline"><span class="comment"><span class="comment">% % The \SI{}{} command is provided by the siunitx package, see its documentation for instructions on how to use it</span></span></div><div class="clear"></div>
<div class="linenb">259</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">260</div><div class="codeline"><span class="comment"><span class="comment">% Speed of Light &amp; $c_{0}$ &amp; \SI{2.99792458e8}{\meter\per\second} (exact)\\</span></span></div><div class="clear"></div>
<div class="linenb">261</div><div class="codeline"><span class="comment"><span class="comment">% %Constant Name &amp; $Symbol$ &amp; $Constant Value$ with units\\</span></span></div><div class="clear"></div>
<div class="linenb">262</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">263</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{constants}</span></span></span></div><div class="clear"></div>
<div class="linenb">264</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">265</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">266</div><div class="codeline"><span class="comment"><span class="comment">%	SYMBOLS</span></span></div><div class="clear"></div>
<div class="linenb">267</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">268</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">269</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\begin{symbols}</span>{lll} % Include a list of Symbols (a three column table)</span></span></div><div class="clear"></div>
<div class="linenb">270</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">271</div><div class="codeline"><span class="comment"><span class="comment">% $a$ &amp; distance &amp; \si{\meter} \\</span></span></div><div class="clear"></div>
<div class="linenb">272</div><div class="codeline"><span class="comment"><span class="comment">% $P$ &amp; power &amp; \si{\watt} (\si{\joule\per\second}) \\</span></span></div><div class="clear"></div>
<div class="linenb">273</div><div class="codeline"><span class="comment"><span class="comment">% %Symbol &amp; Name &amp; Unit \\</span></span></div><div class="clear"></div>
<div class="linenb">274</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">275</div><div class="codeline"><span class="comment"><span class="comment">% \addlinespace % Gap to separate the Roman symbols from the Greek</span></span></div><div class="clear"></div>
<div class="linenb">276</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">277</div><div class="codeline"><span class="comment"><span class="comment">% $\omega$ &amp; angular frequency &amp; \si{\radian} \\</span></span></div><div class="clear"></div>
<div class="linenb">278</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">279</div><div class="codeline"><span class="comment"><span class="comment">% <span class="keyword2">\end{symbols}</span></span></span></div><div class="clear"></div>
<div class="linenb">280</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">281</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">282</div><div class="codeline"><span class="comment"><span class="comment">%	DEDICATION</span></span></div><div class="clear"></div>
<div class="linenb">283</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">284</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">285</div><div class="codeline">\dedicatory{To my Family} </div><div class="clear"></div>
<div class="linenb">286</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">287</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">288</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">289</div><div class="codeline"><span class="comment"><span class="comment">%-----------------</span></span></div><div class="clear"></div>
<div class="linenb">290</div><div class="codeline"><span class="comment"><span class="comment">%	THESIS CONTENT - CHAPTERS</span></span></div><div class="clear"></div>
<div class="linenb">291</div><div class="codeline"><span class="comment"><span class="comment">%--------------------</span></span></div><div class="clear"></div>
<div class="linenb">292</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">293</div><div class="codeline">\mainmatter <span class="comment">% Begin numeric (1,2,3...) page numbering</span></div><div class="clear"></div>
<div class="linenb">294</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">295</div><div class="codeline">\pagestyle{thesis} <span class="comment">% Return the page headers back to the "thesis" style</span></div><div class="clear"></div>
<div class="linenb">296</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">297</div><div class="codeline">   </div><div class="clear"></div>
<div class="linenb">298</div><div class="codeline"><span class="comment"><span class="comment">% Include the chapters of the thesis as separate files from the Chapters folder</span></span></div><div class="clear"></div>
<div class="linenb">299</div><div class="codeline"><span class="comment"><span class="comment">% Uncomment the lines as you write the chapters</span></span></div><div class="clear"></div>
<div class="linenb">300</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">301</div><div class="codeline">\include{Chapters/Chapter1_intro.tex}</div><div class="clear"></div>
<div class="linenb">302</div><div class="codeline">\include{Chapters/Chapter2_Backgr.tex} </div><div class="clear"></div>
<div class="linenb">303</div><div class="codeline">\include{Chapters/Chapter3_Related.tex}</div><div class="clear"></div>
<div class="linenb">304</div><div class="codeline">\include{Chapters/Chapter4_proposed.tex} </div><div class="clear"></div>
<div class="linenb">305</div><div class="codeline">\include{Chapters/Chapter4_proposed2.tex} </div><div class="clear"></div>
<div class="linenb">306</div><div class="codeline">\include{Chapters/Chapter5_Experment.tex}</div><div class="clear"></div>
<div class="linenb">307</div><div class="codeline">\include{Chapters/Chapter6_Conc.tex}</div><div class="clear"></div>
<div class="linenb">308</div><div class="codeline">\include{Chapters/Chapter7_summ.tex}</div><div class="clear"></div>
<div class="linenb">309</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">310</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">311</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">312</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">313</div><div class="codeline"><span class="comment"><span class="comment">%------------</span></span></div><div class="clear"></div>
<div class="linenb">314</div><div class="codeline"><span class="comment"><span class="comment">%	THESIS CONTENT - APPENDICES</span></span></div><div class="clear"></div>
<div class="linenb">315</div><div class="codeline"><span class="comment"><span class="comment">%---------------</span></span></div><div class="clear"></div>
<div class="linenb">316</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">317</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">318</div><div class="codeline"><span class="comment"><span class="comment">% Include the appendices of the thesis as separate files from the Appendices folder</span></span></div><div class="clear"></div>
<div class="linenb">319</div><div class="codeline"><span class="comment"><span class="comment">% Uncomment the lines as you write the Appendices</span></span></div><div class="clear"></div>
<div class="linenb">320</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">321</div><div class="codeline"><span class="comment"><span class="comment">%\include{Appendices/AppendixA}</span></span></div><div class="clear"></div>
<div class="linenb">322</div><div class="codeline"><span class="comment"><span class="comment">%\include{Appendices/AppendixB}</span></span></div><div class="clear"></div>
<div class="linenb">323</div><div class="codeline"><span class="comment"><span class="comment">%\include{Appendices/AppendixC}</span></span></div><div class="clear"></div>
<div class="linenb">324</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">325</div><div class="codeline"><span class="comment"><span class="comment">%---------------</span></span></div><div class="clear"></div>
<div class="linenb">326</div><div class="codeline"><span class="comment"><span class="comment">%	BIBLIOGRAPHY</span></span></div><div class="clear"></div>
<div class="linenb">327</div><div class="codeline"><span class="comment"><span class="comment">%---------------</span></span></div><div class="clear"></div>
<div class="linenb">328</div><div class="codeline"><span class="comment"><span class="comment">% \include{Chapters/publication.tex}</span></span></div><div class="clear"></div>
<div class="linenb">329</div><div class="codeline">\nocite{zaki2021covid} </div><div class="clear"></div>
<div class="linenb">330</div><div class="codeline">\nocite{zaki2022covid} </div><div class="clear"></div>
<div class="linenb">331</div><div class="codeline">\printbibheading[heading=bibintoc]</div><div class="clear"></div>
<div class="linenb">332</div><div class="codeline">\printbibliography[keyword={publ}, heading=subbibliography, title={Publications}]</div><div class="clear"></div>
<div class="linenb">333</div><div class="codeline">\printbibliography[title={References}]</div><div class="clear"></div>
<div class="linenb">334</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">335</div><div class="codeline">\appendix <span class="comment">% Cue to tell LaTeX that the following "chapters" are Appendices</span></div><div class="clear"></div>
<div class="linenb">336</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">337</div><div class="codeline">\pagestyle{plain} <span class="comment">% Default to the plain heading style until the thesis style is called for the body content</span></div><div class="clear"></div>
<div class="linenb">338</div><div class="codeline">\include{Chapters/ArabSummery.tex}</div><div class="clear"></div>
<div class="linenb">339</div><div class="codeline">\include{Chapters/ArabAbst.tex}</div><div class="clear"></div>
<div class="linenb">340</div><div class="codeline">\include{Chapters/ArabCV.tex}</div><div class="clear"></div>
<div class="linenb">341</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">342</div><div class="codeline"><span class="comment"><span class="comment">%------------</span></span></div><div class="clear"></div>
<div class="linenb">343</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">344</div><div class="codeline"><span class="keyword2">\end{document}</span>  </div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/Chapter1_intro.tex</h2>

<p>Found 13 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;3</div><div class="codeline">\chapter{Introduction} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;5</div><div class="codeline"><span class="comment"><span class="comment">% Importance</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;6</div><div class="codeline"><span class="comment"><span class="comment">% Motivation</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;7</div><div class="codeline"><span class="comment"><span class="comment">% Application</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;8</div><div class="codeline"><span class="comment"><span class="comment">% challenges</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;9</div><div class="codeline"><span class="comment"><span class="comment">% thises Content</span></span></div><div class="clear"></div>
<div class="linenb">10</div><div class="codeline"><span class="comment"><span class="comment">% 3Pages of intro </span></span></div><div class="clear"></div>
<div class="linenb">11</div><div class="codeline"><span class="comment"><span class="comment">% RelatedW0Rk  </span></span></div><div class="clear"></div>
<div class="linenb">12</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">13</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">14</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">15</div><div class="codeline"><span class="keyword1">\label</span>{chp:intro} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">16</div><div class="codeline"><span class="keyword1">\section</span>{Novel Coronavirus Disease}</div><div class="clear"></div>
<div class="linenb">17</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">18</div><div class="codeline">COronaVIrus Disease 2019 (COVID-19) is a severe respiratory tract infections which can range from mild to lethal \cite{acter2020evolution}. COVID-19 is contagious disease that can readily spread through direct or indirect contact with an infected person \cite{singhal2020review}. COVID-19 caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). COVID-19 initially appeared in Wuhan, China late 2019 and spread world wide \cite{hui2020continuing}. World Health Organization (WHO) declared the outbreak of COVID-19 as Public Health Emergency of International Concern on  January 2020, and a pandemic on March 2020 \cite{platto2020covid19}.</div><div class="clear"></div>
<div class="linenb">19</div><div class="codeline">Ongoing SARS-CoV-2 infections have not only devastated human lives but also significantly damaged the financial health of both developing and developed countries. Therefore, there is an urgent need to control the pandemic by accelerating the development and mass production of efficacious vaccines against SARS-CoV-2. Healthcare practitioners, researchers, and policymakers around the globe were thrown a challenge to deliver adequate prevention and treatment modalities to combat the pandemic. From the initial stage of this pandemic, scientists were focused on either repurposing the existing drugs or developing vaccines against COVID-19 \cite{le2020evolution}. Fig. \ref{NorCovCXR} illustrates the difference between the COVID-19 and normal lungs.</div><div class="clear"></div>
<div class="linenb">20</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">21</div><div class="codeline">Typical diagnostic tools for COVID-19 are virus? nucleic acid by real-time reverse transcription polymerase chain reaction (rRT-PCR), transcription-mediated amplification (TMA), or by reverse transcription loop-mediated isothermal amplification (RT-LAMP) from a nasopharyngeal swab <span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{tahamtan2020real}.  These manual traditional methods are time-consuming and complex. Chest X-rays (CXR) and chest CT offer fast screening methods for COVID-19 \cite{salehi2020coronavirus}\cite</span>{wu2020new}<span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{zu2020coronavirus}. CXR and chest CT are preferred when RT-PCR testing is not available in time \cite{erickson1993advanced}. CXR has many advantages over chest CT including the widespread of the acquisition devices, low cost, and the speed of the acquisitio<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">n\cite</span>{narin2021automatic}\cite</span>{brenner2007computed}<span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{rubin2020role}\cite</span>{shi2020review}. These advantages lead CXR to be a fixed routine for hindering COVID-19 spread. </div><div class="clear"></div>
<div class="linenb">22</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">23</div><div class="codeline"><span class="keyword2">\begin{figure}</span><span class="comment">%</span></div><div class="clear"></div>
<div class="linenb">24</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">25</div><div class="codeline">    <span class="keyword2">\begin{subfigure}</span>[b]{0.4\textwidth}</div><div class="clear"></div>
<div class="linenb">26</div><div class="codeline">        \centering</div><div class="clear"></div>
<div class="linenb">27</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/introNormCXR.png}</div><div class="clear"></div>
<div class="linenb">28</div><div class="codeline">        <span class="keyword1">\caption</span>{Chest X-Ray image of normal lung.}</div><div class="clear"></div>
<div class="linenb">29</div><div class="codeline">        <span class="keyword1">\label</span>{<span class="highlight-sh" title="Figure NorCXR is never referenced in the text [sh:figref]">N</span>orCXR}</div><div class="clear"></div>
<div class="linenb">30</div><div class="codeline">    <span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">31</div><div class="codeline">    <span class="comment">% \hfill</span></div><div class="clear"></div>
<div class="linenb">32</div><div class="codeline">     <span class="keyword2">\begin{subfigure}</span>[b]{0.4\textwidth}</div><div class="clear"></div>
<div class="linenb">33</div><div class="codeline">         \centering</div><div class="clear"></div>
<div class="linenb">34</div><div class="codeline">         <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/intoCovidCXR.png}</div><div class="clear"></div>
<div class="linenb">35</div><div class="codeline">         <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Chest X-Ray image of COVID-19 patient</span>}</div><div class="clear"></div>
<div class="linenb">36</div><div class="codeline">         <span class="keyword1">\label</span>{CovCXR}</div><div class="clear"></div>
<div class="linenb">37</div><div class="codeline">     <span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">38</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Samples of CXR images of Normal and COVID-19 pneumonia</span>}<span class="comment">%</span></div><div class="clear"></div>
<div class="linenb">39</div><div class="codeline">    <span class="keyword1">\label</span>{NorCovCXR}<span class="comment">%</span></div><div class="clear"></div>
<div class="linenb">40</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">41</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">42</div><div class="codeline"><span class="keyword1">\section</span>{Motivation}</div><div class="clear"></div>
<div class="linenb">43</div><div class="codeline">Fig. \ref{hospitalRoutine} illustrates typical Egyptian hospitals routine for reducing COVID-19 spread among healthcare workers. This process is performed for every visitor of the hospital. Phases of CBC Test and PCR test are automated and does not consume time. While CXR image diagnosing involves human factor which act a bottleneck of the process. This process can be fully automated using image classification models. As a consequence <span class="keyword1">\textit</span>{1)} Total time required for every visitor will be reduced. <span class="keyword1">\textit</span>{2)} Work load of radiologist is reduced. </div><div class="clear"></div>
<div class="linenb">44</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">45</div><div class="codeline"><span class="keyword2">\begin{figure}</span><span class="comment">%</span></div><div class="clear"></div>
<div class="linenb">46</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">47</div><div class="codeline">        <span class="keyword1">\includegraphics</span>[width=\textwidth]{Figures/HosPitalCovidRoutine.png}</div><div class="clear"></div>
<div class="linenb">48</div><div class="codeline">        <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Typical hospitals routine of reducing COVID-19 spread</span>}</div><div class="clear"></div>
<div class="linenb">49</div><div class="codeline">        <span class="keyword1">\label</span>{hospitalRoutine}</div><div class="clear"></div>
<div class="linenb">50</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">51</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">52</div><div class="codeline">Deep learning <span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{lecun2015deep} models, namely convolutional Neural Network (CNN) \cite{lecun1989handwritten}, have shown a great performance in computer vision problems such as object detection \cite{erhan2014scalable}\cite</span>{girshick2014rich}<span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{sermanet2013overfeat}\cite</span>{redmon2016you} and object recognition <span class="highlight-sh" title="Put all references in a single \cite command [sh:c:mul]">\cite{simonyan2014very}\cite</span>{he2016deep}. CNN is initially introduced <span class="highlight-sh" title="Do not use 'in [X]': the syntax of a sentence should not be changed by the removal of a citation. [sh:c:noin]">in \cite{</span>lecun1989handwritten}. CNN  is based on hierarchical learning of the convolutional kernels which organized in  layers \cite{krizhevsky2012imagenet}. The function of lower order layers is to learn low level features such as edges and corner points \cite{zeiler2014visualizing}. Higher order layers learn a high level features such as objects \cite{zeiler2014visualizing}. Typical CNN architecture is a number of convolutional layers that is connected sequentially \cite{simonyan2014very}. This sequential connection of the layers does not scale well for deep CNN \cite{he2016deep}. CNN shows a great performance when it has large number of layers \cite{he2016deep}. To allow CNN to take the advantage of deep architecture, residual connections are used \cite{he2016deep}. Residual connections solve the vanishing gradient problem when gradients approach zeros. Also, residual connections allow the reuse of earlier features \cite{huang2017densely}. Layers with  residual connections are easier to optimize than plain layers as it can easily approximate the identity mapping \cite{he2016deep}. In this thesis CNN is used to automated and accelerate the diagnosing pipeline of the COVID-19. </div><div class="clear"></div>
<div class="linenb">53</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">54</div><div class="codeline"><span class="keyword1">\section</span>{Detection Challenges}</div><div class="clear"></div>
<div class="linenb">55</div><div class="codeline">Like many computer vision problem COVID-19 has the following challenges</div><div class="clear"></div>
<div class="linenb">56</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">57</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">58</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Availability of Data.} CNN is a deep learning technique that require large number of a training Images. However, current COVID-19 dataset are small-size dataset which is a challenging to train large networks with. </div><div class="clear"></div>
<div class="linenb">59</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Scale.} Like many computer vision models CNN is scale variant. CNN can not recognize images with scales different from the scales in it trained on.</div><div class="clear"></div>
<div class="linenb">60</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Vanishing Gradient Problem.} Deep CNN suffer vanishing gradient which prevent CNN parameters to be updated.</div><div class="clear"></div>
<div class="linenb">61</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Exploding Gradient Problem.} Deep CNN suffer Exploding gradient which make CNN diverge.</div><div class="clear"></div>
<div class="linenb">62</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">63</div><div class="codeline">Proposed Systems try to overcome these problems as will be detailed in chapters \ref{chp:proposed1} and \ref{chp:proposed2}.</div><div class="clear"></div>
<div class="linenb">64</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">65</div><div class="codeline"><span class="keyword1">\section</span>{Thesis Objective and Contributions}</div><div class="clear"></div>
<div class="linenb">66</div><div class="codeline">Objective of this thesis is to improve classification accuracy and reduce computational complexity of detecting COVID-19 cases from CXR Images. Contributions of this thesis as follows.</div><div class="clear"></div>
<div class="linenb">67</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">68</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Lightweight classification model.} Lightweight classification model with very low parameter number is proposed for classification the CXR images. It reduces the computational complexity which allows deployment on mobile devices and saving bandwidth of the network during model distribution process. </div><div class="clear"></div>
<div class="linenb">69</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Scale invariant model.}  Pneumonia scales in CXR are not uniform distributed which prevent CNN from recognizing infrequent scales. Scale invariant model is proposed for detection COVID-19 pneumonia at different scales.</div><div class="clear"></div>
<div class="linenb">70</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textit</span>{High Detection accuracy.} Proposed systems provide superior performance according to various classification metrics.</div><div class="clear"></div>
<div class="linenb">71</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">72</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">73</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 116 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span>{Thesis Organization}</div><div class="clear"></div>
<div class="linenb">74</div><div class="codeline">This thesis is organized as follows: </div><div class="clear"></div>
<div class="linenb">75</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">76</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:background}}: includes required Background to understand the Thesis. </div><div class="clear"></div>
<div class="linenb">77</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:related}}: includes and illustrates the recent and related work in the COVID-19 detection literature. </div><div class="clear"></div>
<div class="linenb">78</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:proposed1}}: presents the proposed work I which presents a lightweight classification model.</div><div class="clear"></div>
<div class="linenb">79</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:proposed2}}: presents the proposed work II which includes the scale invariant model for COVID-19 classification. </div><div class="clear"></div>
<div class="linenb">80</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:results}}: illustrates the experimental results for both proposed work I and II and quantitative analysis of the proposed work I and II is provided.</div><div class="clear"></div>
<div class="linenb">81</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:concl}}: concludes the thesis and provide planning for the future work as extension of the proposed approach</div><div class="clear"></div>
<div class="linenb">82</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/ArabSummery.tex</h2>

<p>Found 0 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;2</div><div class="codeline"><span class="keyword2">\begin{arab}</span>[utf]</div><div class="clear"></div>
<div class="linenb">&nbsp;3</div><div class="codeline"><span class="comment"><span class="comment">% \appendix</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;4</div><div class="codeline">\chapter*{\textarab[utf]{???? ???????}} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;5</div><div class="codeline">\addchaptertocentry{\textarab[utf]{???? ???????}}</div><div class="clear"></div>
<div class="linenb">&nbsp;6</div><div class="codeline"><span class="keyword1">\label</span>{araSummery} </div><div class="clear"></div>
<div class="linenb">&nbsp;7</div><div class="codeline">??????? ??????? ?? ????? ?????? (COVID-19) ????? ?? ???????? ????? ?? ??????? ???????? ?????? ????? ?? ???? ??????? ???????? ????????? ??? ??? ??? ????? ???? ??????? ?????? ??????? ??? ???? ?????. ??? ???? ?????? ???????? ??????? ????? ?????? ??? ????? ??????? ?????? ?????? ??? ????? ?????? ?????? ?????. ??? ????? ??????? ??????? ????????? (CNNs) ?????? ?? ???? ?????? ?? ?????? ?????????? ?????? ????? ?????? ??????? ?????? ???????. ?? ??? ???????? ??????? ??????? ????? ???????? ??????? ???????? ?????? ????????? ???????? ??? ????? ???? ????? ?????? COVID-19.</div><div class="clear"></div>
<div class="linenb">&nbsp;8</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;9</div><div class="codeline">????? ??????? CNN-I ?????? ??????? ??????? ????????? ?????? ???????? ?????? ??? ??????? ??????? ???? ????? ???? ????? ??????? ?????? ??? ????? ??????. ??????? ??????? ?????? ???????? ??? ??????? ????? ?????? ??? ??????? ?????? ?????? ?????? ??????. ???? ?????? ??? ??????? ?????? ??? ?????? ???????? ???????? QaTa-Cov19? ?????? ??? ??????? ???? ? F1-score ????? 100? ???? ??????? ????? ???? 150 ??? ???? ??? ??? ????? ?? ???????? ?????? ?? ????????. ????? ???????? ???? ??????? ???????? ????????? ??????? ?????? ?????? ???? ????? ????? ?? ???? ????? ???????? ?????? ?? ???? ??????? ???????? ??????.</div><div class="clear"></div>
<div class="linenb">10</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">11</div><div class="codeline">??????? ?????? ???? ??????? CNN-II? ????? ??????? ?????? ????????? ???????? ??? ?? ??? ??????? ???????? ??????? ?????? ??????? ??? ????? ???????. ??? ??????? ???? ????? ??? ???????? ?????? ??????? ??????? ?????? ??? ?????. CNN-II ?? ???? ????? ??????? ?? ??????? ??? ??????? ????? ????? ??????? ???????? ??????? ???????? ?????? ?????? ??????. ??? ??? ??????? F1-score ????? 0.9929 ??? ??????? ??? ?????? ?????? ???????? QaTa-Cov19? ?? ?????? 5?040?571 ??????? ?????? ???????. ????? ?? SWASPP (??????? ?????? ??????? ??????? ?????? ??????? ???????) ???? ?? ???? ????? ?????? ???????? ????? ???????? ?????? ?????? ?? ???????? ?????? ????????. ???????? ??? ???? ???? ????? ??? ????? ?????? ????? ?????? ?? ???????? ??????.</div><div class="clear"></div>
<div class="linenb">12</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">13</div><div class="codeline">?? ???????? ???? ??? ??????? ??????? ?????? ????? ?????? COVID-19 ?????? ?? ?????? ???? ????? ????? CNN ?????????. ???? ??? ???????? ??? ????? ?? ????? ??????? ???????? ???? ?????????. ???? ??????? ?????????? ??????? ????? ???????? ?????? ??????? ???????? ?????? ?????? ?? ?????? ?????? ?????? ??????. ??? ??? ????? ?????? ??? ????? ????? COVID-19 ????????? ?? ????? ??? ????? ?????? ??????? ??????? ??????????.</div><div class="clear"></div>
<div class="linenb">14</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">15</div><div class="codeline">    ????? ??????? ??? ????? ??????:</div><div class="clear"></div>
<div class="linenb">16</div><div class="codeline">    <span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">17</div><div class="codeline">        <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ?????}}: \textarab[utf]{????? ??? ????? ?? ??? ?????19 ???????? ???? ?????? ???????. ???? ??? ??? ??????? ???????? ??????? ? ????????? ???? ?????? ??????? ?? ??? ??????.}</div><div class="clear"></div>
<div class="linenb">18</div><div class="codeline">        <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ??????}}: \textarab[utf]{ ???? ????? ???? ?? ??????????? ????  ???? ????????? ??????? ?? ??????? ?????? ???  ?????19. }</div><div class="clear"></div>
<div class="linenb">19</div><div class="codeline">        <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ??????}}: \textarab[utf]{??? ????? ???? ????? ???????? ????? ???????? ???? ?????? ????? ??????? ????? ?? ????? ????.}</div><div class="clear"></div>
<div class="linenb">20</div><div class="codeline">        <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ??????}}: \textarab[utf]{???? ????? ???????? ?? ???? ????? ??????? ????? ?????? ???? ?????19 ????? ??? ??? ?????? ??? ??? ???????? ????????.}</div><div class="clear"></div>
<div class="linenb">21</div><div class="codeline">        <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ??????}}: \textarab[utf]{ ???? ????? ???????? ?? ???? ????? ??????? ?????? ?????? ???? ?????19.}</div><div class="clear"></div>
<div class="linenb">22</div><div class="codeline">        <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ??????}}: \textarab[utf]{???? ?????? ??????? ???? ?????? ?????????.}</div><div class="clear"></div>
<div class="linenb">23</div><div class="codeline">        <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{????? ??????}}: \textarab[utf]{????? ??? ??? ??? ?? ?????? ?? ??????? ????? ??? ?????? ???????? ??????? ??????????.}</div><div class="clear"></div>
<div class="linenb">24</div><div class="codeline">        <span class="comment">% <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{\textarab[utf]{}}: \textarab[utf]{}</span></div><div class="clear"></div>
<div class="linenb">25</div><div class="codeline">    <span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">26</div><div class="codeline"><span class="keyword2">\end{arab}</span></div><div class="clear"></div>
</div>
<h2 class="filename">./Tables/relatedlatex.tex</h2>

<p>Found 1 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;1</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;2</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;3</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{<span class="keyword1">\label</span>{tbl:related}Overview of recent studies for classifying COVID19</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;4</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;5</div><div class="codeline"><span class="keyword2">\begin{adjustbox}</span>{angle=90}</div><div class="clear"></div>
<div class="linenb">&nbsp;6</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|l|r|r|l|l|l|}<span class="comment">%{lrrlll}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;7</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;8</div><div class="codeline">Work &amp;  \#Samples &amp;  Classes &amp;  Model &amp;  Best Performing Model &amp;   Performance \\</div><div class="clear"></div>
<div class="linenb">&nbsp;9</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">10</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">11</div><div class="codeline">~\cite{35apostolopoulos2020covid} &amp; 1428 &amp;    3 &amp; VGG19, MobileNetV2, &amp;   MobileNetV2 &amp; Acc = 96.78\%  \\</div><div class="clear"></div>
<div class="linenb">12</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">13</div><div class="codeline">      &amp;      &amp;    &amp; Inception, Xception &amp;    &amp;   \\</div><div class="clear"></div>
<div class="linenb">14</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">15</div><div class="codeline">~\cite{36hall2020finding} &amp;  204 &amp;    2 &amp;   VGG16 + Resnet50 &amp; VGG16 + Resnet50, &amp;    Acc = 89.2\% \\</div><div class="clear"></div>
<div class="linenb">16</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">17</div><div class="codeline">     &amp;    &amp;      &amp;                        &amp;   custom CNN &amp;      \\</div><div class="clear"></div>
<div class="linenb">18</div><div class="codeline">\hline           </div><div class="clear"></div>
<div class="linenb">19</div><div class="codeline">~\cite{37narin2021automatic} &amp;  100 &amp;    2 &amp;   ResNet50, InceptionV3, &amp;  ResNet50 &amp;  Acc = 98\% \\</div><div class="clear"></div>
<div class="linenb">20</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">21</div><div class="codeline">&amp;    &amp;      &amp;   and InceptionRes-NetV2 &amp;   &amp;    \\</div><div class="clear"></div>
<div class="linenb">22</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">23</div><div class="codeline">~\cite{38tang2020automated} &amp;    21152 &amp;    2 &amp;    CNN &amp;   CNN &amp;   Acc = 94.64\% \\</div><div class="clear"></div>
<div class="linenb">24</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">25</div><div class="codeline">~\cite{39minaee2020deep}  &amp; 5184 &amp;    2 &amp;   ResNet18, ResNet50, &amp;    SqueezeNet &amp; Sensitivity = 98\%\\</div><div class="clear"></div>
<div class="linenb">26</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">27</div><div class="codeline">  &amp;   &amp;      &amp;     SqueezeNet, DenseNet-121 &amp;      &amp;  \\</div><div class="clear"></div>
<div class="linenb">28</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">29</div><div class="codeline">~\cite{40afshar2020covid}  &amp;    13975 &amp;    2 &amp; COVID-CAPS &amp;    COVID-CAPS &amp;   Acc = 95.7\%, \\</div><div class="clear"></div>
<div class="linenb">30</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">31</div><div class="codeline">~\cite{41ahsan2020covid}  &amp;  400 &amp;    2 &amp; VGG16, InceptionResNetV2, &amp;  NasNetMobile &amp;   Acc = 93.94\% \\</div><div class="clear"></div>
<div class="linenb">32</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">33</div><div class="codeline">  &amp;    &amp;      &amp;  ResNet50, DenseNet201  &amp;    &amp;     \\</div><div class="clear"></div>
<div class="linenb">34</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">35</div><div class="codeline">~\cite{42hemdan2020covidx}  &amp;   75 &amp;    2 &amp; VGG19, Xception,  &amp;   VGG19, DenseNet &amp;   F1 scores = 0.91 \\</div><div class="clear"></div>
<div class="linenb">36</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">37</div><div class="codeline">  &amp;     &amp;      &amp;  ResNetV2, DenseNet201 &amp;     &amp;    \\</div><div class="clear"></div>
<div class="linenb">38</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">39</div><div class="codeline">~\cite{43ozturk2020automated}  &amp; 1127 &amp;    2 &amp;   Modified Darknet &amp;  Modified Darknet &amp;  Acc = 98\% \\</div><div class="clear"></div>
<div class="linenb">40</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">41</div><div class="codeline">~\cite{44khan2020coronet}  &amp; 1257 &amp;    3 &amp;   Xception &amp;  Xception &amp;  Acc = 94\% \\</div><div class="clear"></div>
<div class="linenb">42</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">43</div><div class="codeline">~\cite{45chandra2021coronavirus} &amp; 2356 &amp;    3 &amp;    ACoS system &amp;  ACoS &amp;   Acc = 91.33\% \\</div><div class="clear"></div>
<div class="linenb">44</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">45</div><div class="codeline">~\cite{46sekeroglu2020covid19} &amp; 6100 &amp;    3 &amp; SVM, LR, DT, &amp;   Mean result &amp;    Acc = 98.5\% \\</div><div class="clear"></div>
<div class="linenb">46</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">47</div><div class="codeline">  &amp;   &amp;      &amp;   kNN + VGG16,  &amp;    &amp;    \\</div><div class="clear"></div>
<div class="linenb">48</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">49</div><div class="codeline">  &amp;   &amp;      &amp;    ResNet50 &amp;    &amp;    \\</div><div class="clear"></div>
<div class="linenb">50</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">51</div><div class="codeline">~\cite{47pandit2021automatic}&amp; 1428 &amp;    2 &amp;  VGG16 &amp; VGG16 &amp;  Acc = 96\% \\</div><div class="clear"></div>
<div class="linenb">52</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">53</div><div class="codeline">~\cite{48arias2020artificial} &amp;    79500 &amp;    3 &amp;   Grad-CAM &amp;  Grad-CAM &amp;    Acc = 91.5\% \\</div><div class="clear"></div>
<div class="linenb">54</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">55</div><div class="codeline">~\cite{49yamac2021convolutional} &amp; 6200 &amp;    4 &amp;  CSEN-based classifier &amp; CSEN-based Classifier &amp;    Sensitivity = 98\% \\</div><div class="clear"></div>
<div class="linenb">56</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">57</div><div class="codeline">~\cite{50wang2020covid} &amp;    13975 &amp;   19 &amp;  COVID-Net &amp; COVID-Net &amp;    Acc = 93.3\% \\</div><div class="clear"></div>
<div class="linenb">58</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">59</div><div class="codeline">~\cite{51abbas2021classification} &amp;  196 &amp;    3 &amp; DeTrac &amp;    Detrac &amp;    Acc = 93.1\% \\</div><div class="clear"></div>
<div class="linenb">60</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">61</div><div class="codeline">~\cite{52toraman2020convolutional} &amp; 3150 &amp;    3 &amp;    CapsNet &amp;   CapsNet &amp;  Acc = 97\% \\</div><div class="clear"></div>
<div class="linenb">62</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">63</div><div class="codeline">~\cite{53das2022automated} &amp; 1127 &amp;    3 &amp;   Xception &amp;  Xception &amp;  Acc = 97\% \\</div><div class="clear"></div>
<div class="linenb">64</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">65</div><div class="codeline">~\cite{54hu2020learning} &amp; 7470 &amp;    2 &amp;    MD-Conv &amp;   MD-Conv &amp;    Acc = 93.4\% \\</div><div class="clear"></div>
<div class="linenb">66</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">67</div><div class="codeline">~\cite{55ismael2021deep} &amp;  380 &amp;    2 &amp;    Novel CNN Model &amp;   Novel CNN Model &amp;    Acc = 91.6\% \\</div><div class="clear"></div>
<div class="linenb">68</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">69</div><div class="codeline">~\cite{56shankar2021optimal} &amp;  247 &amp;    2 &amp;   BMO-CRNN &amp;  BMO-CRNN &amp;  Acc = 97.31\% \\</div><div class="clear"></div>
<div class="linenb">70</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">71</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">72</div><div class="codeline"><span class="keyword2">\end{adjustbox}</span></div><div class="clear"></div>
<div class="linenb">73</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">74</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/Chapter6_Conc.tex</h2>

<p>Found 0 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;3</div><div class="codeline">\chapter{Conclusion And Future Work} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:concl} <span class="comment">% </span></div><div class="clear"></div>
<div class="linenb">&nbsp;6</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;7</div><div class="codeline"><span class="comment"><span class="comment">% COVID-19 is a severe respiratory tract infections. COVID-19 caused by SARS-CoV-2 can readily spread through a contact with an infected person. Monotonically increasing SARS-CoV-2 infections have not only wasted lives but also severely damaged the financial systems of both developing and developed countries. This high spread rate pressure on the health care systems which rise the need to fast methods for diagnosing this disease. Convolutional Neural Networks (CNN) show a great success for various computer vision tasks. However, CNN is a scale-variant model and computationally expensive. In this Thesis, a novel architectures are proposed for multiscale feature extraction and classification and lightweight architecture for COVID-19 diagnosing. The proposed I which is a lightweight CNN model exploits spatial kernel separability to reduce the number of the training parameters to a large extent and regularize the model to only learns linear kernel. Furthermore, This model uses residual connection and batch normalization extensively to maintain the network stability during the training process and provide the model with the regularization effect to reduce the overfitting. This lightweight architecture is trained using QaTa-Cov19 benchmark dataset achieving  100\% for accuracy, sensitivity, precision and F1-score with a very low parameter count (150K) compared with the other methods in the literature. As a future work attention and context attention can benefit the performance. Also evaluating atrous convolution can in the context of spatial separability can be beneficial. Proposed CNN II learns multiscale features using a pyramid of shared convolution kernels with different atrous rates. This scale invariant CNN uses attention based mechanism that is used to guide and select correct scale for each input. Proposed CNN II is an end-to-end trainable network and exploit a novel augmentation technique, Texture Augmentation, to reduce the overfitting. Proposed method II achieved a 0.9929 for $F1-score$ tested on QaTa-Cov19 benchmark dataset with a total of $5,040,571$ trainable parameters. SWASPP can be show a great performance for the segmentation specially atrous convolution originating at the segmentation literature, Also this work can be extended to classify a various pneumonia types.</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;8</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;9</div><div class="codeline">The COVID-19 pandemic has caused severe respiratory tract infections that have rapidly spread through contact with infected individuals, resulting in devastating loss of life and economic damage worldwide. The high rate of transmission has put tremendous pressure on healthcare systems to develop fast and accurate methods for diagnosing the disease. Convolutional Neural Networks (CNNs) have shown success in various computer vision tasks, but they are scale-variant and computationally expensive. In this thesis, we proposed novel architectures for multiscale feature extraction and classification, as well as a lightweight architecture for COVID-19 diagnosis.</div><div class="clear"></div>
<div class="linenb">10</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">11</div><div class="codeline">The proposed lightweight CNN model, referred to as CNN-I, exploits spatial kernel separability to significantly reduce the number of training parameters, and regularizes the model to only learn linear kernels. To maintain network stability and reduce overfitting, residual connections and batch normalization are extensively used. We trained this lightweight architecture on the QaTa-Cov19 benchmark dataset, achieving $100\%$ accuracy, sensitivity, precision, and F1-score with a parameter count of only 150K, which is significantly lower than other methods in the literature. As future work, attention and context attention can be explored to further enhance performance, and evaluating atrous convolution in the context of spatial separability may be beneficial.</div><div class="clear"></div>
<div class="linenb">12</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">13</div><div class="codeline">Our second proposed architecture, CNN-II, learns multiscale features using a pyramid of shared convolution kernels with different atrous rates, making it scale-invariant. An attention-based mechanism is used to guide and select the correct scale for each input. CNN-II is an end-to-end trainable network that exploits a novel augmentation technique, Texture Augmentation, to reduce overfitting. This architecture achieved an F1-score of 0.9929 when tested on the QaTa-Cov19 benchmark dataset, with a total of 5,040,571 trainable parameters. We suggest that the SWASPP (Spatial Pyramid Atrous Spatial Pyramid Pooling) can show great performance for segmentation, especially atrous convolution originating in the segmentation literature. Additionally, this work can be extended to classify various types of pneumonia.</div><div class="clear"></div>
<div class="linenb">14</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">15</div><div class="codeline">In conclusion, this thesis proposes novel architectures for COVID-19 diagnosis that address the limitations of traditional CNN models. These architectures achieved high accuracy while reducing computational cost and parameter count. Further research can explore attention mechanisms and evaluate the use of atrous convolution in the context of spatial separability to improve performance. This work has the potential to improve COVID-19 diagnosis and aid in the development of fast and effective methods to combat future pandemics.</div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/Chapter7_summ.tex</h2>

<p>Found 0 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;3</div><div class="codeline">\chapter{Summary} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:summ} <span class="comment">% </span></div><div class="clear"></div>
<div class="linenb">&nbsp;6</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;7</div><div class="codeline"><span class="comment"><span class="comment">% COVID-19 is a severe respiratory tract infections. COVID-19 caused by SARS-CoV-2 can readily spread through a contact with an infected person. Monotonically increasing SARS-CoV-2 infections have not only wasted lives but also severely damaged the financial systems of both developing and developed countries. This high spread rate pressure on the health care systems which rise the need to fast methods for diagnosing this disease. Convolutional Neural Networks (CNN) show a great success for various computer vision tasks. However, CNN is a scale-variant model and computationally expensive. In this Thesis, a novel architectures are proposed for multiscale feature extraction and classification and lightweight architecture for COVID-19 diagnosing. The proposed I which is a lightweight CNN model exploits spatial kernel separability to reduce the number of the training parameters to a large extent and regularize the model to only learns linear kernel. Furthermore, This model uses residual connection and batch normalization extensively to maintain the network stability during the training process and provide the model with the regularization effect to reduce the overfitting. This lightweight architecture is trained using QaTa-Cov19 benchmark dataset achieving  100\% for accuracy, sensitivity, precision and F1-score with a very low parameter count (150K) compared with the other methods in the literature. As a future work attention and context attention can benefit the performance. Also evaluating atrous convolution can in the context of spatial separability can be beneficial. Proposed CNN II learns multiscale features using a pyramid of shared convolution kernels with different atrous rates. This scale invariant CNN uses attention based mechanism that is used to guide and select correct scale for each input. Proposed CNN II is an end-to-end trainable network and exploit a novel augmentation technique, Texture Augmentation, to reduce the overfitting. Proposed method II achieved a 0.9929 for $F1-score$ tested on QaTa-Cov19 benchmark dataset with a total of $5,040,571$ trainable parameters. SWASPP can be show a great performance for the segmentation specially atrous convolution originating at the segmentation literature, Also this work can be extended to classify a various pneumonia types.</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;8</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;9</div><div class="codeline">The COVID-19 pandemic has caused severe respiratory tract infections that have rapidly spread through contact with infected individuals, resulting in devastating loss of life and economic damage worldwide. The high rate of transmission has put tremendous pressure on healthcare systems to develop fast and accurate methods for diagnosing the disease. Convolutional Neural Networks (CNNs) have shown success in various computer vision tasks, but they are scale-variant and computationally expensive. In this thesis, we proposed novel architectures for multiscale feature extraction and classification, as well as a lightweight architecture for COVID-19 diagnosis.</div><div class="clear"></div>
<div class="linenb">10</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">11</div><div class="codeline">The proposed lightweight CNN model, referred to as CNN-I, exploits spatial kernel separability to significantly reduce the number of training parameters, and regularizes the model to only learn linear kernels. To maintain network stability and reduce overfitting, residual connections and batch normalization are extensively used. We trained this lightweight architecture on the QaTa-Cov19 benchmark dataset, achieving $100\%$ accuracy, sensitivity, precision, and F1-score with a parameter count of only 150K, which is significantly lower than other methods in the literature. As future work, attention and context attention can be explored to further enhance performance, and evaluating atrous convolution in the context of spatial separability may be beneficial.</div><div class="clear"></div>
<div class="linenb">12</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">13</div><div class="codeline">Our second proposed architecture, CNN-II, learns multiscale features using a pyramid of shared convolution kernels with different atrous rates, making it scale-invariant. An attention-based mechanism is used to guide and select the correct scale for each input. CNN-II is an end-to-end trainable network that exploits a novel augmentation technique, Texture Augmentation, to reduce overfitting. This architecture achieved an F1-score of 0.9929 when tested on the QaTa-Cov19 benchmark dataset, with a total of 5,040,571 trainable parameters. We suggest that the SWASPP (Spatial Pyramid Atrous Spatial Pyramid Pooling) can show great performance for segmentation, especially atrous convolution originating in the segmentation literature. Additionally, this work can be extended to classify various types of pneumonia.</div><div class="clear"></div>
<div class="linenb">14</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">15</div><div class="codeline">In conclusion, this thesis proposes novel architectures for COVID-19 diagnosis that address the limitations of traditional CNN models. These architectures achieved high accuracy while reducing computational cost and parameter count. Further research can explore attention mechanisms and evaluate the use of atrous convolution in the context of spatial separability to improve performance. This work has the potential to improve COVID-19 diagnosis and aid in the development of fast and effective methods to combat future pandemics.</div><div class="clear"></div>
<div class="linenb">16</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">17</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">18</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:intro}}: briefly discussed the history of COVID-19 and the importance of automating COVID-19 detection.</div><div class="clear"></div>
<div class="linenb">19</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:background}}: includes required Background to understand the Thesis. </div><div class="clear"></div>
<div class="linenb">20</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:related}}: includes and illustrates the recent and related work in the COVID-19 detection literature. </div><div class="clear"></div>
<div class="linenb">21</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:proposed1}}: presents the proposed work I which presents a lightweight classification model.</div><div class="clear"></div>
<div class="linenb">22</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:proposed2}}: presents the proposed work II which includes the scale invariant model for COVID-19 classification. </div><div class="clear"></div>
<div class="linenb">23</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:results}}: illustrates the experimental results for both proposed work I and II and quantitative analysis of the proposed work I and II is provided.</div><div class="clear"></div>
<div class="linenb">24</div><div class="codeline">    <span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Chapter \ref{chp:concl}}: concludes the thesis and provide planning for the future work as extension of the proposed approach</div><div class="clear"></div>
<div class="linenb">25</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/Chapter5_Experment.tex</h2>

<p>Found 22 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">\chapter{Experimental Results} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:results} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use~\ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">In this chapter proposed methodologies are evaluated and compared with the related work.</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline">All models are Trained using QaTa-Cov-19~\cite{ahishali2021advance} dataset using NVIDIA Tesla P-100 GPU and programmed using PyTorch.</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline"><span class="keyword1">\section</span>{QaTa-COV19 Dataset}</div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=60mm,width=9cm]{ScaleDist.png}}</div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Pneumonia Scales of QaTa-COV19-v1, Y-axis represents the frequency, number of occurrence, of a pneumonia with a particular area</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline"><span class="keyword1">\label</span>{pdist}</div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline">QaTa-COV19 is a benchmark dataset for COVID-19 detection and Segmentation form CXR images. All models that used for comparison are trained using QaTa-COV19-v1. Qata-COV19-v1 consists of 4603 COVID-19 CXR and $120,013$ control group CXRs. A balanced number of samples for the two classes is used, namely 4603 CXR image for each class to train the models. Pneumonia Scales of QaTa-COV19-v1 does not exhibit a uniform distribution. Scale of the Pneumonia can be defined as number, area, of 8-neighbor connected pixels labeled as COVID-19 pneumonia. QaTa-COV19-v1 provides a binary masks of 2951 COVID-19 CXR image which can be used for approximating the distribution of scales across the dataset. Fig.~\ref{pdist} illustrates the statistical distribution of QaTa-COV19 scales. The non-uniform distribution of the scales allows the CNN models to only recognize the small scales and not large scales.</div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline"><span class="keyword1">\section</span>{Evaluation of the Methodology I}</div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline">Experiments are conducted on a Lenovo Z50-70 with Intel CORE i7-4510U CPU 2.00 GHz, 8GB RAM, NVIDIA GeForce 840M GPU; and with python and PyTorch library.</div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline"><span class="keyword1">\subsection</span>{Details of the Proposed Architecture}</div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline">The Proposed architecture composed Convbase and Densebase. Convbase is composed of a $6$ feature extraction modules <span class="keyword1">\textit</span>{(FX)} preceded by batch normalization layer. Each FX module can be considered sub-sequential model consists of RSB layer followed by Batch Normalization, Max-pooling and LeakyReLU activation function. The Densebase is a two fully connected layers that classify the Convbase output.</div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline"><span class="keyword1">\subsection</span>{Hyperparameter Specification}</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline">All input chest X-Ray images are resized to be $200\times 200$ . After resizing the input images, these images are fed the Convbase model part which consists of 6 layers of residual separated block. Each residual separated block is followed with batch normalization and LeakyReLU~\cite{he2015delving} as activation function. The output depth of each residual separated block is 4$\times$16, 4$\times$32, 4$\times$64, 4$\times$64, 4$\times$64 and 4$\times$16, respectively. The output of Convbase model part is 1D feature vector of 576 length. Densebase model part consists of two hidden layers. Each layer has the  size of 64 and the output layer of size 2. Each layer of Densebase layers is fully connected to its previous layer. The activation function used in the densebase model part is LeakyReLU. Table~\ref{lyrSpec} summarizes the architecture hyperparameters.</div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{The proposed architecture hyperparameters</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|l|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline"><span class="keyword1">\textbf</span>{Layer Number} &amp; <span class="keyword1">\textbf</span>{Layer Size} &amp; <span class="keyword1">\textbf</span>{Activation Function} \\</div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">RSBLayer1 &amp; 4 $\times$ 16 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline">RSBLayer2 &amp; 4 $\times$ 23 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline">RSBLayer3 &amp; 4 $\times$ 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline">RSBLayer4 &amp; 4 $\times$ 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline">RSBLayer5 &amp; 4 $\times$ 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline">RSBLayer6 &amp; 4 $\times$ 16 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline">\multicolumn{3}{|c|}{<span class="keyword1">\textit</span>{Flatten The Feature maps to 1D 576 feature  vector}}\\</div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline">\cline{1-3}</div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline">LinearLayer1 &amp; 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline">LinearLayer2 &amp; 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">LinearLayer3 &amp; 2 &amp; Softmax\\</div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline"><span class="keyword1">\label</span>{lyrSpec}</div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline"><span class="keyword1">\subsection</span>{Network Training}</div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">The proposed CNN model  is trained for 22 epoch. Adaptive Moment Estimation (Adam) optimizer~\cite{kingma2014adam} is a popular optimization  technique for training deep networks. Adam optimizer is used  during the training  phase of the proposed CNN model. Both batch size and Adam optimizer learning rate is changed during the training phase if the training loss stopped decreasing. Table~\ref{tabTrparam} summarizes the parameters values used in the training phase of the proposed CNN model. Fig.~\ref{fig5}(a) show the progress for training and validation loss across each epoch. The difference between the training loss and validation loss through epochs show that our did not memorize the dataset.</div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{The change of batch size and learning rate through the Training process</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|l|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline"><span class="keyword1">\textbf</span>{Epoch Number} &amp; <span class="keyword1">\textbf</span>{Batch Size} &amp; <span class="keyword1">\textbf</span>{Learning Rate} \\</div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">From 0 to 6 &amp; 128 &amp; 1e-3\\</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline">From 7 to 12 &amp; 256 &amp; 1e-3\\</div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline">From 13 to 21 &amp; 256 &amp; 1e-4\\</div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline"> </div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline"><span class="keyword1">\label</span>{tabTrparam}</div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline"><span class="keyword1">\subsection</span>{Model Evaluation}</div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline">To assess the efficiency of the proposed method,  the proposed method is compared to recent state-of-the-art methods for detecting Covid-19 cases. Experiments are conducted with the same dataset and the corresponding hyperparameter of each work. All the methods depend on CNN. The comparison is performed using precision, sensitivity, F1-score, and accuracy~\cite{hossin2015review}. In addition, the number of the parameters used in the training phase is very important comparison factor. Table~\ref{modelperf} depicts the comparison between state-of-the-art methods and the proposed method. As shown in the comparison, the proposed method  outperforms other methods achieving the maximum accuracy and the lowest  parameter count. </div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline"><span class="keyword1">\caption</span>{ A performance comparison between the proposed method and state-of-the-art models.}</div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|l|c|c|c|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline"><span class="keyword1">\textbf</span>{Method} &amp; <span class="keyword1">\textbf</span>{PC} &amp; <span class="keyword1">\textbf</span>{P(\%)}&amp; <span class="keyword1">\textbf</span>{S(\%)}&amp; <span class="keyword1">\textbf</span>{F1(\%)}&amp; <span class="keyword1">\textbf</span>{A(\%)} \\</div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline">Proposed Method &amp; 0.15M &amp; 100.00 &amp; 100.00 &amp; 100.00 &amp;100.00\\</div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline">ResNet-34~\cite{nayak2021application} &amp; 21.8M &amp; 96.77&amp; 100.00 &amp; 98.36 &amp;98.33  \\</div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline">ACoS Phase I~\cite{chandra2021coronavirus}&amp; - &amp; 98.266 &amp; 96.512 &amp; 98.551 &amp; 98.062 \\</div><div class="clear"></div>
<div class="linenb">108</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">109</div><div class="codeline">ResNet-50~\cite{nayak2021application}&amp; 25.6M&amp; 95.24&amp; 100.00&amp; 97.56&amp; 97.50 \\</div><div class="clear"></div>
<div class="linenb">110</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">111</div><div class="codeline">GoogleNet~\cite{nayak2021application}&amp; 5M &amp;96.67&amp; 96.67&amp; 96.67&amp; 96.67 \\</div><div class="clear"></div>
<div class="linenb">112</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">113</div><div class="codeline">VGG-16~\cite{nayak2021application}&amp; 138M&amp; 95.08 &amp; 96.67 &amp; 95.87 &amp;95.83\\</div><div class="clear"></div>
<div class="linenb">114</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">115</div><div class="codeline">AlexNet~\cite{nayak2021application}&amp; 60M&amp; 96.72 &amp;98.33 &amp; 97.52&amp; 97.50 \\</div><div class="clear"></div>
<div class="linenb">116</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">117</div><div class="codeline">MobileNet-V2~\cite{nayak2021application} &amp; 3.4M &amp;98.24&amp; 93.33&amp; 95.73 &amp; 95.83 \\</div><div class="clear"></div>
<div class="linenb">118</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">119</div><div class="codeline">Inception-V3~\cite{nayak2021application}&amp; 24M &amp;96.36&amp; 88.33 &amp; 92.17&amp; 92.50\\</div><div class="clear"></div>
<div class="linenb">120</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">121</div><div class="codeline">SqueezeNet~\cite{nayak2021application}&amp; 1.25M &amp;98.27 &amp;95.00&amp; 96.61&amp; 96.67 \\</div><div class="clear"></div>
<div class="linenb">122</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">123</div><div class="codeline">\multicolumn{6}{l}{<span class="keyword1">\textit</span>{ PC is Parameter count, P is precision, S is sensitivity }}\\</div><div class="clear"></div>
<div class="linenb">124</div><div class="codeline">\multicolumn{6}{l}{<span class="keyword1">\textit</span>{  F1 is F1-score, and A is accuracy }}\\</div><div class="clear"></div>
<div class="linenb">125</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">126</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">127</div><div class="codeline"><span class="keyword1">\label</span>{modelperf}</div><div class="clear"></div>
<div class="linenb">128</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">129</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">130</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">131</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">132</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">133</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">134</div><div class="codeline"><span class="keyword1">\includegraphics</span>[height=90mm,width=8.0cm]{Figures/fig6.png}</div><div class="clear"></div>
<div class="linenb">135</div><div class="codeline"><span class="highlight-sh" title="This figure is missing a label [sh:figref]"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]">\</span>caption{(a) The training loss and the validation loss of each epoch and (b) The training accuracy and the validation accuracy of each epoch.}<span class="keyword1">\label</span>{fig5</span>}<span class="keyword2">\end{center}</span><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">136</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">137</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">138</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">139</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 15 words). You should consider merging it with another section or make it longer. [sh:seclen]"><span class="highlight-sh" title="This section is very short (about 16 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span></span>{Evaluation of the Methodology II}</div><div class="clear"></div>
<div class="linenb">140</div><div class="codeline">Methodology II is evaluated and compared against strong baselines and related works. </div><div class="clear"></div>
<div class="linenb">141</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">142</div><div class="codeline"><span class="keyword1">\subsection</span>{Baseline Networks}</div><div class="clear"></div>
<div class="linenb">143</div><div class="codeline">Different architectures are trained to validate the effectiveness of the proposed method. </div><div class="clear"></div>
<div class="linenb">144</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Spatial Pyramid Pooling (SPP-net) Based model}</div><div class="clear"></div>
<div class="linenb">145</div><div class="codeline">Four variants of SPP-ne<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">t\cite</span>{he2015spatial} is trained. All $4$ variants have the same architecture but different SPP-layer. These variants of SPP-layer are as follows:</div><div class="clear"></div>
<div class="linenb">146</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">147</div><div class="codeline">  <span class="keyword1">\item</span> full pyramid SPP of 8-levels using average-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">148</div><div class="codeline">  <span class="keyword1">\item</span> full SPP pyramid of 8-levels using max-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">149</div><div class="codeline">  <span class="keyword1">\item</span> single level SPP with 10-bins using average-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">150</div><div class="codeline">  <span class="keyword1">\item</span> single level SPP with 10-bins using max-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">151</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">152</div><div class="codeline">  A Fixed Architecture is used for all SPP variant models with the same design principles of the proposed architecture. These architectures are the same as the proposed architecture but DSWASPP is replaced by DC6 and SPP-1 layer is replaced with the corresponding SPP layer. DC6 is defined as six convolutional layers Densely connected together. For SPP-net variants training a multiscale augmentation is added to the proposed augmentation process. Multiscale augmentation is done by randomly sampling different $5$ scales typically $\{320, 320\pm25, 320\pm50 \}$.</div><div class="clear"></div>
<div class="linenb">153</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Switchable Atrous Spatial Pyramid Pooling (SASPP-net) Based models} </div><div class="clear"></div>
<div class="linenb">154</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">155</div><div class="codeline"><span class="keyword2">\begin{figure*}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">156</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=63mm,width=15cm]{SPP-netsTraining.PNG}}</div><div class="clear"></div>
<div class="linenb">157</div><div class="codeline"><span class="keyword1">\caption</span>{Training profiles of both SPP-net variants and the proposed network. For the same color solid line represents training statistics while dashed line represents the validation statistics for the corresponding model. <span class="keyword1">\textbf</span>{left:} is the training accuracy. <span class="keyword1">\textbf</span>{Right:} is the training loss.}</div><div class="clear"></div>
<div class="linenb">158</div><div class="codeline"><span class="keyword1">\label</span>{SPP-train}</div><div class="clear"></div>
<div class="linenb">159</div><div class="codeline"><span class="keyword2">\end{figure*}</span></div><div class="clear"></div>
<div class="linenb">160</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">161</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">162</div><div class="codeline">Another Base-line is introduced for comparison which is exactly as same as the proposed network but with different Attention module structure and does not include a bottleneck within ASPP. This architecture is referred Switchable Atrous Spatial Pyramid Pooling (SASPP-net). Attention module structure is $Softmax(FC(GAP(X)))$ where: <span class="keyword1">\textit</span>{$X$: is the input feature map}, <span class="keyword1">\textit</span>{$GAP$: is a global average pooling}, <span class="keyword1">\textit</span>{$FC$: is fully Connected layer performs a non-linear projection to ${\rm I\!R}^{4}$ a 4 values for the three scales and the input feature map}.<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">163</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">164</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">165</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Baselines and their total number of parameters</span>}</div><div class="clear"></div>
<div class="linenb">166</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">167</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|c|c|c|}</div><div class="clear"></div>
<div class="linenb">168</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">169</div><div class="codeline"><span class="keyword1">\textbf</span>{Model}&amp;\multicolumn{2}{|c|}{<span class="keyword1">\textbf</span>{Baseline CNN Architectures}} \\</div><div class="clear"></div>
<div class="linenb">170</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">171</div><div class="codeline"><span class="keyword1">\textbf</span>{Type} &amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Variant}}&amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Param. Count}} \\</div><div class="clear"></div>
<div class="linenb">172</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">173</div><div class="codeline">  &amp; ML Average pooling &amp; $14,916,420$   \\</div><div class="clear"></div>
<div class="linenb">174</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">175</div><div class="codeline">SPP &amp; ML max pooling &amp; $14,916,420$   \\</div><div class="clear"></div>
<div class="linenb">176</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">177</div><div class="codeline">  &amp; SL Average pooling &amp; $14,490,436$   \\</div><div class="clear"></div>
<div class="linenb">178</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">179</div><div class="codeline">  &amp; SL max pooling &amp; $14,490,436$ \\</div><div class="clear"></div>
<div class="linenb">180</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">181</div><div class="codeline">\multicolumn{2}{|c|}{SASPP} &amp; $13,031,841$\\</div><div class="clear"></div>
<div class="linenb">182</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">183</div><div class="codeline">\multicolumn{3}{l}{ <span class="keyword1">\textbf</span>{ML}: Multilevel, <span class="keyword1">\textbf</span>{SL}: Single level}</div><div class="clear"></div>
<div class="linenb">184</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">185</div><div class="codeline"><span class="keyword1">\label</span>{Basarch}</div><div class="clear"></div>
<div class="linenb">186</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">187</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">188</div><div class="codeline">Table~\ref{Basarch} summarizes the base-line models and the Corresponding parameter count.</div><div class="clear"></div>
<div class="linenb">189</div><div class="codeline"><span class="keyword1">\subsection</span>{Models Training}</div><div class="clear"></div>
<div class="linenb">190</div><div class="codeline">Proposed architecture and baseline architecture are trained with the same hyperparameters. Dataset is split to $0.6$, $0.2$ and $0.2$ for training, validation and testing, respectively. For training a Cross Entropy Loss is used. All models trained with ADAM~\cite{kingma2014adam} optimizer with learning rate start by $10^{-3}$ and reduced every time validation loss plateau by multiplying by $10^{-1}$. A Max Norm Constraint is used to clip the gradient value to norm of $1$~\cite{krizhevsky2012imagenet}. A batch size of $128$ is used to calculate the gradient.</div><div class="clear"></div>
<div class="linenb">191</div><div class="codeline"><span class="keyword1">\subsection</span>{Reducing the overfitting}</div><div class="clear"></div>
<div class="linenb">192</div><div class="codeline">Overfitting is a critical problem for training large networks~\cite{krizhevsky2012imagenet}. Proposed work has reduced the overfitting by using:</div><div class="clear"></div>
<div class="linenb">193</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">194</div><div class="codeline"><span class="keyword1">\item</span> Using Dropout with retrain probability of $0.5$~\cite{srivastava2014dropout}.</div><div class="clear"></div>
<div class="linenb">195</div><div class="codeline"><span class="keyword1">\item</span> Using BatchNorm adds noise due to randomization introduced when constructing the minibatch~\cite{ioffe2015batch}.</div><div class="clear"></div>
<div class="linenb">196</div><div class="codeline"><span class="keyword1">\item</span> Using max norm constraint~\cite{krizhevsky2012imagenet}.</div><div class="clear"></div>
<div class="linenb">197</div><div class="codeline"><span class="keyword1">\item</span> Deep and thin architectures by design has an implicit regularization effect~\cite{he2016deep}. </div><div class="clear"></div>
<div class="linenb">198</div><div class="codeline"><span class="keyword1">\item</span> Augmentation process <span class="highlight-sh" title="Use a backslash or comma after the second period; otherwise LaTeX will think it is a full stop ending a sentence. [sh:011]">i.e.)</span> Texture augmentation~\cite{krizhevsky2012imagenet}. </div><div class="clear"></div>
<div class="linenb">199</div><div class="codeline"><span class="keyword1">\item</span> The use of small kernel size~\cite{simonyan2014very}.</div><div class="clear"></div>
<div class="linenb">200</div><div class="codeline"><span class="keyword1">\item</span> Bottleneck in SWASPP module and the attention module.</div><div class="clear"></div>
<div class="linenb">201</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">202</div><div class="codeline">During training no overfitting effects is observed.</div><div class="clear"></div>
<div class="linenb">203</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 108 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span>{Comparison with baselines}</div><div class="clear"></div>
<div class="linenb">204</div><div class="codeline">Proposed network is compared with the vanilla SPP-based Architectures and ASPP architecture.</div><div class="clear"></div>
<div class="linenb">205</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Comparing with SPP-nets}</div><div class="clear"></div>
<div class="linenb">206</div><div class="codeline">Fig.~\ref{SPP-train} illustrates both training loss and training and validation accuracies and losses. Table~\ref{blaccom} illustrates the testing accuracy for comparison between the SPP-nets baseline and the proposed architecture.</div><div class="clear"></div>
<div class="linenb">207</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">208</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Comparison between Proposed network and baseline SPP architectures </span>}</div><div class="clear"></div>
<div class="linenb">209</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">210</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|c|c|}</div><div class="clear"></div>
<div class="linenb">211</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">212</div><div class="codeline"><span class="keyword1">\textbf</span>{Model Name}&amp; Accurracy \\</div><div class="clear"></div>
<div class="linenb">213</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">214</div><div class="codeline"> SPP ML Average pooling &amp; $0.958$   \\</div><div class="clear"></div>
<div class="linenb">215</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">216</div><div class="codeline">SPP ML max pooling &amp; $0.950$   \\</div><div class="clear"></div>
<div class="linenb">217</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">218</div><div class="codeline">  SPP SL Average pooling &amp; $0.927$   \\</div><div class="clear"></div>
<div class="linenb">219</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">220</div><div class="codeline">  SPP SL max pooling &amp; $0.957$ \\</div><div class="clear"></div>
<div class="linenb">221</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">222</div><div class="codeline">Proposed Network &amp; $0.987$\\</div><div class="clear"></div>
<div class="linenb">223</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">224</div><div class="codeline">\multicolumn{2}{l}{ <span class="keyword1">\textbf</span>{ML}: Multilevel, <span class="keyword1">\textbf</span>{SL}: Single level}</div><div class="clear"></div>
<div class="linenb">225</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">226</div><div class="codeline"><span class="keyword1">\label</span>{blaccom}</div><div class="clear"></div>
<div class="linenb">227</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">228</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">229</div><div class="codeline">\<span class="highlight-sh" title="This subsubsection is very short (about 71 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsubsection</span>{Comparing with SASPP}</div><div class="clear"></div>
<div class="linenb">230</div><div class="codeline">Fig.~\ref{saspp} illustrates the training and validation loss of training a SASPP baseline architecture. As shown in Fig.~\ref{saspp} SASPP unable to generalize and start overfitting the training set. This comparison empirically shows the importance of the bottleneck introduced in the proposed architecture.</div><div class="clear"></div>
<div class="linenb">231</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">232</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">233</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">234</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{saspp.PNG}}</div><div class="clear"></div>
<div class="linenb">235</div><div class="codeline"><span class="keyword1">\caption</span>{SASPP baseline architecture loss during both training, solid line, and validation, bashed line, compared with Proposed network and best performing SPP architecture.}</div><div class="clear"></div>
<div class="linenb">236</div><div class="codeline"><span class="keyword1">\label</span>{saspp}</div><div class="clear"></div>
<div class="linenb">237</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">238</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">239</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">240</div><div class="codeline"><span class="keyword1">\subsection</span>{Comparing with the related works}</div><div class="clear"></div>
<div class="linenb">241</div><div class="codeline">To fairly compare with the related works proposed work is further trained. Fig.~\ref{ploss} shows the training and validation loss of the proposed network. Fig.~\ref{pacc} shows the of the training and validation accuracy. </div><div class="clear"></div>
<div class="linenb">242</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">243</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">244</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{PLOSS.PNG}}</div><div class="clear"></div>
<div class="linenb">245</div><div class="codeline"><span class="keyword1">\caption</span>{Cross entropy loss of the proposed architecture.}</div><div class="clear"></div>
<div class="linenb">246</div><div class="codeline"><span class="keyword1">\label</span>{ploss}</div><div class="clear"></div>
<div class="linenb">247</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">248</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">249</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">250</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">251</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{PACC.PNG}}</div><div class="clear"></div>
<div class="linenb">252</div><div class="codeline"><span class="keyword1">\caption</span>{Training and validation accuracy of the proposed architecture.}</div><div class="clear"></div>
<div class="linenb">253</div><div class="codeline"><span class="keyword1">\label</span>{pacc}</div><div class="clear"></div>
<div class="linenb">254</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">255</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">256</div><div class="codeline">Proposed Network has a sensitivity, recall, and precision of $0.994$ and $0.991$ respectively on the validation set. Precision can be improved by investigating the precision-recall trade-off. Fig.~\ref{prt} shows the trade-off between precision and recall for different thresholds. A threshold of $0.618$ is used to improve the precision resulting in a sensitivity, recall, of $0.9903$ and precision of $0.9956$.</div><div class="clear"></div>
<div class="linenb">257</div><div class="codeline">Comparison metrics are defined as follows:</div><div class="clear"></div>
<div class="linenb">258</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">259</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Accuracy}: is ratio of correctly classified samples to the total number of samples</div><div class="clear"></div>
<div class="linenb">260</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Sensitivity}: is ratio of correctly classified Covid-19 samples to the total number of actual Covid-19 samples </div><div class="clear"></div>
<div class="linenb">261</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Precision}: is the ratio of correctly, according to the ground-truth labels, classified Covid-19 samples to the total number of samples classified as Covid-19.</div><div class="clear"></div>
<div class="linenb">262</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Specificity}: is the ratio of correctly, according to the ground-truth labels, classified non-COVID-19 to the total number of non-Covid-19.</div><div class="clear"></div>
<div class="linenb">263</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{F1-score}: is the harmonic mean of both Sensitivity and Precision.</div><div class="clear"></div>
<div class="linenb">264</div><div class="codeline"><span class="keyword2">\begin{center}</span>  </div><div class="clear"></div>
<div class="linenb">265</div><div class="codeline"> $F_{1}=\frac{2\times\text{Precision} \times \text{Sensitivity}}{\text{Precision} + \text{Sensitivity}}$</div><div class="clear"></div>
<div class="linenb">266</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">267</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Param. Count}: is the total number of the trainable parameters.</div><div class="clear"></div>
<div class="linenb">268</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">269</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">270</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">271</div><div class="codeline"><span class="keyword2">\begin{table*}</span>[!p!t]</div><div class="clear"></div>
<div class="linenb">272</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Comparison between Proposed network and Related works </span>}</div><div class="clear"></div>
<div class="linenb">273</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">274</div><div class="codeline">\resizebox{\textwidth}{!}{<span class="keyword2">\begin{tabular}</span>{|c|c|c|c|c|c|c|}</div><div class="clear"></div>
<div class="linenb">275</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">276</div><div class="codeline"><span class="keyword1">\textbf</span>{Model Name}&amp; <span class="keyword1">\textbf</span>{Accuracy} &amp; <span class="keyword1">\textbf</span>{Sensitivity} &amp;<span class="keyword1">\textbf</span>{ Precision} &amp; <span class="keyword1">\textbf</span>{Specificity} &amp; <span class="keyword1">\textbf</span>{F1-score} &amp; <span class="keyword1">\textbf</span>{Param. Count}\\</div><div class="clear"></div>
<div class="linenb">277</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">278</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">279</div><div class="codeline">Proposed &amp; 0.99294 &amp; <span class="keyword1">\textbf</span>{0.9903} &amp; <span class="keyword1">\textbf</span>{0.9956} &amp; 0.9956 &amp; <span class="keyword1">\textbf</span>{0.9929} &amp; <span class="keyword1">\textbf</span>{5,040,571}\\</div><div class="clear"></div>
<div class="linenb">280</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">281</div><div class="codeline">SRC-Dal<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">m\cite</span>{ar} &amp; 0.985 &amp; 0.886 &amp; - &amp; 0.993 &amp; - &amp; -\\</div><div class="clear"></div>
<div class="linenb">282</div><div class="codeline">\hline </div><div class="clear"></div>
<div class="linenb">283</div><div class="codeline">SRC-Ho<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">m\cite</span>{ar} &amp; 0.977 &amp; 0.921 &amp; - &amp; 0.982 &amp; - &amp; - \\</div><div class="clear"></div>
<div class="linenb">284</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">285</div><div class="codeline">CRC-ligh<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">t\cite</span>{ar} &amp; 0.973 &amp; 0.955 &amp; - &amp; 0.974 &amp; - &amp;- \\</div><div class="clear"></div>
<div class="linenb">286</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">287</div><div class="codeline">DenseNet121*\cite{ar} &amp; 0.992 &amp; 0.9714 &amp; - &amp; 0.9949 &amp; - &amp; 6,955,906  \\</div><div class="clear"></div>
<div class="linenb">288</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">289</div><div class="codeline">Inception-v<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">3\cite</span>{ar} &amp; 0.993 &amp; 0.954 &amp; - &amp; 0.998 &amp; - &amp; 21,772,450  \\</div><div class="clear"></div>
<div class="linenb">290</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">291</div><div class="codeline">Modified MobileNetV2~\cite{akt}  &amp; 0.98 &amp; 0.98 &amp; 0.97 &amp; - &amp; 0.97 &amp; -\\</div><div class="clear"></div>
<div class="linenb">292</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">293</div><div class="codeline">ReCovNet-v<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">2\cite</span>{dag} &amp; 0.99726 &amp; 0.98571 &amp; 0.94262 &amp; 0.9977 &amp; 0.96369 &amp;- \\</div><div class="clear"></div>
<div class="linenb">294</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">295</div><div class="codeline">ReCovNet-v<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">1\cite</span>{dag} &amp; 0.99824 &amp; 0.9781 &amp; 0.97438 &amp; 0.99901 &amp; 0.97624 &amp; -\\</div><div class="clear"></div>
<div class="linenb">296</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">297</div><div class="codeline">DenseNet-12<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">1\cite</span>{dag}  &amp; <span class="keyword1">\textbf</span>{0.9988} &amp; 0.97429 &amp; 0.9932 &amp; <span class="keyword1">\textbf</span>{0.99974} &amp; 0.98365 &amp; 6,955,906 \\</div><div class="clear"></div>
<div class="linenb">298</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">299</div><div class="codeline"><span class="keyword2">\end{tabular}</span>}</div><div class="clear"></div>
<div class="linenb">300</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">301</div><div class="codeline"><span class="keyword1">\label</span>{rwcom}</div><div class="clear"></div>
<div class="linenb">302</div><div class="codeline"><span class="keyword2">\end{table*}</span></div><div class="clear"></div>
<div class="linenb">303</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">304</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">305</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">306</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">307</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{PresRecuTradff.PNG}}</div><div class="clear"></div>
<div class="linenb">308</div><div class="codeline"><span class="keyword1">\caption</span>{precision-recall trade-off of the proposed network.}</div><div class="clear"></div>
<div class="linenb">309</div><div class="codeline"><span class="keyword1">\label</span>{prt}</div><div class="clear"></div>
<div class="linenb">310</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">311</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">312</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">313</div><div class="codeline">Table~\ref{rwcom} summarizes the comparison between the recent related works and the proposed architecture. Proposed architecture outperform these works in many metrics. As their training and testing does not depend on a balanced number of samples, accuracy and specificity are not good metrics for evaluation. </div><div class="clear"></div>
<div class="linenb">314</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">315</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">316</div><div class="codeline"><span class="keyword1">\section</span>{Summary}</div><div class="clear"></div>
<div class="linenb">317</div><div class="codeline"><span class="comment"><span class="comment">% This chapter illustrates the superior performance of the proposed work I and II. Experimental results of proposed work I show the effectiveness of spatial separable kernels and residual connection for detecting COVID-19. The proposed architecture I use batch normalization to maintain the network stability during the training process. During the training process, the hyperparameters (such as batch size and learning rate) are determined dynamically. Proposed architecture I outperformed previous works for binary classification of chest X-Ray images to normal or COVID-19 cases. The proposed architecture has a very low parameter count (150K trainable parameter) compared to previous work. The proposed  architecture I achieved a performance of 100\% for accuracy, sensitivity, precision and F1-score. Proposed work I does not take care of the fact that CNN is scale variant model while proposed work II does. Better quantitative results for CXR COVID-19 classification can be obtained with a multiscale training approaches. Proposed work II internally produces multiscale feature maps using Atrous Spatial pyramid pooling. These multiscales feature maps are fused using an attention module. To learn a compact representation a bottleneck dimension is introduced in both the multiscale feature extractor module and the attention module. Proposed work II outperformed current sate-of-the-art architecture with lower parameter number. Proposed method has recorded a $0.9929$ for $F1-score$.</span></span></div><div class="clear"></div>
<div class="linenb">318</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">319</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">320</div><div class="codeline">This chapter illustrates the superior performance of the proposed work I and II. In addition to the superior performance of the proposed works I and II, the chapter also provides a detailed analysis of the experimental results. The evaluation of proposed work I demonstrates that the use of spatial separable kernels and residual connection significantly improves the performance of the COVID-19 detection system. The batch normalization technique is found to be effective in maintaining the network stability during the training process. The dynamic selection of hyperparameters such as batch size and learning rate further improves the performance of the proposed architecture I.</div><div class="clear"></div>
<div class="linenb">321</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">322</div><div class="codeline">Furthermore, the proposed architecture I outperforms existing works for binary classification of chest X-Ray images for normal and COVID-19 cases. This is particularly noteworthy as the proposed architecture has a low parameter count of only 150K trainable parameters compared to previous works. The achievement of a performance of $100\%$ for accuracy, sensitivity, precision, and F1-score indicates the high accuracy and reliability of the proposed architecture.</div><div class="clear"></div>
<div class="linenb">323</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">324</div><div class="codeline">Although the proposed architecture I performs exceptionally well, it does not address the scale variant nature of the CNN model. This issue is addressed in the proposed work II, which incorporates multiscale training approaches to obtain better quantitative results for CXR COVID-19 classification. The use of Atrous Spatial pyramid pooling enables the internal production of multiscale feature maps, which are then fused using an attention module. To achieve a compact representation, a bottleneck dimension is introduced in both the multiscale feature extractor module and the attention module.</div><div class="clear"></div>
<div class="linenb">325</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">326</div><div class="codeline">The proposed work II outperforms the current state-of-the-art architecture with lower parameter numbers. The recorded $0.9929$ for F1-score indicates the high performance of the proposed architecture. The detailed analysis and experimental results presented in this chapter provide valuable insights into the effectiveness of the proposed architectures and their potential for improving the accuracy and reliability of COVID-19 detection systems.</div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/Chapter4_proposed2.tex</h2>

<p>Found 8 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 111 words). You should consider merging it with another section or make it longer. [sh:seclen]">chapter</span>{Proposed Methodology II} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:proposed2} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use~\ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline">CNN, like many computer vision models, is a scale-variant~\cite{van2017learning} model such that it cannot recognize objects at various scales unless it explicitly trained to recognize such objects. Data augmentation can accomplish some degree of invariance as it allows the network to be trained with distorted samples, but it not the case for pneumonia scales. This chapter presents a CNN architecture that learns multiscale features using scale pyramid of the  CNN's internal feature maps. Scale pyramid is constructed using atrous convolution of various dilation rates. The correct scale from scale pyramid that allows minimization of the objective function loss is selected using the spatial attention mechanism. </div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline"><span class="keyword1">\section</span>{Methodology II} </div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">    <span class="keyword2">\begin{figure*}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline">    \centerline{<span class="keyword1">\includegraphics</span>[height=40mm,width=15cm]{Figures/ProposedPipe.png}}</div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline"><span class="highlight-sh" title="This figure is missing a label [sh:figref]"> </span>   <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Proposed method for COVID-19 classification from CXR images.}<span class="keyword1">\label</span>{ProposedPipe</span>}<span class="keyword2">\end{figure*}</span><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline">    </div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline">The proposed system presented in this chapter proposes a novel CNN micro-architecture model for learning scale-invariant features from row input CXR images and then classifies these features into normal or COVID-19 cases. Fig.~\ref{ProposedPipe} illustrates trainable end-to-end pipeline of the proposed system. The proposed system depends on a novel Spatially weighted Atrous Spatial Pyramid Pooling (SWASPP) to extract multi-scale features of input CXR images. A novel attention module is then used to fuse the extracted these multi-scale features and select relevant features' scale that the next layer should consider.</div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline"><span class="keyword1">\subsection</span>{Data augmentation}</div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline">    <span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline">    \centerline{<span class="keyword1">\includegraphics</span>[height=30mm,width=9cm]{Figures/TexAug.PNG}}</div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Texture Augmentation module</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline">    <span class="keyword1">\label</span>{texaug}</div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline">    <span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline">The first phase of the proposed CXR classification system is data augmentation phase. Data augmentation is used to reduce the overfitting by artificially enlarge the training dataset~\cite{krizhevsky2012imagenet} using label preserving transformation. Data augmentation phase introduces a degree invariance to a distortion transformation such as the flipping and rotation. The input CXR images are augmented using texture augmentation.  Texture augmentation is performed by introducing a multiplicative normally distributed noises to the frequency spectrum of the input image. CXR image is transformed to the frequency spectrum using the fourier transform.  Noise is modeled using $\mathcal{N}(\mu = 1,\,\sigma = 0.3)$. Fig.~\ref{texaug} illustrates texture augmentation process for frequency distortion of the CXR image. Fig.~\ref{resltaug} shows the original CXR image and the corresponding frequency distorted CXR image. A standard augmentation techniques such as random rotation, horizontal flipping, and vertical flipping are included in the augmentation process. </div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline">    <span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline">    \centerline{<span class="keyword1">\includegraphics</span>[height=40mm,width=9cm]{Figures/freqJitt.png}}</div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Texture Augmentation</span>}{The resulting CXR image from Texture augmentation <span class="keyword1">\textbf</span>{left}: is the original image. <span class="keyword1">\textbf</span>{Right} is the augmented  CXR Image}</div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline">    <span class="keyword1">\label</span>{resltaug}</div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline">    <span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline">    <span class="keyword2">\end{center}</span> </div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline">    </div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=50mm,width=9cm]{Figures/SWASPP.PNG}}</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline"><span class="keyword1">\caption</span>{Spatially weighted atrous spatial Pyramid Pooling (SWASPP) interal layers within dashed square are parameter shared.}</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline"><span class="keyword1">\label</span>{swaspp}</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline"><span class="keyword1">\subsection</span>{Spatially Weighted Atrous Spatial Pyramid Pooling}</div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline">Atrous convolution is a powerful technique for adjusting the resolution of convolutional kernels. This allows to effectively enlarge the field-of-view of the kernel without increasing neither the number of kernel parameters nor the computational complexity of the convolution operation. Atrous convolution is equivalent to performing downsampling and then performing convolution with original kernel without dilation. As a result different dilation rates of the kernel corresponding to different downsampling degrees. A novel spatially weighted atrous spatial pyramid pooling (SWASPP) micro-architecture is presented that exploit the scale space of the CNN's feature maps. Fig.~\ref{swaspp} shows the architecture of the SWASPP. In Fig.~\ref{swaspp}, internal pipelines, bounded by dashed-line square, are parameter-shared and each pipeline of these has a different dilation rates. These pipelines are responsible for extracting multi-scale, scale invariant, features. Sharing of the parameters enforce these pipelines to learn features that exists at multiple levels of scale-pyramid and hence scale-invariance. For a given input CXR image, three scales feature maps are produced.</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=60mm,width=3.5cm]{Figures/AttentionModUl.PNG}}</div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Attantion module structure used by SWASPP micro-architecture</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline"><span class="keyword1">\label</span>{attain}</div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline">To fuse these feature maps produced by different pipeline of the SWASPP from the input feature map, an attention module is emerged. Attention module can be thought as a pixel level classification of which scale does this pixel it belongs to. Fig.~\ref{attain} illustrates the proposed attention module structure. Proposed attention module generates four heatmaps. The first three heatmaps correspond to the three scale feature maps while the remaining heatmap corresponds to the input feature map itself. These heatmaps are summed  up to one (<span class="keyword1">\textit</span>{i.e.,} for a  spatial position </div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline">$(x, y)$, $\sum_{i =1}^{4} H(i,x,y) = 1$ where $H(i,x,y)$ is the $i$ heatmap produced by the attention module). To make sure this property holds, softmax function is used. </div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline">The proposed mirco-architecture uses a pixel level weights produced by corresponding attention module rather than a single weight value for each scale. A single input CXR image may have multiple COVID-19 pneumonia scales which effectively lead to simply averaging the scale space when using single weight for each scale on scale space. In SWASPP, every convolution operation is followed by a BN and leakyReLU~\cite{krizhevsky2012imagenet} non-linearity except the re-projection layers that used to project back to the input space is not followed by nonlinearity. </div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline">BN allows the use of larger learning rate~\cite{ioffe2015batch} and makes network stable during training~\cite{ioffe2015batch}. BN makes the loss landscape of the optimization problem significantly smoother~\cite{santurkar2018does}.</div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline">leakyReLU is used to reduce the vanishing gradient problem~\cite{krizhevsky2012imagenet}.</div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline">A bottleneck is introduced within both the attention module and multi-scale feature extractor pipeline. A bottleneck in SWASPP is used to project the input feature map of dimension $C_{in}\times H\times W$ to $32\times H\times W$ then re-project back to $C_{in}\times H\times W$. Multi-scale feature extraction is preformed on the projected dimension. Same logic is applied to the attention module where the input feature map is projected to a dimension of $16\times H\times W$.</div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline">This bottleneck allows the efficient use of model capacity and reduce the network computational complexity~\cite{huang2017densely}. It only allows the flow of important information and discarding irrelevant information. </div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline"><span class="keyword1">\subsection</span>{Proposed CNN Architecture}</div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">SWASPP is densely stacked~\cite{huang2017densely} together as Fig.~\ref{denseB} illustrates. This kind of connectivity allows implicit deep supervisions as each layer is effectively connected to the last layer using shorter path also facilitate feature reuse~\cite{huang2017densely} and gradient flow. Residual layers are easier to optimize if the required mapping is the identity mapping or simply near to it~\cite{he2016deep}. Densely stacked SWASPP is denoted by (DSWASPP). Convolutional part of proposed model consists of stacking six DSWASPP layers such that the first four layers are interconnected using maxpooling to reduce the spatial size and enlarge the Network receptive field. A single level Spatial Pyramid Pooling (SPP)~\cite{he2015spatial} is added after to produce a fixed size feature vector for a variable size input. SPP layer divides the input feature map into $10\times 10 = 100$ bins then performs a $max$ for each bin as an aggregation function. </div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=30mm,width=6cm]{Figures/DensResd.PNG}}</div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline"><span class="keyword1">\caption</span>{Densely connected SWASPP (DSWASPP): is a stack of densely connected SWASPP, such that the output of any SWASPP is Concatenated to the input of all next layers. All the three layers produce an output of dimension of $C_{in} \times H \times W$.}</div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline"><span class="keyword1">\label</span>{denseB}</div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline">The fixed length feature vector produced by SPP is used as an input to dropout~\cite{srivastava2014dropout} layer. Dropout layer randomly sets the activation of to $0$ with a probability of $0.5$. Dropout prevents the overfitting and reduce complex co-adaptation between the neurons allowing them to learn better representation~\cite{srivastava2014dropout}. It allow implicit ensempling of exponential number of sampled thin network from the original network which enhance the network performance~\cite{srivastava2014dropout}. The result of dropout layer is used as input to the classification network. Classification network consists of a fully connected layers with a $3$ Dense layers such that the output layer is 2-neuron for binary classification<span class="highlight-sh" title="There should be a space after a period. If you are writing a URL or a filename, use the \url{} or \verb markup. [sh:d:002]"> <span class="keyword1">\textit</span>{i.e)}</span> COVID19 or not. Table~\ref{PCNN} shows the details of the proposed architecture.</div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline">\renewcommand{\arraystretch}{1.5}</div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Proposed CNN architecture of methodology II</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline">    <span class="keyword2">\begin{tabular}</span>{|c|c|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline">    <span class="keyword1">\textbf</span>{Layer}&amp;\multicolumn{3}{|c|}{<span class="keyword1">\textbf</span>{Proposed CNN Architecture of Methodology II}} \\</div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline">    \cline{2-4} </div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline">    <span class="keyword1">\textbf</span>{Name} &amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Input Shape}}&amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Output Shape}}&amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Param. Count}} \\</div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">    Input layer &amp; - &amp; $1 \times 320 \times 320$ &amp; 0 \\</div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">    BatchNorm-1 &amp; $1 \times 320 \times 320$ &amp; $1 \times 320 \times 320$ &amp; 2 \\</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">    DSWASPP-1&amp; $1 \times 320 \times 320$ &amp; $32 \times 320 \times 320$ &amp; 121,035  \\</div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">    Maxpooling-1&amp; $32 \times 320 \times 320$ &amp;$32 \times 160 \times 160$ &amp; 0 \\</div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline">    DSWASPP-2&amp; $32 \times 160 \times 160$ &amp; $64 \times 160 \times 160$ &amp; 298,236  \\</div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline">    Maxpooling-2 &amp; $64 \times 160 \times 160$ &amp; $64 \times 80 \times 80$ &amp;0  \\</div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline">    DSWASPP-3  &amp; $64 \times 80 \times 80$ &amp; $128 \times 80 \times 80$ &amp; 604,956  \\</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline">    Maxpooling-3 &amp; $128 \times 80 \times 80$ &amp; $128 \times 40 \times 40$ &amp; 0  \\</div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline">    DSWASPP-4  &amp; $128 \times 80 \times 80$ &amp; $128 \times 80 \times 80$ &amp; 784,092 \\</div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline">    DSWASPP-5  &amp; $128 \times 80 \times 80$ &amp; $128 \times 80 \times 80$ &amp; 784,092 \\</div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline">    DSWASPP-6  &amp; $128 \times 80 \times 80$ &amp; $128 \times 80 \times 80$ &amp; 784,092 \\</div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">108</div><div class="codeline">    SPP-1 &amp; $128 \times 80 \times 80$ &amp; $12800$ &amp; 0 \\</div><div class="clear"></div>
<div class="linenb">109</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">110</div><div class="codeline">    Dropout-1 &amp; $12800$ &amp; $12800$ &amp; 0 \\</div><div class="clear"></div>
<div class="linenb">111</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">112</div><div class="codeline">    FC-1 &amp; $12800$ &amp; $128$ &amp; 1,638,528 \\</div><div class="clear"></div>
<div class="linenb">113</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">114</div><div class="codeline">    FC-2 &amp; $128$ &amp; $128$ &amp; 16,512 \\</div><div class="clear"></div>
<div class="linenb">115</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">116</div><div class="codeline">    FC-3 &amp; $128$ &amp; $64$ &amp; 8,256 \\</div><div class="clear"></div>
<div class="linenb">117</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">118</div><div class="codeline">    FC-4 &amp; $64$ &amp; $2$ &amp; 130 \\</div><div class="clear"></div>
<div class="linenb">119</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">120</div><div class="codeline">    Softmax &amp; $2$ &amp; $2$ &amp; 0 \\</div><div class="clear"></div>
<div class="linenb">121</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">122</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">123</div><div class="codeline">    \multicolumn{3}{|c|}{Total Number of Parameter}&amp;5,040,571\\</div><div class="clear"></div>
<div class="linenb">124</div><div class="codeline">    \hline</div><div class="clear"></div>
<div class="linenb">125</div><div class="codeline">    \multicolumn{4}{c}{Any linear combination is followed by BN and leakyReLU nonlinearity}\\</div><div class="clear"></div>
<div class="linenb">126</div><div class="codeline">    \multicolumn{4}{l}{excluding re-projection layer of the SWASPP modules}</div><div class="clear"></div>
<div class="linenb">127</div><div class="codeline">    <span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">128</div><div class="codeline">    <span class="keyword1">\label</span>{PCNN}</div><div class="clear"></div>
<div class="linenb">129</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">130</div><div class="codeline">    <span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">131</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">132</div><div class="codeline"><span class="keyword1">\section</span>{Summary}</div><div class="clear"></div>
<div class="linenb">133</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">134</div><div class="codeline"><span class="comment"><span class="comment">% CNN is a scale variant model. Many approaches were introduced to overcome this problem such as shared networks, feature pyramid network and atrous convolution. Atrous convolution increases the receptive field of the convolutional kernel without neither increasing the parameter number nor the computational complexity. Atrous convolution is used in the proposed work II to construct the scale space of the input feature. Attention mechanism is used to guide to process the most relevant part of the feature maps. To select the correct scale and fuse multiple scales of the input feature map a spatial attention module is used. A novel CNN architecture is proposed that internally produces multiscale feature maps which is further fused using attention based mechanism. Compact representation is learned via a bottleneck dimension which is introduced in both the multiscale feature extractor module and the attention module.</span></span></div><div class="clear"></div>
<div class="linenb">135</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">136</div><div class="codeline">Convolutional Neural Networks (CNNs) have been widely used in computer vision tasks, including image classification, object detection, and segmentation. However, CNNs are known to be scale variant models, meaning that they can miss important features at different scales. To overcome this issue, various approaches have been proposed, such as shared networks, feature pyramid networks, and atrous convolution.</div><div class="clear"></div>
<div class="linenb">137</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">138</div><div class="codeline">Atrous convolution, also known as dilated convolution, increases the receptive field of the convolutional kernel without increasing the number of parameters or computational complexity. In the proposed work II, atrous convolution is used to construct the scale space of the input feature, allowing the CNN to extract multiscale features.</div><div class="clear"></div>
<div class="linenb">139</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">140</div><div class="codeline">Moreover, to select the correct scale and fuse multiple scales of the input feature map, a spatial attention module is used in the proposed work II. This attention mechanism guides the network to focus on the most relevant parts of the feature maps, which helps to improve the accuracy of the network.</div><div class="clear"></div>
<div class="linenb">141</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">142</div><div class="codeline">To further enhance the performance of the network, a novel CNN architecture is proposed in which multiscale feature maps are internally produced and then fused using an attention-based mechanism. This approach leads to a compact representation of the input data via a bottleneck dimension introduced in both the multiscale feature extractor module and the attention module. Overall, these techniques and architectures help to improve the performance and accuracy of CNNs for computer vision tasks.</div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/ArabAbst.tex</h2>

<p>Found 0 warning(s)</p>
<div class="original-file">
<div class="linenb">1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">2</div><div class="codeline"><span class="keyword2">\begin{arab}</span>[utf]</div><div class="clear"></div>
<div class="linenb">3</div><div class="codeline">    <span class="comment">% \appendix</span></div><div class="clear"></div>
<div class="linenb">4</div><div class="codeline">    \chapter*{\textarab[utf]{???? ???????}} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">5</div><div class="codeline">    \addchaptertocentry{\textarab[utf]{???? ???????}}</div><div class="clear"></div>
<div class="linenb">6</div><div class="codeline">    <span class="keyword1">\label</span>{araSummery} </div><div class="clear"></div>
<div class="linenb">7</div><div class="codeline">    </div><div class="clear"></div>
<div class="linenb">8</div><div class="codeline">        ?????19 ?? ?????? ??? ?? ?????? ???????. ???? ?? ????? ?????19 ?????? ?? SARS-CoV-2 ?????? ?? ???? ??????? ???? ????. ?? ??????? ?????? ?????? ?????? SARS-CoV-2 ?? ???? ??????? ????? ?? ??? ????? ??? ????? ????? ????? ?????? ??????? ?? ?? ?? ??????? ??????? ?????????. ???  ?????? ?????? ?? ???????? ??? ??? ?????? ??? ????? ??????? ?????? ??? ???? ?? ?????? ??? ??? ????? ?????? ??? ?????. ????? ??????? ??????? ?????????? (CNN) ?????? ?????? ?? ???? ?????? ????????? ????????. ??? ??? ? ??? CNN ??????? ??????? scale-invariant ??????? ?? ??????? ????????. ?? ??? ???????? ?? ?????? ????? ????? ???????? ??????? ?????? ???????? ???????? ?????? ????? ????? ?? ???????? ?????? ?????19. ????? ??????? I ??????? ??? ????? CNN ???? ????? ?? ???????? ?????? ??? kernel ???????? ?????? ??? ??????? ??????? ??? ?? ???? ?????? ??????? ????? kernel ???? ???. ????? ??? ??? ? ?????? ??? ??????? ??????? Residual BatchNorm ?????? ???????? ??? ???? ???? ?????? ??? ??????? ?????? ????? ????? ??????? ?????? ??????? ?????? ??????? Regularization ?????? ??????? ?????? Overfitting . ????? CNN II ??????? ????? ?????? ???????? Multiscale  ???????? ??? Atrous Convolution ???????? ??????? Dilation ??????. ??????  CNN  ???? ????? ??? ???????? Attention ??????? ?????? ??????? ??????? ?????? ??? ?????. ?? ???? CNN II ???????? ?? ???? ????? ????? ?????? ????? ????? ????? ? ??? Texture Augmentation ? ?????? ??????? ??????. ??? ????? ?????? ????? ????? ???????? ?????? ???????? ????????? QaTa-Cov19 ???? ???? 100 ? ?? ????? ????????? ?????? ????? F1 ?? ??? ?????? ????? ???? (150K) ?????? ?????? ?????? ?? ??????? ???????. ???? ??????? ???????? II 0.9929 ????? F1 ???? ?? ???????? ??? ?????? ???????? ????????? QaTa-Cov19 ??????? 5?040?571 ????? ????? ???????.</div><div class="clear"></div>
<div class="linenb">9</div><div class="codeline">    </div><div class="clear"></div>
<div class="linenb">10</div><div class="codeline">    <span class="keyword2">\end{arab}</span></div><div class="clear"></div>
</div>
<h2 class="filename">./Chapters/Chapter4_proposed.tex</h2>

<p>Found 4 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 148 words). You should consider merging it with another section or make it longer. [sh:seclen]">chapter</span>{Proposed Methodology I} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:proposed1} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use~\ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">In this chapter, a novel architecture is introduced for detecting COVID-19 that is designed to be lightweight. The architecture is based on two key components: spatial kernel separability and residual connection. By exploiting spatial kernel separability, the number of training parameters is significantly reduced, making the model more computationally efficient. Additionally, residual connections are used extensively to maintain network stability during the training process and to provide the model with regularization effects that reduce overfitting. This combination of spatial kernel separability and residual connections creates a lightweight architecture that is highly effective at detecting COVID-19. Overall, this chapter provides a valuable contribution to the field of COVID-19 detection by introducing a novel and efficient architecture that can help to identify the disease quickly and accurately. </div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[th]</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline">    \centering</div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[height=40mm,width=8.0cm]{Figures/fig1.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline">    <span class="comment">% \decoRule</span></div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">    <span class="keyword1">\caption</span>{The phases of the proposed method I.}</div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline">    <span class="keyword1">\label</span>{fig1}</div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline">    <span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline"><span class="keyword1">\section</span>{Methodology I}</div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline">In this section, a  proposed  method I to detect COVID-19 disease from chest X-Ray images is presented. The proposed method exploits CNN model to classify the input chest X-Ray image to one of two categories; normal case or Covid-19 case. The proposed  method I consists of three phases: preprocessing, feature extraction, and classification. The proposed method phases are shown in Fig.~\ref{fig1}. </div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline"><span class="keyword1">\subsection</span>{Preprocessing Phase}</div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline">The preprocessing phase is responsible for resizing and normalizing the  input  chest X-Ray images. The pre-processing phase is employed to maintain the numerical stability of the model and reduce the co-variance shift~\cite{lecun1989handwritten}. In addition, this phase leads the learning model of CNN model to reduce  the required overhead to adapt to the different scales of different features of the input data. Reshaping size is determined empirically. The input chest X-Ray image is re-sized and then adapted and normalized to a normal distribution as follows:</div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline">Y := \frac{x_i - \mu_{\mathcal B}}{\sqrt{\sigma_{\mathcal B}^2 + \epsilon}}</div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline"><span class="keyword1">\label</span>{eq1}</div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline">where $\mu$ and $\sigma$ is the mean and standard deviation of chest X-Ray image (X), respectively.</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline">After re-sizing the input chest X-Ray image, the input image is normalized to have a zero mean and unit standard deviation. Then,  the image can be scaled and shifted with a normalization parameter which is determined and adapted by the training dataset during the training process according to the following equation: </div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline">Z := w_1 Y + w_2</div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline"><span class="keyword1">\label</span>{eq2}</div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline">where $w_1$ and $w_2$ are a trainable parameter.</div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline">Unlike the  normalization method presented in~\cite{ioffe2015batch}, the batch normalization process presented in this paper has $z$-score normalization parameter that is used in both training and validation phases.</div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline"><span class="keyword1">\subsection</span>{Feature Extraction and Classification}</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline">CNN models achieved an outstanding success in image recognition~\cite{lecun2015deep}. This phase  is responsible for extracting spatial features from the normalized chest X-Ray image using a tailored CNN model.  This phase is based on learning the CNN model by the input preprocessed chest X-Ray images. The design of the tailored CNN model is described as follows: </div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Separable CNN kernels}</div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline"><span class="keyword2">\begin{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline"><span class="keyword1">\includegraphics</span>[height=33mm,width=14.0cm]{Figures/fig2.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline"><span class="keyword1">\caption</span>{Separable convolution  $Gy$ and $Gx$ have kernel size of $M\times1$ and $1 \times M$. The combination of these kernels is approximately a $M\times M$ kernel  and depth wise convolution are applied by a $1\times1$ convolution. The output depth  is padded with zeros to have the same spatial size of  $Gy, Gx$. $Gy, Gx$ are performed channel wise. }</div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline"><span class="highlight-sh" title="This figure is missing a label [sh:figref]">\</span>label{fig2}<span class="keyword2">\end{center}</span><span class="keyword2">\end{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline">    </div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline">Kernel separability~\cite{rigamonti2013learning}~\cite{szegedy2017inception} is based on decomposing a 2D convolution kernel to linear combinations of two 1D vectors which leads to a large reduction in  the total number of resulting parameters. For example, a 2D kernel of size $9 \times 9$ has a total number of $9^2 = 81$  trained parameters. Whereas in the case of separating this 2D kernel to  linear combinations of two 1D vectors of sizes $9 \times 1$ and $1 \times 9$, this results in a total number of  $9 + 9 = 18$ trained parameters. As a consequence, kernel separability reduces the number of CNN model operations (such as the multiplication and the addition). A  2D kernel of $k \times k$ applied for 2D signal with spatial dimensions of $ M \times N$ has a total number of  $(N-4)(M-4)\times k^2$ operations but in case of  applying kernel separability  yields $2(N-4)(M-4)k$ operations. The flow of separated convolution operations are summarized in Fig.~\ref{fig2}. Fig.~\ref{fig3} represents the structure, denoted by Separated Convolutional Layer, used in the proposed method with kernel size of $(M\times N)$ and satisfying the convolutional kernel separability. Separated Convolutional Layer is composed of three consecutive layers. The first convolutional layer has a kernel size of $(M\times1)$ and the number of convolutional neuron and  filters are equal to the number of channels as the input feature map and the convolution operations are performed in a channel wise. The second layer  operates in the same way as the first layer but it has a kernel of size $(1\times M)$. The third layer is the convolutional layer with kernel of size $(1\times1)$ and number of convolutional neuron is $N$. The collaboration of the three layers are  connected to preform similarly to the convolutional layer with kernel size of $(M\times M)$ and number of neuron and filter are the same as $N$ but with large difference in the performance.</div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[height=34mm,width=7.0cm]{Figures/fig3.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline">    <span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Separated Convolutional Layer</span>}{ composed of three consecutive layers. The first Convolutional layer has a kernel size of $(M\times1)$ and $D$  convolutional neuron. The second layer  operates in the same way as the first layer but it has a kernel of size $(1\times M)$ and $D$ convolutional neuron. The third layer is the convolutional layer with kernel of size $(1\times1)$ and number of convolutional neuron is $N$.}</div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline">    <span class="keyword1">\label</span>{fig3}</div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline">    <span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline"><span class="keyword1">\subsubsection</span>{ Batch Normalization and  Activation function}</div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline">In the proposed method linear separable convolutional kernels are followed by a batch normalization and an activation function. Rectified Linear Unit (ReLU)~\cite{he2015delving} is a nonlinear activation that allows the network to fit and approximate highly non-linear datasets distribution. The proposed method employs the batch normalization which is described in~\cite{ioffe2015batch}. </div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline">Batch Normalization~\cite{ioffe2015batch} reduces internal covariate shift produced as a result of  moving between layers during the feedforward procedure~\cite{ioffe2015batch}. Batch Normalization makes the loss landscape smoother and reduces the number of saddle points~\cite{santurkar2018does} which allows to use higher learning rates. Using a higher learning rate makes the network training  faster~\cite{ioffe2015batch}. Batch normalization reduces the vanishing gradient problem and exploding gradient problem as it makes the resulted activation scale independent from the trainable parameter scale~\cite{ioffe2015batch}. Batch normalization has the effect of regularization because of the inherited randomness when selecting the batch sample~\cite{ioffe2015batch} which help the generalization to unseen chest X-Ray image.</div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline"><span class="keyword1">\subsubsection</span>{ Deep and larger receptive field Network design}</div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline">Deeper convolutional neural network design is a very important task for any image recognition task~\cite{he2016deep}. Training a deeper network is very expensive and has many challenges such as vanishing gradient problem, exploding gradient problem, and degradation problem~\cite{he2016deep}. Exploding gradient problem occurs  when the  gradient update becomes very large (approaching infinity) resulting in the network diversion. Vanishing gradient problem occurs when the  gradient update becomes very small (approaching zero) resulting in preventing the parameter update for early layers~\cite{ioffe2015batch} and preventing the network to learn new patterns. Batch normalization~\cite{ioffe2015batch} and the use of ReLU activation function~\cite{krizhevsky2012imagenet} alleviate these two problems.</div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline">The deep layers of CNN networks sometimes need to  approximate the identity function which is not a simple task especially  with the existence of a non-linear functions. Residual connection~\cite{he2016deep} overcomes this problem by using skip connection as shown in Fig.~\ref{fig4}.</div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">Fig.~\ref{fig4} represents the building block layer of the feature extraction phase, denoted by stack of Residual Separated Block  (RSB). RSB consists of four layers of separated convolutional layers, each layer is followed by a batch normalization and an activation function. It has an output of depth $N$ where each sublayer produces an output of depth $N/4$ which is concatenated at the end of the layer to produce a depth  $N$. RSB produces a feature map that includes both low level features and high level features.</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline"><span class="keyword2">\begin{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline"><span class="keyword1">\includegraphics</span>[height=38mm,width=14.0cm]{Figures/fig4.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline"><span class="keyword1">\caption</span>{The stack of residual separated block  (RSB) consists of four layer of separated convolutional layer each of which is followed by batch normalization and activation function.}</div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline"><span class="keyword1">\label</span>{fig4}</div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline"><span class="keyword2">\end{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline"><span class="keyword2">\begin{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">    <span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline">    <span class="keyword1">\includegraphics</span>[height=37mm,width=14.0cm]{Figures/fig5.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">    <span class="keyword1">\caption</span>{The complete proposed tailored CNN architecture.}</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline">    <span class="keyword1">\label</span>{fig5}</div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">    <span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline">    <span class="keyword2">\end{figure*}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">    </div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline">Unlike the traditional neural network, which is fully connected to the previous layer, convolutional neural network is connected locally to a local region of the previous feature map. This introduces the concept of the network receptive field~\cite{luo2016understanding}. Receptive field should be large enough to capture large patterns in the input chest X-Ray image. Therefore, any consecutive convolutional layers in the proposed method without a pooling layer in between a larger kernel size is used in one of them. Residual Separated block, RSB, in Fig.~\ref{fig4} may have kernel sizes of 3, 5, 7, and 9, respectively.<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline">Fig.~\ref{fig5} Represent a complete CNN architecture.</div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline"><span class="keyword1">\section</span>{Summary}</div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline"><span class="comment"><span class="comment">% In this chapter a lightweight CNN architecture is proposed for COVID19 detection. Proposed architecture is based on spatial separability of the convolutional kernel to enforce the learning of linear kernels. The proposed architecture consists of separated kernels convolutional layers that is connected by a residual connection. The proposed architecture uses batch normalization to maintain the network stability during the training process.</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline"><span class="comment"><span class="comment">% In this chapter, a novel lightweight CNN architecture is proposed for COVID-19 detection that is based on the concept of spatial kernel separability. The proposed architecture is designed to reduce the number of training parameters and improve computational efficiency by exploiting the separability of convolutional kernels. By learning linear kernels, the model can perform faster and more accurately on the given dataset. The proposed architecture includes separated kernel convolutional layers that are connected by a residual connection, which helps maintain network stability during training. Additionally, the proposed architecture utilizes batch normalization, a technique that helps to standardize the inputs of each layer and improve the convergence rate of the model. By combining these techniques, the proposed architecture offers a lightweight, efficient, and accurate method for detecting COVID-19.</span></span></div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline">In this chapter, the proposed lightweight CNN architecture for COVID-19 detection is designed with the concept of spatial separability in mind. The spatial separability of the convolutional kernel is used to enforce the learning of linear kernels, which reduces the number of training parameters and improves computational efficiency. Essentially, the model is designed to recognize patterns in the data that are linearly separable, which enables the use of simpler and more efficient models.</div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline">The proposed architecture comprises of separated kernel convolutional layers that are connected by a residual connection. The use of separated kernel convolutional layers helps to reduce the number of training parameters, while the residual connection improves network stability during the training process. The residual connection enables the model to retain important features while also discarding unimportant ones, which helps prevent overfitting.</div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline">Batch normalization is used in the proposed architecture to maintain network stability during the training process. The technique standardizes the inputs of each layer, which improves the convergence rate of the model. This is done by normalizing the layer inputs to have zero mean and unit variance, which helps prevent internal covariate shift. Internal covariate shift refers to the change in the distribution of network activations that occurs during training, which can slow down the convergence rate.</div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline">In summary, the proposed lightweight CNN architecture for COVID-19 detection is based on the spatial separability of the convolutional kernel, with separated kernel convolutional layers connected by a residual connection. Batch normalization is used to maintain network stability during training, which improves the convergence rate of the model. By combining these techniques, the proposed architecture offers an efficient, accurate, and stable method for detecting COVID-19.</div><div class="clear"></div>
</div>
<hr/>
Output produced by TeXtidote v0.8.2, &copy; 2018-2020 Sylvain Hall&eacute; - All rights reserved.<br/>
See the <a href="https://sylvainhalle.github.io/textidote">TeXtidote website</a> for more information.
</body>
</html>
