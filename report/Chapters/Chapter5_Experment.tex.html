<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>TeXtidote analysis</title>
<style type="text/css">
body {
  font-family: sans-serif;
}
.highlight, .highlight-sh, .highlight-spelling {
  padding: 2pt;
  border-radius: 4pt;
  cursor: help;
  opacity: 0.7;
  border: dashed 1px;
}
.highlight {
  background-color: orange;
  color: black;
}
.highlight-sh {
  background-color: yellow;
  color: black;
}
.highlight-spelling {
  background-color: red;
  color: white;
}
div.original-file {
  font-family: monospace;
  font-size: 11pt;
  background-color: #f8f8ff;
  padding: 20pt;
  border-radius: 6pt;
}
.textidote {
  	background-image: url(data:image/svg+xml;base64,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);
}
h2.filename {
  font-family: monospace;
}
h1.textidote {
  width: 378px;
  height: 68px;
  display: block;
}
.keyword1 {
  font-weight: bold;
  color: green;
}
.keyword2 {
  font-weight: bold;
  color: darkblue;
}
.comment, .comment * {
  color: darkred;
  font-weight: normal;
}
.linenb {
  font-style: italic;
  color: lightgrey;
  width: 30pt;
  float: left;
  margin-top: 1pt;
  margin-bottom: 1pt;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.codeline {
  margin-left: -30pt;
  padding-left: 60pt;
  margin-top: 1pt;
  margin-bottom: 1pt;
}
.no-text {
  display: none;
}
.clear {
  clear: both;
}
</style>
</head>
<body>
<a href="https://sylvainhalle.github.io/textidote"><h1 class="textidote"><span class="no-text">Results of TeXtidote analysis</span></h1></a>
<p>Here is the result of analyzing your file(s) with TeXtidote. Hover the mouse over highlighted portions of the document to read a tooltip that gives you some writing advice.</p>
<p>Found 22 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="comment"><span class="comment">% Chapter Template</span></span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline">\chapter{Experimental Results} <span class="comment">% Main chapter title</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline"><span class="keyword1">\label</span>{chp:results} <span class="comment">% Change X to a consecutive number; for referencing this chapter elsewhere, use~\ref{ChapterX}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline">In this chapter proposed methodologies are evaluated and compared with the related work.</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline">All models are Trained using QaTa-Cov-19~\cite{ahishali2021advance} dataset using NVIDIA Tesla P-100 GPU and programmed using PyTorch.</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline"><span class="keyword1">\section</span>{QaTa-COV19 Dataset}</div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=60mm,width=9cm]{ScaleDist.png}}</div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Pneumonia Scales of QaTa-COV19-v1, Y-axis represents the frequency, number of occurrence, of a pneumonia with a particular area</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline"><span class="keyword1">\label</span>{pdist}</div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline">QaTa-COV19 is a benchmark dataset for COVID-19 detection and Segmentation form CXR images. All models that used for comparison are trained using QaTa-COV19-v1. Qata-COV19-v1 consists of 4603 COVID-19 CXR and $120,013$ control group CXRs. A balanced number of samples for the two classes is used, namely 4603 CXR image for each class to train the models. Pneumonia Scales of QaTa-COV19-v1 does not exhibit a uniform distribution. Scale of the Pneumonia can be defined as number, area, of 8-neighbor connected pixels labeled as COVID-19 pneumonia. QaTa-COV19-v1 provides a binary masks of 2951 COVID-19 CXR image which can be used for approximating the distribution of scales across the dataset. Fig.~\ref{pdist} illustrates the statistical distribution of QaTa-COV19 scales. The non-uniform distribution of the scales allows the CNN models to only recognize the small scales and not large scales.</div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline"><span class="keyword1">\section</span>{Evaluation of the Methodology I}</div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline">Experiments are conducted on a Lenovo Z50-70 with Intel CORE i7-4510U CPU 2.00 GHz, 8GB RAM, NVIDIA GeForce 840M GPU; and with python and PyTorch library.</div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline"><span class="keyword1">\subsection</span>{Details of the Proposed Architecture}</div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline">The Proposed architecture composed Convbase and Densebase. Convbase is composed of a $6$ feature extraction modules <span class="keyword1">\textit</span>{(FX)} preceded by batch normalization layer. Each FX module can be considered sub-sequential model consists of RSB layer followed by Batch Normalization, Max-pooling and LeakyReLU activation function. The Densebase is a two fully connected layers that classify the Convbase output.</div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline"><span class="keyword1">\subsection</span>{Hyperparameter Specification}</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline">All input chest X-Ray images are resized to be $200\times 200$ . After resizing the input images, these images are fed the Convbase model part which consists of 6 layers of residual separated block. Each residual separated block is followed with batch normalization and LeakyReLU~\cite{he2015delving} as activation function. The output depth of each residual separated block is 4$\times$16, 4$\times$32, 4$\times$64, 4$\times$64, 4$\times$64 and 4$\times$16, respectively. The output of Convbase model part is 1D feature vector of 576 length. Densebase model part consists of two hidden layers. Each layer has the  size of 64 and the output layer of size 2. Each layer of Densebase layers is fully connected to its previous layer. The activation function used in the densebase model part is LeakyReLU. Table~\ref{lyrSpec} summarizes the architecture hyperparameters.</div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{The proposed architecture hyperparameters</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|l|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline"><span class="keyword1">\textbf</span>{Layer Number} &amp; <span class="keyword1">\textbf</span>{Layer Size} &amp; <span class="keyword1">\textbf</span>{Activation Function} \\</div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">RSBLayer1 &amp; 4 $\times$ 16 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline">RSBLayer2 &amp; 4 $\times$ 23 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline">RSBLayer3 &amp; 4 $\times$ 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline">RSBLayer4 &amp; 4 $\times$ 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline">RSBLayer5 &amp; 4 $\times$ 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline">RSBLayer6 &amp; 4 $\times$ 16 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline">\multicolumn{3}{|c|}{<span class="keyword1">\textit</span>{Flatten The Feature maps to 1D 576 feature  vector}}\\</div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline">\cline{1-3}</div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline">LinearLayer1 &amp; 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline">LinearLayer2 &amp; 64 &amp; LeakyReLU\\</div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">LinearLayer3 &amp; 2 &amp; Softmax\\</div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline"><span class="keyword1">\label</span>{lyrSpec}</div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline"><span class="keyword1">\subsection</span>{Network Training}</div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">The proposed CNN model  is trained for 22 epoch. Adaptive Moment Estimation (Adam) optimizer~\cite{kingma2014adam} is a popular optimization  technique for training deep networks. Adam optimizer is used  during the training  phase of the proposed CNN model. Both batch size and Adam optimizer learning rate is changed during the training phase if the training loss stopped decreasing. Table~\ref{tabTrparam} summarizes the parameters values used in the training phase of the proposed CNN model. Fig.~\ref{fig5}(a) show the progress for training and validation loss across each epoch. The difference between the training loss and validation loss through epochs show that our did not memorize the dataset.</div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{The change of batch size and learning rate through the Training process</span>}</div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|l|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline"><span class="keyword1">\textbf</span>{Epoch Number} &amp; <span class="keyword1">\textbf</span>{Batch Size} &amp; <span class="keyword1">\textbf</span>{Learning Rate} \\</div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">From 0 to 6 &amp; 128 &amp; 1e-3\\</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline">From 7 to 12 &amp; 256 &amp; 1e-3\\</div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline">From 13 to 21 &amp; 256 &amp; 1e-4\\</div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline"> </div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline"><span class="keyword1">\label</span>{tabTrparam}</div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline"><span class="keyword1">\subsection</span>{Model Evaluation}</div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline">To assess the efficiency of the proposed method,  the proposed method is compared to recent state-of-the-art methods for detecting Covid-19 cases. Experiments are conducted with the same dataset and the corresponding hyperparameter of each work. All the methods depend on CNN. The comparison is performed using precision, sensitivity, F1-score, and accuracy~\cite{hossin2015review}. In addition, the number of the parameters used in the training phase is very important comparison factor. Table~\ref{modelperf} depicts the comparison between state-of-the-art methods and the proposed method. As shown in the comparison, the proposed method  outperforms other methods achieving the maximum accuracy and the lowest  parameter count. </div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline"><span class="keyword1">\caption</span>{ A performance comparison between the proposed method and state-of-the-art models.}</div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|l|c|c|c|c|c|}</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline"><span class="keyword1">\textbf</span>{Method} &amp; <span class="keyword1">\textbf</span>{PC} &amp; <span class="keyword1">\textbf</span>{P(\%)}&amp; <span class="keyword1">\textbf</span>{S(\%)}&amp; <span class="keyword1">\textbf</span>{F1(\%)}&amp; <span class="keyword1">\textbf</span>{A(\%)} \\</div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline">Proposed Method &amp; 0.15M &amp; 100.00 &amp; 100.00 &amp; 100.00 &amp;100.00\\</div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline">ResNet-34~\cite{nayak2021application} &amp; 21.8M &amp; 96.77&amp; 100.00 &amp; 98.36 &amp;98.33  \\</div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline">ACoS Phase I~\cite{chandra2021coronavirus}&amp; - &amp; 98.266 &amp; 96.512 &amp; 98.551 &amp; 98.062 \\</div><div class="clear"></div>
<div class="linenb">108</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">109</div><div class="codeline">ResNet-50~\cite{nayak2021application}&amp; 25.6M&amp; 95.24&amp; 100.00&amp; 97.56&amp; 97.50 \\</div><div class="clear"></div>
<div class="linenb">110</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">111</div><div class="codeline">GoogleNet~\cite{nayak2021application}&amp; 5M &amp;96.67&amp; 96.67&amp; 96.67&amp; 96.67 \\</div><div class="clear"></div>
<div class="linenb">112</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">113</div><div class="codeline">VGG-16~\cite{nayak2021application}&amp; 138M&amp; 95.08 &amp; 96.67 &amp; 95.87 &amp;95.83\\</div><div class="clear"></div>
<div class="linenb">114</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">115</div><div class="codeline">AlexNet~\cite{nayak2021application}&amp; 60M&amp; 96.72 &amp;98.33 &amp; 97.52&amp; 97.50 \\</div><div class="clear"></div>
<div class="linenb">116</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">117</div><div class="codeline">MobileNet-V2~\cite{nayak2021application} &amp; 3.4M &amp;98.24&amp; 93.33&amp; 95.73 &amp; 95.83 \\</div><div class="clear"></div>
<div class="linenb">118</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">119</div><div class="codeline">Inception-V3~\cite{nayak2021application}&amp; 24M &amp;96.36&amp; 88.33 &amp; 92.17&amp; 92.50\\</div><div class="clear"></div>
<div class="linenb">120</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">121</div><div class="codeline">SqueezeNet~\cite{nayak2021application}&amp; 1.25M &amp;98.27 &amp;95.00&amp; 96.61&amp; 96.67 \\</div><div class="clear"></div>
<div class="linenb">122</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">123</div><div class="codeline">\multicolumn{6}{l}{<span class="keyword1">\textit</span>{ PC is Parameter count, P is precision, S is sensitivity }}\\</div><div class="clear"></div>
<div class="linenb">124</div><div class="codeline">\multicolumn{6}{l}{<span class="keyword1">\textit</span>{  F1 is F1-score, and A is accuracy }}\\</div><div class="clear"></div>
<div class="linenb">125</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">126</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">127</div><div class="codeline"><span class="keyword1">\label</span>{modelperf}</div><div class="clear"></div>
<div class="linenb">128</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">129</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">130</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">131</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">132</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">133</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">134</div><div class="codeline"><span class="keyword1">\includegraphics</span>[height=90mm,width=8.0cm]{Figures/fig6.png}</div><div class="clear"></div>
<div class="linenb">135</div><div class="codeline"><span class="highlight-sh" title="This figure is missing a label [sh:figref]"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]">\</span>caption{(a) The training loss and the validation loss of each epoch and (b) The training accuracy and the validation accuracy of each epoch.}<span class="keyword1">\label</span>{fig5</span>}<span class="keyword2">\end{center}</span><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">136</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">137</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">138</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">139</div><div class="codeline">\<span class="highlight-sh" title="This section is very short (about 15 words). You should consider merging it with another section or make it longer. [sh:seclen]"><span class="highlight-sh" title="This section is very short (about 16 words). You should consider merging it with another section or make it longer. [sh:seclen]">section</span></span>{Evaluation of the Methodology II}</div><div class="clear"></div>
<div class="linenb">140</div><div class="codeline">Methodology II is evaluated and compared against strong baselines and related works. </div><div class="clear"></div>
<div class="linenb">141</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">142</div><div class="codeline"><span class="keyword1">\subsection</span>{Baseline Networks}</div><div class="clear"></div>
<div class="linenb">143</div><div class="codeline">Different architectures are trained to validate the effectiveness of the proposed method. </div><div class="clear"></div>
<div class="linenb">144</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Spatial Pyramid Pooling (SPP-net) Based model}</div><div class="clear"></div>
<div class="linenb">145</div><div class="codeline">Four variants of SPP-ne<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">t\cite</span>{he2015spatial} is trained. All $4$ variants have the same architecture but different SPP-layer. These variants of SPP-layer are as follows:</div><div class="clear"></div>
<div class="linenb">146</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">147</div><div class="codeline">  <span class="keyword1">\item</span> full pyramid SPP of 8-levels using average-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">148</div><div class="codeline">  <span class="keyword1">\item</span> full SPP pyramid of 8-levels using max-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">149</div><div class="codeline">  <span class="keyword1">\item</span> single level SPP with 10-bins using average-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">150</div><div class="codeline">  <span class="keyword1">\item</span> single level SPP with 10-bins using max-pooling as aggregation function</div><div class="clear"></div>
<div class="linenb">151</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">152</div><div class="codeline">  A Fixed Architecture is used for all SPP variant models with the same design principles of the proposed architecture. These architectures are the same as the proposed architecture but DSWASPP is replaced by DC6 and SPP-1 layer is replaced with the corresponding SPP layer. DC6 is defined as six convolutional layers Densely connected together. For SPP-net variants training a multiscale augmentation is added to the proposed augmentation process. Multiscale augmentation is done by randomly sampling different $5$ scales typically $\{320, 320\pm25, 320\pm50 \}$.</div><div class="clear"></div>
<div class="linenb">153</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Switchable Atrous Spatial Pyramid Pooling (SASPP-net) Based models} </div><div class="clear"></div>
<div class="linenb">154</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">155</div><div class="codeline"><span class="keyword2">\begin{figure*}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">156</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=63mm,width=15cm]{SPP-netsTraining.PNG}}</div><div class="clear"></div>
<div class="linenb">157</div><div class="codeline"><span class="keyword1">\caption</span>{Training profiles of both SPP-net variants and the proposed network. For the same color solid line represents training statistics while dashed line represents the validation statistics for the corresponding model. <span class="keyword1">\textbf</span>{left:} is the training accuracy. <span class="keyword1">\textbf</span>{Right:} is the training loss.}</div><div class="clear"></div>
<div class="linenb">158</div><div class="codeline"><span class="keyword1">\label</span>{SPP-train}</div><div class="clear"></div>
<div class="linenb">159</div><div class="codeline"><span class="keyword2">\end{figure*}</span></div><div class="clear"></div>
<div class="linenb">160</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">161</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">162</div><div class="codeline">Another Base-line is introduced for comparison which is exactly as same as the proposed network but with different Attention module structure and does not include a bottleneck within ASPP. This architecture is referred Switchable Atrous Spatial Pyramid Pooling (SASPP-net). Attention module structure is $Softmax(FC(GAP(X)))$ where: <span class="keyword1">\textit</span>{$X$: is the input feature map}, <span class="keyword1">\textit</span>{$GAP$: is a global average pooling}, <span class="keyword1">\textit</span>{$FC$: is fully Connected layer performs a non-linear projection to ${\rm I\!R}^{4}$ a 4 values for the three scales and the input feature map}.<span class="highlight-sh" title="You should not break lines manually in a paragraph. Either start a new paragraph or stay in the current one. [sh:nobreak]">\</span>\</div><div class="clear"></div>
<div class="linenb">163</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">164</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">165</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Baselines and their total number of parameters</span>}</div><div class="clear"></div>
<div class="linenb">166</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">167</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|c|c|c|}</div><div class="clear"></div>
<div class="linenb">168</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">169</div><div class="codeline"><span class="keyword1">\textbf</span>{Model}&amp;\multicolumn{2}{|c|}{<span class="keyword1">\textbf</span>{Baseline CNN Architectures}} \\</div><div class="clear"></div>
<div class="linenb">170</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">171</div><div class="codeline"><span class="keyword1">\textbf</span>{Type} &amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Variant}}&amp; <span class="keyword1">\textbf</span>{<span class="keyword1">\textit</span>{Param. Count}} \\</div><div class="clear"></div>
<div class="linenb">172</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">173</div><div class="codeline">  &amp; ML Average pooling &amp; $14,916,420$   \\</div><div class="clear"></div>
<div class="linenb">174</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">175</div><div class="codeline">SPP &amp; ML max pooling &amp; $14,916,420$   \\</div><div class="clear"></div>
<div class="linenb">176</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">177</div><div class="codeline">  &amp; SL Average pooling &amp; $14,490,436$   \\</div><div class="clear"></div>
<div class="linenb">178</div><div class="codeline">\cline{2-3} </div><div class="clear"></div>
<div class="linenb">179</div><div class="codeline">  &amp; SL max pooling &amp; $14,490,436$ \\</div><div class="clear"></div>
<div class="linenb">180</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">181</div><div class="codeline">\multicolumn{2}{|c|}{SASPP} &amp; $13,031,841$\\</div><div class="clear"></div>
<div class="linenb">182</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">183</div><div class="codeline">\multicolumn{3}{l}{ <span class="keyword1">\textbf</span>{ML}: Multilevel, <span class="keyword1">\textbf</span>{SL}: Single level}</div><div class="clear"></div>
<div class="linenb">184</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">185</div><div class="codeline"><span class="keyword1">\label</span>{Basarch}</div><div class="clear"></div>
<div class="linenb">186</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">187</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">188</div><div class="codeline">Table~\ref{Basarch} summarizes the base-line models and the Corresponding parameter count.</div><div class="clear"></div>
<div class="linenb">189</div><div class="codeline"><span class="keyword1">\subsection</span>{Models Training}</div><div class="clear"></div>
<div class="linenb">190</div><div class="codeline">Proposed architecture and baseline architecture are trained with the same hyperparameters. Dataset is split to $0.6$, $0.2$ and $0.2$ for training, validation and testing, respectively. For training a Cross Entropy Loss is used. All models trained with ADAM~\cite{kingma2014adam} optimizer with learning rate start by $10^{-3}$ and reduced every time validation loss plateau by multiplying by $10^{-1}$. A Max Norm Constraint is used to clip the gradient value to norm of $1$~\cite{krizhevsky2012imagenet}. A batch size of $128$ is used to calculate the gradient.</div><div class="clear"></div>
<div class="linenb">191</div><div class="codeline"><span class="keyword1">\subsection</span>{Reducing the overfitting}</div><div class="clear"></div>
<div class="linenb">192</div><div class="codeline">Overfitting is a critical problem for training large networks~\cite{krizhevsky2012imagenet}. Proposed work has reduced the overfitting by using:</div><div class="clear"></div>
<div class="linenb">193</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">194</div><div class="codeline"><span class="keyword1">\item</span> Using Dropout with retrain probability of $0.5$~\cite{srivastava2014dropout}.</div><div class="clear"></div>
<div class="linenb">195</div><div class="codeline"><span class="keyword1">\item</span> Using BatchNorm adds noise due to randomization introduced when constructing the minibatch~\cite{ioffe2015batch}.</div><div class="clear"></div>
<div class="linenb">196</div><div class="codeline"><span class="keyword1">\item</span> Using max norm constraint~\cite{krizhevsky2012imagenet}.</div><div class="clear"></div>
<div class="linenb">197</div><div class="codeline"><span class="keyword1">\item</span> Deep and thin architectures by design has an implicit regularization effect~\cite{he2016deep}. </div><div class="clear"></div>
<div class="linenb">198</div><div class="codeline"><span class="keyword1">\item</span> Augmentation process <span class="highlight-sh" title="Use a backslash or comma after the second period; otherwise LaTeX will think it is a full stop ending a sentence. [sh:011]">i.e.)</span> Texture augmentation~\cite{krizhevsky2012imagenet}. </div><div class="clear"></div>
<div class="linenb">199</div><div class="codeline"><span class="keyword1">\item</span> The use of small kernel size~\cite{simonyan2014very}.</div><div class="clear"></div>
<div class="linenb">200</div><div class="codeline"><span class="keyword1">\item</span> Bottleneck in SWASPP module and the attention module.</div><div class="clear"></div>
<div class="linenb">201</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">202</div><div class="codeline">During training no overfitting effects is observed.</div><div class="clear"></div>
<div class="linenb">203</div><div class="codeline">\<span class="highlight-sh" title="This subsection is very short (about 108 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsection</span>{Comparison with baselines}</div><div class="clear"></div>
<div class="linenb">204</div><div class="codeline">Proposed network is compared with the vanilla SPP-based Architectures and ASPP architecture.</div><div class="clear"></div>
<div class="linenb">205</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Comparing with SPP-nets}</div><div class="clear"></div>
<div class="linenb">206</div><div class="codeline">Fig.~\ref{SPP-train} illustrates both training loss and training and validation accuracies and losses. Table~\ref{blaccom} illustrates the testing accuracy for comparison between the SPP-nets baseline and the proposed architecture.</div><div class="clear"></div>
<div class="linenb">207</div><div class="codeline"><span class="keyword2">\begin{table}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">208</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Comparison between Proposed network and baseline SPP architectures </span>}</div><div class="clear"></div>
<div class="linenb">209</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">210</div><div class="codeline"><span class="keyword2">\begin{tabular}</span>{|c|c|}</div><div class="clear"></div>
<div class="linenb">211</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">212</div><div class="codeline"><span class="keyword1">\textbf</span>{Model Name}&amp; Accurracy \\</div><div class="clear"></div>
<div class="linenb">213</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">214</div><div class="codeline"> SPP ML Average pooling &amp; $0.958$   \\</div><div class="clear"></div>
<div class="linenb">215</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">216</div><div class="codeline">SPP ML max pooling &amp; $0.950$   \\</div><div class="clear"></div>
<div class="linenb">217</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">218</div><div class="codeline">  SPP SL Average pooling &amp; $0.927$   \\</div><div class="clear"></div>
<div class="linenb">219</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">220</div><div class="codeline">  SPP SL max pooling &amp; $0.957$ \\</div><div class="clear"></div>
<div class="linenb">221</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">222</div><div class="codeline">Proposed Network &amp; $0.987$\\</div><div class="clear"></div>
<div class="linenb">223</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">224</div><div class="codeline">\multicolumn{2}{l}{ <span class="keyword1">\textbf</span>{ML}: Multilevel, <span class="keyword1">\textbf</span>{SL}: Single level}</div><div class="clear"></div>
<div class="linenb">225</div><div class="codeline"><span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">226</div><div class="codeline"><span class="keyword1">\label</span>{blaccom}</div><div class="clear"></div>
<div class="linenb">227</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">228</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">229</div><div class="codeline">\<span class="highlight-sh" title="This subsubsection is very short (about 71 words). You should consider merging it with another section or make it longer. [sh:seclen]">subsubsection</span>{Comparing with SASPP}</div><div class="clear"></div>
<div class="linenb">230</div><div class="codeline">Fig.~\ref{saspp} illustrates the training and validation loss of training a SASPP baseline architecture. As shown in Fig.~\ref{saspp} SASPP unable to generalize and start overfitting the training set. This comparison empirically shows the importance of the bottleneck introduced in the proposed architecture.</div><div class="clear"></div>
<div class="linenb">231</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">232</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">233</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">234</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{saspp.PNG}}</div><div class="clear"></div>
<div class="linenb">235</div><div class="codeline"><span class="keyword1">\caption</span>{SASPP baseline architecture loss during both training, solid line, and validation, bashed line, compared with Proposed network and best performing SPP architecture.}</div><div class="clear"></div>
<div class="linenb">236</div><div class="codeline"><span class="keyword1">\label</span>{saspp}</div><div class="clear"></div>
<div class="linenb">237</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">238</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">239</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">240</div><div class="codeline"><span class="keyword1">\subsection</span>{Comparing with the related works}</div><div class="clear"></div>
<div class="linenb">241</div><div class="codeline">To fairly compare with the related works proposed work is further trained. Fig.~\ref{ploss} shows the training and validation loss of the proposed network. Fig.~\ref{pacc} shows the of the training and validation accuracy. </div><div class="clear"></div>
<div class="linenb">242</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">243</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">244</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{PLOSS.PNG}}</div><div class="clear"></div>
<div class="linenb">245</div><div class="codeline"><span class="keyword1">\caption</span>{Cross entropy loss of the proposed architecture.}</div><div class="clear"></div>
<div class="linenb">246</div><div class="codeline"><span class="keyword1">\label</span>{ploss}</div><div class="clear"></div>
<div class="linenb">247</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">248</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">249</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">250</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">251</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{PACC.PNG}}</div><div class="clear"></div>
<div class="linenb">252</div><div class="codeline"><span class="keyword1">\caption</span>{Training and validation accuracy of the proposed architecture.}</div><div class="clear"></div>
<div class="linenb">253</div><div class="codeline"><span class="keyword1">\label</span>{pacc}</div><div class="clear"></div>
<div class="linenb">254</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">255</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">256</div><div class="codeline">Proposed Network has a sensitivity, recall, and precision of $0.994$ and $0.991$ respectively on the validation set. Precision can be improved by investigating the precision-recall trade-off. Fig.~\ref{prt} shows the trade-off between precision and recall for different thresholds. A threshold of $0.618$ is used to improve the precision resulting in a sensitivity, recall, of $0.9903$ and precision of $0.9956$.</div><div class="clear"></div>
<div class="linenb">257</div><div class="codeline">Comparison metrics are defined as follows:</div><div class="clear"></div>
<div class="linenb">258</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">259</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Accuracy}: is ratio of correctly classified samples to the total number of samples</div><div class="clear"></div>
<div class="linenb">260</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Sensitivity}: is ratio of correctly classified Covid-19 samples to the total number of actual Covid-19 samples </div><div class="clear"></div>
<div class="linenb">261</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Precision}: is the ratio of correctly, according to the ground-truth labels, classified Covid-19 samples to the total number of samples classified as Covid-19.</div><div class="clear"></div>
<div class="linenb">262</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Specificity}: is the ratio of correctly, according to the ground-truth labels, classified non-COVID-19 to the total number of non-Covid-19.</div><div class="clear"></div>
<div class="linenb">263</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{F1-score}: is the harmonic mean of both Sensitivity and Precision.</div><div class="clear"></div>
<div class="linenb">264</div><div class="codeline"><span class="keyword2">\begin{center}</span>  </div><div class="clear"></div>
<div class="linenb">265</div><div class="codeline"> $F_{1}=\frac{2\times\text{Precision} \times \text{Sensitivity}}{\text{Precision} + \text{Sensitivity}}$</div><div class="clear"></div>
<div class="linenb">266</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">267</div><div class="codeline"><span class="keyword1">\item</span> <span class="keyword1">\textit</span>{Param. Count}: is the total number of the trainable parameters.</div><div class="clear"></div>
<div class="linenb">268</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">269</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">270</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">271</div><div class="codeline"><span class="keyword2">\begin{table*}</span>[!p!t]</div><div class="clear"></div>
<div class="linenb">272</div><div class="codeline"><span class="highlight-sh" title="A caption should end with a period [sh:capperiod]"><span class="keyword1">\caption</span>{Comparison between Proposed network and Related works </span>}</div><div class="clear"></div>
<div class="linenb">273</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">274</div><div class="codeline">\resizebox{\textwidth}{!}{<span class="keyword2">\begin{tabular}</span>{|c|c|c|c|c|c|c|}</div><div class="clear"></div>
<div class="linenb">275</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">276</div><div class="codeline"><span class="keyword1">\textbf</span>{Model Name}&amp; <span class="keyword1">\textbf</span>{Accuracy} &amp; <span class="keyword1">\textbf</span>{Sensitivity} &amp;<span class="keyword1">\textbf</span>{ Precision} &amp; <span class="keyword1">\textbf</span>{Specificity} &amp; <span class="keyword1">\textbf</span>{F1-score} &amp; <span class="keyword1">\textbf</span>{Param. Count}\\</div><div class="clear"></div>
<div class="linenb">277</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">278</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">279</div><div class="codeline">Proposed &amp; 0.99294 &amp; <span class="keyword1">\textbf</span>{0.9903} &amp; <span class="keyword1">\textbf</span>{0.9956} &amp; 0.9956 &amp; <span class="keyword1">\textbf</span>{0.9929} &amp; <span class="keyword1">\textbf</span>{5,040,571}\\</div><div class="clear"></div>
<div class="linenb">280</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">281</div><div class="codeline">SRC-Dal<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">m\cite</span>{ar} &amp; 0.985 &amp; 0.886 &amp; - &amp; 0.993 &amp; - &amp; -\\</div><div class="clear"></div>
<div class="linenb">282</div><div class="codeline">\hline </div><div class="clear"></div>
<div class="linenb">283</div><div class="codeline">SRC-Ho<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">m\cite</span>{ar} &amp; 0.977 &amp; 0.921 &amp; - &amp; 0.982 &amp; - &amp; - \\</div><div class="clear"></div>
<div class="linenb">284</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">285</div><div class="codeline">CRC-ligh<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">t\cite</span>{ar} &amp; 0.973 &amp; 0.955 &amp; - &amp; 0.974 &amp; - &amp;- \\</div><div class="clear"></div>
<div class="linenb">286</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">287</div><div class="codeline">DenseNet121*\cite{ar} &amp; 0.992 &amp; 0.9714 &amp; - &amp; 0.9949 &amp; - &amp; 6,955,906  \\</div><div class="clear"></div>
<div class="linenb">288</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">289</div><div class="codeline">Inception-v<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">3\cite</span>{ar} &amp; 0.993 &amp; 0.954 &amp; - &amp; 0.998 &amp; - &amp; 21,772,450  \\</div><div class="clear"></div>
<div class="linenb">290</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">291</div><div class="codeline">Modified MobileNetV2~\cite{akt}  &amp; 0.98 &amp; 0.98 &amp; 0.97 &amp; - &amp; 0.97 &amp; -\\</div><div class="clear"></div>
<div class="linenb">292</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">293</div><div class="codeline">ReCovNet-v<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">2\cite</span>{dag} &amp; 0.99726 &amp; 0.98571 &amp; 0.94262 &amp; 0.9977 &amp; 0.96369 &amp;- \\</div><div class="clear"></div>
<div class="linenb">294</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">295</div><div class="codeline">ReCovNet-v<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">1\cite</span>{dag} &amp; 0.99824 &amp; 0.9781 &amp; 0.97438 &amp; 0.99901 &amp; 0.97624 &amp; -\\</div><div class="clear"></div>
<div class="linenb">296</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">297</div><div class="codeline">DenseNet-12<span class="highlight-sh" title="Add a space before citation or reference. [sh:c:001]">1\cite</span>{dag}  &amp; <span class="keyword1">\textbf</span>{0.9988} &amp; 0.97429 &amp; 0.9932 &amp; <span class="keyword1">\textbf</span>{0.99974} &amp; 0.98365 &amp; 6,955,906 \\</div><div class="clear"></div>
<div class="linenb">298</div><div class="codeline">\hline</div><div class="clear"></div>
<div class="linenb">299</div><div class="codeline"><span class="keyword2">\end{tabular}</span>}</div><div class="clear"></div>
<div class="linenb">300</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">301</div><div class="codeline"><span class="keyword1">\label</span>{rwcom}</div><div class="clear"></div>
<div class="linenb">302</div><div class="codeline"><span class="keyword2">\end{table*}</span></div><div class="clear"></div>
<div class="linenb">303</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">304</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">305</div><div class="codeline"><span class="keyword2">\begin{center}</span></div><div class="clear"></div>
<div class="linenb">306</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[htbp]</div><div class="clear"></div>
<div class="linenb">307</div><div class="codeline">\centerline{<span class="keyword1">\includegraphics</span>[height=55mm,width=8cm]{PresRecuTradff.PNG}}</div><div class="clear"></div>
<div class="linenb">308</div><div class="codeline"><span class="keyword1">\caption</span>{precision-recall trade-off of the proposed network.}</div><div class="clear"></div>
<div class="linenb">309</div><div class="codeline"><span class="keyword1">\label</span>{prt}</div><div class="clear"></div>
<div class="linenb">310</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">311</div><div class="codeline"><span class="keyword2">\end{center}</span></div><div class="clear"></div>
<div class="linenb">312</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">313</div><div class="codeline">Table~\ref{rwcom} summarizes the comparison between the recent related works and the proposed architecture. Proposed architecture outperform these works in many metrics. As their training and testing does not depend on a balanced number of samples, accuracy and specificity are not good metrics for evaluation. </div><div class="clear"></div>
<div class="linenb">314</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">315</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">316</div><div class="codeline"><span class="keyword1">\section</span>{Summary}</div><div class="clear"></div>
<div class="linenb">317</div><div class="codeline"><span class="comment"><span class="comment">% This chapter illustrates the superior performance of the proposed work I and II. Experimental results of proposed work I show the effectiveness of spatial separable kernels and residual connection for detecting COVID-19. The proposed architecture I use batch normalization to maintain the network stability during the training process. During the training process, the hyperparameters (such as batch size and learning rate) are determined dynamically. Proposed architecture I outperformed previous works for binary classification of chest X-Ray images to normal or COVID-19 cases. The proposed architecture has a very low parameter count (150K trainable parameter) compared to previous work. The proposed  architecture I achieved a performance of 100\% for accuracy, sensitivity, precision and F1-score. Proposed work I does not take care of the fact that CNN is scale variant model while proposed work II does. Better quantitative results for CXR COVID-19 classification can be obtained with a multiscale training approaches. Proposed work II internally produces multiscale feature maps using Atrous Spatial pyramid pooling. These multiscales feature maps are fused using an attention module. To learn a compact representation a bottleneck dimension is introduced in both the multiscale feature extractor module and the attention module. Proposed work II outperformed current sate-of-the-art architecture with lower parameter number. Proposed method has recorded a $0.9929$ for $F1-score$.</span></span></div><div class="clear"></div>
<div class="linenb">318</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">319</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">320</div><div class="codeline">This chapter illustrates the superior performance of the proposed work I and II. In addition to the superior performance of the proposed works I and II, the chapter also provides a detailed analysis of the experimental results. The evaluation of proposed work I demonstrates that the use of spatial separable kernels and residual connection significantly improves the performance of the COVID-19 detection system. The batch normalization technique is found to be effective in maintaining the network stability during the training process. The dynamic selection of hyperparameters such as batch size and learning rate further improves the performance of the proposed architecture I.</div><div class="clear"></div>
<div class="linenb">321</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">322</div><div class="codeline">Furthermore, the proposed architecture I outperforms existing works for binary classification of chest X-Ray images for normal and COVID-19 cases. This is particularly noteworthy as the proposed architecture has a low parameter count of only 150K trainable parameters compared to previous works. The achievement of a performance of $100\%$ for accuracy, sensitivity, precision, and F1-score indicates the high accuracy and reliability of the proposed architecture.</div><div class="clear"></div>
<div class="linenb">323</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">324</div><div class="codeline">Although the proposed architecture I performs exceptionally well, it does not address the scale variant nature of the CNN model. This issue is addressed in the proposed work II, which incorporates multiscale training approaches to obtain better quantitative results for CXR COVID-19 classification. The use of Atrous Spatial pyramid pooling enables the internal production of multiscale feature maps, which are then fused using an attention module. To achieve a compact representation, a bottleneck dimension is introduced in both the multiscale feature extractor module and the attention module.</div><div class="clear"></div>
<div class="linenb">325</div><div class="codeline">&nbsp;</div><div class="clear"></div>
<div class="linenb">326</div><div class="codeline">The proposed work II outperforms the current state-of-the-art architecture with lower parameter numbers. The recorded $0.9929$ for F1-score indicates the high performance of the proposed architecture. The detailed analysis and experimental results presented in this chapter provide valuable insights into the effectiveness of the proposed architectures and their potential for improving the accuracy and reliability of COVID-19 detection systems.</div><div class="clear"></div>
</div>
<hr/>
Output produced by TeXtidote v0.8.2, &copy; 2018-2020 Sylvain Hall&eacute; - All rights reserved.<br/>
See the <a href="https://sylvainhalle.github.io/textidote">TeXtidote website</a> for more information.
</body>
</html>
